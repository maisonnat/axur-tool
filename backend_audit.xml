[Context] Ingesting 'crates/backend/src' in mode 'Audit'...
[Context] Using template: .agent/templates/audit.hbs
<AUDIT_PACKET>
    <INTENT>Security & Safety Review</INTENT>
    <FILES>
        <FILE path="error.rs">
            <![CDATA[
```rs
//! API error types

use axum::{
    http::StatusCode,
    response::{IntoResponse, Response},
    Json,
};
use serde_json::json;

/// API error type with proper HTTP status codes
#[derive(Debug)]
pub enum ApiError {
    /// Bad request (400)
    BadRequest(String),
    /// Unauthorized (401)  
    Unauthorized(String),
    /// Forbidden (403)
    Forbidden(String),
    /// Not found (404)
    NotFound(String),
    /// Internal server error (500)
    Internal(String),
    /// External API error
    ExternalApi(String),
}

impl IntoResponse for ApiError {
    fn into_response(self) -> Response {
        let (status, message) = match self {
            ApiError::BadRequest(msg) => (StatusCode::BAD_REQUEST, msg),
            ApiError::Unauthorized(msg) => (StatusCode::UNAUTHORIZED, msg),
            ApiError::Forbidden(msg) => (StatusCode::FORBIDDEN, msg),
            ApiError::NotFound(msg) => (StatusCode::NOT_FOUND, msg),
            ApiError::Internal(msg) => (StatusCode::INTERNAL_SERVER_ERROR, msg),
            ApiError::ExternalApi(msg) => (StatusCode::BAD_GATEWAY, msg),
        };

        let body = Json(json!({
            "error": message,
            "status": status.as_u16()
        }));

        (status, body).into_response()
    }
}

impl From<anyhow::Error> for ApiError {
    fn from(err: anyhow::Error) -> Self {
        ApiError::Internal(err.to_string())
    }
}

impl From<reqwest::Error> for ApiError {
    fn from(err: reqwest::Error) -> Self {
        ApiError::ExternalApi(format!("API request failed: {}", err))
    }
}

```
      ]]>
        </FILE>
        <FILE path="firebase.rs">
            <![CDATA[
```rs
//! Firebase Firestore Client (REST API)
//!
//! Lightweight Firestore client using REST API instead of heavy SDK.
//! Includes rate limiting and caching for zero-cost operation.
//!
//! ## Zero-Cost Safeguards
//! - Rate limiting: 2K reads/hour, 800 writes/hour
//! - In-memory cache with 5 minute TTL
//! - Fallback mode when quota exceeded

use once_cell::sync::Lazy;
use serde::{de::DeserializeOwned, Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::{Arc, RwLock};
use std::time::{Duration, Instant};
use tokio::sync::OnceCell;

// Google Auth dependencies
use base64::Engine;
use google_drive3::{hyper_rustls, hyper_util, yup_oauth2};

type HttpsConnector =
    hyper_rustls::HttpsConnector<hyper_util::client::legacy::connect::HttpConnector>;
type Authenticator = yup_oauth2::authenticator::Authenticator<HttpsConnector>;

// ========================
// CONFIGURATION
// ========================

/// Firebase project configuration
#[derive(Clone)]
pub struct FirebaseConfig {
    pub project_id: String,
    pub api_key: Option<String>,
    /// Service account JSON for server-side auth (base64 encoded)
    pub service_account_json: Option<String>,
}

impl FirebaseConfig {
    pub fn from_env() -> Option<Self> {
        let project_id = std::env::var("FIREBASE_PROJECT_ID").ok()?;
        Some(Self {
            project_id,
            api_key: std::env::var("FIREBASE_API_KEY").ok(),
            service_account_json: std::env::var("FIREBASE_SERVICE_ACCOUNT_B64").ok(),
        })
    }
}

// ========================
// RATE LIMITING
// ========================

/// Rate limiter with hourly quotas
struct RateLimiter {
    reads: u32,
    writes: u32,
    hour_start: Instant,
}

impl RateLimiter {
    fn new() -> Self {
        Self {
            reads: 0,
            writes: 0,
            hour_start: Instant::now(),
        }
    }

    fn reset_if_needed(&mut self) {
        if self.hour_start.elapsed() > Duration::from_secs(3600) {
            self.reads = 0;
            self.writes = 0;
            self.hour_start = Instant::now();
        }
    }

    fn can_read(&mut self) -> bool {
        self.reset_if_needed();
        const MAX_READS_PER_HOUR: u32 = 2000;
        if self.reads < MAX_READS_PER_HOUR {
            self.reads += 1;
            true
        } else {
            tracing::warn!("Firebase rate limit reached: reads");
            false
        }
    }

    fn can_write(&mut self) -> bool {
        self.reset_if_needed();
        const MAX_WRITES_PER_HOUR: u32 = 800;
        if self.writes < MAX_WRITES_PER_HOUR {
            self.writes += 1;
            true
        } else {
            tracing::warn!("Firebase rate limit reached: writes");
            false
        }
    }
}

static RATE_LIMITER: Lazy<Arc<RwLock<RateLimiter>>> =
    Lazy::new(|| Arc::new(RwLock::new(RateLimiter::new())));

// ========================
// CACHING
// ========================

/// Cache entry with TTL
struct CacheEntry {
    data: String,
    expires_at: Instant,
}

/// In-memory cache for Firestore documents
struct Cache {
    entries: HashMap<String, CacheEntry>,
}

impl Cache {
    fn new() -> Self {
        Self {
            entries: HashMap::new(),
        }
    }

    fn get(&self, key: &str) -> Option<String> {
        self.entries.get(key).and_then(|entry| {
            if entry.expires_at > Instant::now() {
                Some(entry.data.clone())
            } else {
                None
            }
        })
    }

    fn set(&mut self, key: String, data: String, ttl_secs: u64) {
        self.entries.insert(
            key,
            CacheEntry {
                data,
                expires_at: Instant::now() + Duration::from_secs(ttl_secs),
            },
        );
    }

    fn invalidate(&mut self, key: &str) {
        self.entries.remove(key);
    }

    fn invalidate_prefix(&mut self, prefix: &str) {
        self.entries.retain(|k, _| !k.starts_with(prefix));
    }
}

static CACHE: Lazy<Arc<RwLock<Cache>>> = Lazy::new(|| Arc::new(RwLock::new(Cache::new())));

/// Cache TTL in seconds (5 minutes)
const CACHE_TTL: u64 = 300;

// ========================
// FIRESTORE CLIENT
// ========================

/// Firestore REST API client
pub struct FirestoreClient {
    config: FirebaseConfig,
    http: reqwest::Client,
    auth: Option<Authenticator>,
}

impl FirestoreClient {
    pub fn new(config: FirebaseConfig, auth: Option<Authenticator>) -> Self {
        Self {
            config,
            http: reqwest::Client::new(),
            auth,
        }
    }

    /// Helper to get access token if auth is configured
    async fn get_token(&self) -> Result<Option<String>, FirestoreError> {
        if let Some(auth) = &self.auth {
            let scopes = &["https://www.googleapis.com/auth/datastore"];
            let token = auth
                .token(scopes)
                .await
                .map_err(|e| FirestoreError::NetworkError(format!("Auth error: {}", e)))?;
            Ok(token.token().map(|s| s.to_string()))
        } else {
            Ok(None)
        }
    }

    /// Get Firestore base URL
    fn base_url(&self) -> String {
        format!(
            "https://firestore.googleapis.com/v1/projects/{}/databases/(default)/documents",
            self.config.project_id
        )
    }

    /// Get a single document
    pub async fn get_doc<T: DeserializeOwned>(
        &self,
        collection: &str,
        doc_id: &str,
    ) -> Result<Option<T>, FirestoreError> {
        let cache_key = format!("{}/{}", collection, doc_id);

        // Check cache first
        if let Ok(cache) = CACHE.read() {
            if let Some(cached) = cache.get(&cache_key) {
                return serde_json::from_str(&cached)
                    .map(Some)
                    .map_err(|e| FirestoreError::ParseError(format!("Cache parse error: {}", e)));
            }
        }

        // Rate limit check
        {
            let mut limiter = RATE_LIMITER
                .write()
                .map_err(|e| FirestoreError::LockError(e.to_string()))?;
            if !limiter.can_read() {
                return Err(FirestoreError::RateLimited);
            }
        }

        // Get token
        let token = self.get_token().await?;

        let url = format!("{}/{}/{}", self.base_url(), collection, doc_id);
        let mut req = self.http.get(&url);

        if let Some(t) = token {
            req = req.bearer_auth(t);
        }

        let res = req
            .send()
            .await
            .map_err(|e| FirestoreError::NetworkError(e.to_string()))?;

        if res.status() == 404 {
            return Ok(None);
        }

        if !res.status().is_success() {
            return Err(FirestoreError::ApiError(format!(
                "Status: {}",
                res.status()
            )));
        }

        let doc: FirestoreDocument = res
            .json()
            .await
            .map_err(|e| FirestoreError::ParseError(e.to_string()))?;

        let value = firestore_to_value(&doc.fields)?;
        let json =
            serde_json::to_string(&value).map_err(|e| FirestoreError::ParseError(e.to_string()))?;

        // Cache the result
        if let Ok(mut cache) = CACHE.write() {
            cache.set(cache_key, json.clone(), CACHE_TTL);
        }

        serde_json::from_str(&json)
            .map(Some)
            .map_err(|e| FirestoreError::ParseError(e.to_string()))
    }

    /// List documents in a collection
    pub async fn list_docs<T: DeserializeOwned>(
        &self,
        collection: &str,
    ) -> Result<Vec<T>, FirestoreError> {
        let cache_key = format!("list:{}", collection);

        // Check cache
        if let Ok(cache) = CACHE.read() {
            if let Some(cached) = cache.get(&cache_key) {
                return serde_json::from_str(&cached)
                    .map_err(|e| FirestoreError::ParseError(format!("Cache parse error: {}", e)));
            }
        }

        // Rate limit
        {
            let mut limiter = RATE_LIMITER
                .write()
                .map_err(|e| FirestoreError::LockError(e.to_string()))?;
            if !limiter.can_read() {
                return Err(FirestoreError::RateLimited);
            }
        }

        // Get token
        let token = self.get_token().await?;

        let url = format!("{}/{}", self.base_url(), collection);
        let mut req = self.http.get(&url);

        if let Some(t) = token {
            req = req.bearer_auth(t);
        }

        let res = req
            .send()
            .await
            .map_err(|e| FirestoreError::NetworkError(e.to_string()))?;

        if !res.status().is_success() {
            return Err(FirestoreError::ApiError(format!(
                "Status: {}",
                res.status()
            )));
        }

        let list_res: FirestoreListResponse = res
            .json()
            .await
            .map_err(|e| FirestoreError::ParseError(e.to_string()))?;

        // Convert to serde_json::Value array for caching
        let values: Vec<serde_json::Value> = list_res
            .documents
            .unwrap_or_default()
            .into_iter()
            .filter_map(|doc| firestore_to_value(&doc.fields).ok())
            .collect();

        // Cache the JSON values
        let json = serde_json::to_string(&values)
            .map_err(|e| FirestoreError::ParseError(e.to_string()))?;

        if let Ok(mut cache) = CACHE.write() {
            cache.set(cache_key, json, CACHE_TTL);
        }

        // Deserialize to target type
        let docs: Vec<T> = values
            .into_iter()
            .filter_map(|v| serde_json::from_value(v).ok())
            .collect();

        Ok(docs)
    }

    /// Create or update a document
    pub async fn set_doc<T: Serialize>(
        &self,
        collection: &str,
        doc_id: &str,
        data: &T,
    ) -> Result<(), FirestoreError> {
        // Rate limit
        {
            let mut limiter = RATE_LIMITER
                .write()
                .map_err(|e| FirestoreError::LockError(e.to_string()))?;
            if !limiter.can_write() {
                return Err(FirestoreError::RateLimited);
            }
        }

        let url = format!("{}/{}/{}", self.base_url(), collection, doc_id);
        let fields = value_to_firestore(
            &serde_json::to_value(data).map_err(|e| FirestoreError::ParseError(e.to_string()))?,
        )?;
        let body = serde_json::json!({ "fields": fields });

        // Get token
        let token = self.get_token().await?;

        let mut req = self.http.patch(&url);

        if let Some(t) = token {
            req = req.bearer_auth(t);
        }

        let res = req
            .json(&body)
            .send()
            .await
            .map_err(|e| FirestoreError::NetworkError(e.to_string()))?;

        if !res.status().is_success() {
            return Err(FirestoreError::ApiError(format!(
                "Status: {}",
                res.status()
            )));
        }

        // Invalidate cache
        if let Ok(mut cache) = CACHE.write() {
            cache.invalidate(&format!("{}/{}", collection, doc_id));
            cache.invalidate_prefix(&format!("list:{}", collection));
        }

        Ok(())
    }

    /// Delete a document
    pub async fn delete_doc(&self, collection: &str, doc_id: &str) -> Result<(), FirestoreError> {
        {
            let mut limiter = RATE_LIMITER
                .write()
                .map_err(|e| FirestoreError::LockError(e.to_string()))?;
            if !limiter.can_write() {
                return Err(FirestoreError::RateLimited);
            }
        }

        let url = format!("{}/{}/{}", self.base_url(), collection, doc_id);

        // Get token
        let token = self.get_token().await?;

        let mut req = self.http.delete(&url);

        if let Some(t) = token {
            req = req.bearer_auth(t);
        }

        let res = req
            .send()
            .await
            .map_err(|e| FirestoreError::NetworkError(e.to_string()))?;

        if !res.status().is_success() && res.status() != 404 {
            return Err(FirestoreError::ApiError(format!(
                "Status: {}",
                res.status()
            )));
        }

        if let Ok(mut cache) = CACHE.write() {
            cache.invalidate(&format!("{}/{}", collection, doc_id));
            cache.invalidate_prefix(&format!("list:{}", collection));
        }

        Ok(())
    }

    /// Update a document (partial update)
    pub async fn update_doc<T: Serialize>(
        &self,
        collection: &str,
        doc_id: &str,
        data: &T,
    ) -> Result<(), FirestoreError> {
        {
            let mut limiter = RATE_LIMITER
                .write()
                .map_err(|e| FirestoreError::LockError(e.to_string()))?;
            if !limiter.can_write() {
                return Err(FirestoreError::RateLimited);
            }
        }

        let base_url = format!("{}/{}/{}", self.base_url(), collection, doc_id);
        let fields_map = value_to_firestore(
            &serde_json::to_value(data).map_err(|e| FirestoreError::ParseError(e.to_string()))?,
        )?;

        let body = serde_json::json!({ "fields": fields_map });

        // Construct updateMask query params
        // We need to list all field paths from the data
        let mut url = base_url;

        // fields_map is HashMap<String, FirestoreValue>
        if !fields_map.is_empty() {
            let mut first = true;
            for key in fields_map.keys() {
                if first {
                    url.push_str("?");
                    first = false;
                } else {
                    url.push_str("&");
                }
                url.push_str(&format!("updateMask.fieldPaths={}", key));
            }
        }

        // Get token
        let token = self.get_token().await?;

        let mut req = self.http.patch(&url);

        if let Some(t) = token {
            req = req.bearer_auth(t);
        }

        let res = req
            .json(&body)
            .send()
            .await
            .map_err(|e| FirestoreError::NetworkError(e.to_string()))?;

        if !res.status().is_success() {
            return Err(FirestoreError::ApiError(format!(
                "Status: {}",
                res.status()
            )));
        }

        // Invalidate cache
        if let Ok(mut cache) = CACHE.write() {
            cache.invalidate(&format!("{}/{}", collection, doc_id));
            cache.invalidate_prefix(&format!("list:{}", collection));
        }

        Ok(())
    }
}

// Type alias for convenience (if needed by other modules)
pub type Firestore = FirestoreClient;

// ========================
// FIRESTORE TYPES
// ========================

#[derive(Debug, Deserialize)]
struct FirestoreDocument {
    #[allow(dead_code)]
    name: Option<String>,
    fields: HashMap<String, FirestoreValue>,
}

#[derive(Debug, Deserialize)]
struct FirestoreListResponse {
    documents: Option<Vec<FirestoreDocument>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
enum FirestoreValue {
    StringValue(String),
    IntegerValue(String),
    DoubleValue(f64),
    BooleanValue(bool),
    NullValue(()),
    MapValue {
        fields: HashMap<String, FirestoreValue>,
    },
    ArrayValue {
        values: Vec<FirestoreValue>,
    },
    TimestampValue(String),
}

/// Convert Firestore fields to serde_json::Value
fn firestore_to_value(
    fields: &HashMap<String, FirestoreValue>,
) -> Result<serde_json::Value, FirestoreError> {
    let mut map = serde_json::Map::new();
    for (key, val) in fields {
        map.insert(key.clone(), firestore_value_to_json(val)?);
    }
    Ok(serde_json::Value::Object(map))
}

fn firestore_value_to_json(val: &FirestoreValue) -> Result<serde_json::Value, FirestoreError> {
    match val {
        FirestoreValue::StringValue(s) => Ok(serde_json::Value::String(s.clone())),
        FirestoreValue::IntegerValue(s) => {
            let n: i64 = s.parse().unwrap_or(0);
            Ok(serde_json::Value::Number(n.into()))
        }
        FirestoreValue::DoubleValue(d) => Ok(serde_json::json!(*d)),
        FirestoreValue::BooleanValue(b) => Ok(serde_json::Value::Bool(*b)),
        FirestoreValue::NullValue(_) => Ok(serde_json::Value::Null),
        FirestoreValue::MapValue { fields } => firestore_to_value(fields),
        FirestoreValue::ArrayValue { values } => {
            let arr: Result<Vec<_>, _> = values.iter().map(firestore_value_to_json).collect();
            Ok(serde_json::Value::Array(arr?))
        }
        FirestoreValue::TimestampValue(s) => Ok(serde_json::Value::String(s.clone())),
    }
}

/// Convert serde_json::Value to Firestore fields
fn value_to_firestore(
    val: &serde_json::Value,
) -> Result<HashMap<String, FirestoreValue>, FirestoreError> {
    match val {
        serde_json::Value::Object(map) => {
            let mut fields = HashMap::new();
            for (k, v) in map {
                fields.insert(k.clone(), json_to_firestore_value(v)?);
            }
            Ok(fields)
        }
        _ => Err(FirestoreError::ParseError("Expected object".to_string())),
    }
}

fn json_to_firestore_value(val: &serde_json::Value) -> Result<FirestoreValue, FirestoreError> {
    match val {
        serde_json::Value::Null => Ok(FirestoreValue::NullValue(())),
        serde_json::Value::Bool(b) => Ok(FirestoreValue::BooleanValue(*b)),
        serde_json::Value::Number(n) => {
            if let Some(i) = n.as_i64() {
                Ok(FirestoreValue::IntegerValue(i.to_string()))
            } else if let Some(f) = n.as_f64() {
                Ok(FirestoreValue::DoubleValue(f))
            } else {
                Ok(FirestoreValue::IntegerValue("0".to_string()))
            }
        }
        serde_json::Value::String(s) => Ok(FirestoreValue::StringValue(s.clone())),
        serde_json::Value::Array(arr) => {
            let values: Result<Vec<_>, _> = arr.iter().map(json_to_firestore_value).collect();
            Ok(FirestoreValue::ArrayValue { values: values? })
        }
        serde_json::Value::Object(map) => {
            let mut fields = HashMap::new();
            for (k, v) in map {
                fields.insert(k.clone(), json_to_firestore_value(v)?);
            }
            Ok(FirestoreValue::MapValue { fields })
        }
    }
}

// ========================
// ERRORS
// ========================

#[derive(Debug)]
pub enum FirestoreError {
    NetworkError(String),
    ApiError(String),
    ParseError(String),
    RateLimited,
    NotConfigured,
    LockError(String),
}

impl std::fmt::Display for FirestoreError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::NetworkError(e) => write!(f, "Network error: {}", e),
            Self::ApiError(e) => write!(f, "API error: {}", e),
            Self::ParseError(e) => write!(f, "Parse error: {}", e),
            Self::RateLimited => write!(f, "Rate limited - quota exceeded"),
            Self::NotConfigured => write!(f, "Firebase not configured"),
            Self::LockError(e) => write!(f, "Lock error: {}", e),
        }
    }
}

impl std::error::Error for FirestoreError {}

// ========================
// GLOBAL CLIENT
// ========================

static FIRESTORE_CLIENT: OnceCell<Option<FirestoreClient>> = OnceCell::const_new();

/// Initialize the global Firestore client (async)
pub async fn init_global() {
    let client = if let Some(config) = FirebaseConfig::from_env() {
        let mut auth = None;

        // Try to initialize auth if service account is present
        if let Some(b64) = &config.service_account_json {
            match base64::engine::general_purpose::STANDARD.decode(b64) {
                Ok(json_bytes) => {
                    // Similar implementation to google_services.rs
                    match yup_oauth2::parse_service_account_key(&json_bytes) {
                        Ok(key) => {
                            match yup_oauth2::ServiceAccountAuthenticator::builder(key)
                                .build()
                                .await
                            {
                                Ok(authenticator) => {
                                    tracing::info!(
                                        "Firestore Auth initialized with Service Account"
                                    );
                                    auth = Some(authenticator);
                                }
                                Err(e) => tracing::error!(
                                    "Failed to build Firestore authenticator: {}",
                                    e
                                ),
                            }
                        }
                        Err(e) => tracing::error!("Failed to parse service account key: {}", e),
                    }
                }
                Err(e) => tracing::error!("Failed to decode service account base64: {}", e),
            }
        } else {
            tracing::warn!("No service account JSON found for Firestore. Writes might fail (403).");
        }

        Some(FirestoreClient::new(config, auth))
    } else {
        tracing::warn!("Firebase not configured (missing FIREBASE_PROJECT_ID)");
        None
    };

    if FIRESTORE_CLIENT.set(client).is_err() {
        tracing::warn!("Firestore client already initialized");
    }
}

/// Get the global Firestore client
pub fn get_firestore() -> Option<&'static FirestoreClient> {
    FIRESTORE_CLIENT.get().and_then(|opt| opt.as_ref())
}

// ========================
// USAGE STATS
// ========================

```
      ]]>
        </FILE>
        <FILE path="github_storage.rs">
            <![CDATA[
```rs
//! GitHub Storage Backend
//!
//! Uses a private GitHub repository as storage for user templates and data.
//! Zero SQL cost, automatic versioning via Git history.

use base64::{engine::general_purpose::STANDARD as BASE64, Engine};
use reqwest::Client;
use serde::Deserialize;
use sha2::{Digest, Sha256};
use std::collections::HashMap;
use std::sync::RwLock;
use std::time::{Duration, Instant};

/// GitHub API configuration
#[derive(Clone)]
pub struct GitHubStorageConfig {
    pub token: String,
    pub owner: String,
    pub repo: String,
}

impl GitHubStorageConfig {
    /// Create from environment variables
    pub fn from_env() -> Option<Self> {
        Some(Self {
            token: std::env::var("GITHUB_TOKEN").ok()?,
            owner: std::env::var("GITHUB_OWNER").unwrap_or_else(|_| "maisonnat".to_string()),
            repo: std::env::var("GITHUB_LOGS_REPO")
                .unwrap_or_else(|_| "axur-logs-private".to_string()),
        })
    }
}

/// Cache entry with ETag for smart invalidation
struct CacheEntry {
    data: String,
    etag: Option<String>, // GitHub ETag for conditional requests
    expires_at: Instant,
}

/// GitHub Storage Client
pub struct GitHubStorage {
    client: Client,
    config: GitHubStorageConfig,
    cache: RwLock<HashMap<String, CacheEntry>>,
}

impl GitHubStorage {
    /// Create new storage client
    pub fn new(config: GitHubStorageConfig) -> Self {
        Self {
            client: Client::new(),
            config,
            cache: RwLock::new(HashMap::new()),
        }
    }

    /// Create from environment
    pub fn from_env() -> Option<Self> {
        GitHubStorageConfig::from_env().map(Self::new)
    }

    /// Hash user ID for privacy (sha256 of email)
    pub fn hash_user_id(user_id: &str) -> String {
        let mut hasher = Sha256::new();
        hasher.update(user_id.as_bytes());
        format!("{:x}", hasher.finalize())[..16].to_string() // First 16 chars
    }

    /// Get full path for user storage
    fn user_path(&self, user_hash: &str, key: &str) -> String {
        format!("users/{}/{}", user_hash, key)
    }

    /// Save data to GitHub
    pub async fn save(&self, path: &str, content: &str, message: &str) -> Result<(), String> {
        // First check if file exists to get SHA
        let existing_sha = self.get_file_sha(path).await.ok();

        let url = format!(
            "https://api.github.com/repos/{}/{}/contents/{}",
            self.config.owner, self.config.repo, path
        );

        let encoded = BASE64.encode(content.as_bytes());

        let mut body = serde_json::json!({
            "message": message,
            "content": encoded,
            "branch": "main"
        });

        // If file exists, include SHA for update
        if let Some(sha) = existing_sha {
            body["sha"] = serde_json::Value::String(sha);
        }

        let resp = self
            .client
            .put(&url)
            .header("Authorization", format!("Bearer {}", self.config.token))
            .header("Accept", "application/vnd.github.v3+json")
            .header("User-Agent", "axur-backend")
            .json(&body)
            .send()
            .await
            .map_err(|e| format!("Request failed: {}", e))?;

        if resp.status().is_success() {
            // Invalidate cache
            if let Ok(mut cache) = self.cache.write() {
                cache.remove(path);
            }
            Ok(())
        } else {
            let status = resp.status();
            let text = resp.text().await.unwrap_or_default();
            Err(format!("GitHub save failed ({}): {}", status, text))
        }
    }

    /// Load data from GitHub (with ETag-based smart caching)
    pub async fn load(&self, path: &str) -> Result<String, String> {
        self.load_with_ttl(path, Duration::from_secs(3600)).await
    }

    /// Load with custom TTL (0 = always check ETag)
    pub async fn load_with_ttl(&self, path: &str, ttl: Duration) -> Result<String, String> {
        // Check cache - get both data and etag for conditional request
        let cached = {
            if let Ok(cache) = self.cache.read() {
                cache
                    .get(path)
                    .map(|e| (e.data.clone(), e.etag.clone(), e.expires_at))
            } else {
                None
            }
        };

        // If cache is fresh (not expired), return it
        if let Some((data, _, expires_at)) = &cached {
            if *expires_at > Instant::now() && ttl.as_secs() > 0 {
                return Ok(data.clone());
            }
        }

        // Build request with conditional headers
        let url = format!(
            "https://api.github.com/repos/{}/{}/contents/{}",
            self.config.owner, self.config.repo, path
        );

        let mut req = self
            .client
            .get(&url)
            .header("Authorization", format!("Bearer {}", self.config.token))
            .header("Accept", "application/vnd.github.v3+json")
            .header("User-Agent", "axur-backend");

        // Add If-None-Match header if we have a cached etag
        if let Some((_, Some(etag), _)) = &cached {
            req = req.header("If-None-Match", etag);
        }

        let resp = req
            .send()
            .await
            .map_err(|e| format!("Request failed: {}", e))?;

        // Handle 304 Not Modified - return cached data
        if resp.status() == reqwest::StatusCode::NOT_MODIFIED {
            if let Some((data, _, _)) = cached {
                tracing::debug!("ETag match for {}, using cached data", path);
                return Ok(data);
            }
        }

        if resp.status().is_success() {
            // Extract ETag from response headers
            let new_etag = resp
                .headers()
                .get("etag")
                .and_then(|v| v.to_str().ok())
                .map(|s| s.to_string());

            let file: GitHubFile = resp
                .json()
                .await
                .map_err(|e| format!("Parse failed: {}", e))?;

            let content = BASE64
                .decode(file.content.replace('\n', ""))
                .map_err(|e| format!("Base64 decode failed: {}", e))?;

            let data = String::from_utf8(content).map_err(|e| format!("UTF8 failed: {}", e))?;

            // Update cache with new data and ETag
            if let Ok(mut cache) = self.cache.write() {
                cache.insert(
                    path.to_string(),
                    CacheEntry {
                        data: data.clone(),
                        etag: new_etag,
                        expires_at: Instant::now() + ttl,
                    },
                );
            }

            Ok(data)
        } else if resp.status() == reqwest::StatusCode::NOT_FOUND {
            Err("File not found".to_string())
        } else {
            Err(format!("GitHub load failed: {}", resp.status()))
        }
    }

    /// Delete file from GitHub
    pub async fn delete(&self, path: &str, message: &str) -> Result<(), String> {
        let sha = self.get_file_sha(path).await?;

        let url = format!(
            "https://api.github.com/repos/{}/{}/contents/{}",
            self.config.owner, self.config.repo, path
        );

        let body = serde_json::json!({
            "message": message,
            "sha": sha,
            "branch": "main"
        });

        let resp = self
            .client
            .delete(&url)
            .header("Authorization", format!("Bearer {}", self.config.token))
            .header("Accept", "application/vnd.github.v3+json")
            .header("User-Agent", "axur-backend")
            .json(&body)
            .send()
            .await
            .map_err(|e| format!("Request failed: {}", e))?;

        if resp.status().is_success() {
            // Invalidate cache
            if let Ok(mut cache) = self.cache.write() {
                cache.remove(path);
            }
            Ok(())
        } else {
            Err(format!("GitHub delete failed: {}", resp.status()))
        }
    }

    /// List files in a directory
    pub async fn list(&self, path: &str) -> Result<Vec<String>, String> {
        let url = format!(
            "https://api.github.com/repos/{}/{}/contents/{}",
            self.config.owner, self.config.repo, path
        );

        let resp = self
            .client
            .get(&url)
            .header("Authorization", format!("Bearer {}", self.config.token))
            .header("Accept", "application/vnd.github.v3+json")
            .header("User-Agent", "axur-backend")
            .send()
            .await
            .map_err(|e| format!("Request failed: {}", e))?;

        if resp.status().is_success() {
            let items: Vec<GitHubDirEntry> = resp
                .json()
                .await
                .map_err(|e| format!("Parse failed: {}", e))?;

            Ok(items.into_iter().map(|e| e.name).collect())
        } else if resp.status() == 404 {
            Ok(vec![]) // Directory doesn't exist yet
        } else {
            Err(format!("GitHub list failed: {}", resp.status()))
        }
    }

    /// Get file SHA (needed for updates)
    async fn get_file_sha(&self, path: &str) -> Result<String, String> {
        let url = format!(
            "https://api.github.com/repos/{}/{}/contents/{}",
            self.config.owner, self.config.repo, path
        );

        let resp = self
            .client
            .get(&url)
            .header("Authorization", format!("Bearer {}", self.config.token))
            .header("Accept", "application/vnd.github.v3+json")
            .header("User-Agent", "axur-backend")
            .send()
            .await
            .map_err(|e| format!("Request failed: {}", e))?;

        if resp.status().is_success() {
            let file: GitHubFile = resp
                .json()
                .await
                .map_err(|e| format!("Parse failed: {}", e))?;
            Ok(file.sha)
        } else {
            Err("File not found".to_string())
        }
    }

    // =========== User Template Operations ===========

    /// Save user template
    pub async fn save_template(
        &self,
        user_id: &str,
        template_name: &str,
        template_json: &str,
    ) -> Result<(), String> {
        let user_hash = Self::hash_user_id(user_id);
        let path = self.user_path(&user_hash, &format!("templates/{}.json", template_name));
        self.save(
            &path,
            template_json,
            &format!("Save template: {}", template_name),
        )
        .await
    }

    /// Load user template
    pub async fn load_template(
        &self,
        user_id: &str,
        template_name: &str,
    ) -> Result<String, String> {
        let user_hash = Self::hash_user_id(user_id);
        let path = self.user_path(&user_hash, &format!("templates/{}.json", template_name));
        self.load(&path).await
    }

    /// List user templates
    pub async fn list_templates(&self, user_id: &str) -> Result<Vec<String>, String> {
        let user_hash = Self::hash_user_id(user_id);
        let path = self.user_path(&user_hash, "templates");
        self.list(&path).await
    }

    /// Delete user template
    pub async fn delete_template(&self, user_id: &str, template_name: &str) -> Result<(), String> {
        let user_hash = Self::hash_user_id(user_id);
        let path = self.user_path(&user_hash, &format!("templates/{}.json", template_name));
        self.delete(&path, &format!("Delete template: {}", template_name))
            .await
    }

    // =========== Permission Operations (always fresh, 0 TTL) ===========

    /// Check if user is allowed (beta tester or admin)
    pub async fn is_user_allowed(&self, email: &str) -> Result<bool, String> {
        // Use 0 TTL to always check ETag for permissions
        let data = self
            .load_with_ttl("system/allowed_users.json", Duration::ZERO)
            .await?;
        let users: Vec<AllowedUser> =
            serde_json::from_str(&data).map_err(|e| format!("Parse failed: {}", e))?;
        Ok(users.iter().any(|u| u.email.eq_ignore_ascii_case(email)))
    }

    /// Get user role (admin, beta_tester, etc.)
    pub async fn get_user_role(&self, email: &str) -> Result<Option<String>, String> {
        let data = self
            .load_with_ttl("system/allowed_users.json", Duration::ZERO)
            .await?;
        let users: Vec<AllowedUser> =
            serde_json::from_str(&data).map_err(|e| format!("Parse failed: {}", e))?;
        Ok(users
            .iter()
            .find(|u| u.email.eq_ignore_ascii_case(email))
            .map(|u| u.role.clone()))
    }

    /// Check if user is admin
    pub async fn is_admin(&self, email: &str) -> Result<bool, String> {
        match self.get_user_role(email).await? {
            Some(role) => Ok(role == "admin"),
            None => Ok(false),
        }
    }
}

/// Allowed user entry in system/allowed_users.json
#[derive(Debug, Clone, serde::Deserialize)]
pub struct AllowedUser {
    pub email: String,
    pub role: String,
    #[serde(default)]
    pub description: Option<String>,
}

/// GitHub file response
#[derive(Deserialize)]
struct GitHubFile {
    sha: String,
    content: String,
}

/// GitHub directory entry
#[derive(Deserialize)]
struct GitHubDirEntry {
    name: String,
    #[allow(dead_code)]
    path: String,
    #[serde(rename = "type")]
    #[allow(dead_code)]
    entry_type: String,
}

// =========== Global Storage Instance ===========

use std::sync::OnceLock;
static GITHUB_STORAGE: OnceLock<Option<GitHubStorage>> = OnceLock::new();

/// Get global GitHub storage instance
pub fn get_github_storage() -> Option<&'static GitHubStorage> {
    GITHUB_STORAGE
        .get_or_init(|| GitHubStorage::from_env())
        .as_ref()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_hash_user_id() {
        let hash = GitHubStorage::hash_user_id("test@example.com");
        assert_eq!(hash.len(), 16);
        // Same input should produce same hash
        assert_eq!(hash, GitHubStorage::hash_user_id("test@example.com"));
    }
}

```
      ]]>
        </FILE>
        <FILE path="google_services.rs">
            <![CDATA[
```rs
//! Google Services for PPTX preview generation using Google Drive and Slides APIs.

use google_drive3::{hyper_rustls, hyper_util, yup_oauth2, DriveHub};
use governor::{Quota, RateLimiter};
use nonzero_ext::*;
use serde::Deserialize;
use std::sync::Arc;

// Type alias for the connector used by google-drive3
type HttpConnector = hyper_util::client::legacy::connect::HttpConnector;

#[derive(Clone)]
pub struct GoogleServices {
    drive: DriveHub<hyper_rustls::HttpsConnector<HttpConnector>>,
    limiter: Arc<
        RateLimiter<
            governor::state::NotKeyed,
            governor::state::InMemoryState,
            governor::clock::DefaultClock,
        >,
    >,
    auth: yup_oauth2::authenticator::Authenticator<hyper_rustls::HttpsConnector<HttpConnector>>,
    http_client: reqwest::Client,
}

#[derive(Deserialize)]
struct Presentation {
    slides: Option<Vec<Slide>>,
}

#[derive(Deserialize)]
struct Slide {
    #[serde(rename = "objectId")]
    object_id: Option<String>,
}

#[derive(Deserialize)]
struct ThumbnailResponse {
    #[serde(rename = "contentUrl")]
    content_url: Option<String>,
}

impl GoogleServices {
    /// Create from environment variables (for production)
    /// Required env vars: GOOGLE_CLIENT_ID, GOOGLE_CLIENT_SECRET, GOOGLE_REFRESH_TOKEN
    pub async fn from_env() -> std::result::Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        let client_id =
            std::env::var("GOOGLE_CLIENT_ID").map_err(|_| "GOOGLE_CLIENT_ID not set")?;
        let client_secret =
            std::env::var("GOOGLE_CLIENT_SECRET").map_err(|_| "GOOGLE_CLIENT_SECRET not set")?;
        let refresh_token =
            std::env::var("GOOGLE_REFRESH_TOKEN").map_err(|_| "GOOGLE_REFRESH_TOKEN not set")?;

        // Write to temp file (yup-oauth2 doesn't expose the struct publicly)
        let json_content = serde_json::json!({
            "type": "authorized_user",
            "client_id": client_id,
            "client_secret": client_secret,
            "refresh_token": refresh_token
        });

        let temp_path = "/tmp/google_token.json";
        std::fs::write(temp_path, json_content.to_string())?;

        Self::new("", temp_path).await
    }

    /// Create from token.json file (for local development)
    pub async fn new(
        _client_secret_path: &str,
        token_path: &str,
    ) -> std::result::Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        let secret = yup_oauth2::read_authorized_user_secret(token_path).await?;

        // Build HTTPS connector with rustls using google_drive3's bundled types
        let https_connector = hyper_rustls::HttpsConnectorBuilder::new()
            .with_native_roots()?
            .https_only()
            .enable_http1()
            .build();

        // Build hyper client with hyper_util (hyper v1 style)
        let hyper_client =
            hyper_util::client::legacy::Client::builder(hyper_util::rt::TokioExecutor::new())
                .build(https_connector);

        // Build authenticator for Authorized User
        let auth: yup_oauth2::authenticator::Authenticator<
            hyper_rustls::HttpsConnector<HttpConnector>,
        > = yup_oauth2::AuthorizedUserAuthenticator::builder(secret)
            .build()
            .await?;

        // Create Drive hub with scopes
        let drive = DriveHub::new(hyper_client, auth.clone());

        // Rate Limiter: 4 req/sec
        let quota = Quota::per_second(nonzero!(4u32));
        let limiter = Arc::new(RateLimiter::direct(quota));

        // Reqwest client for manual Slides API calls
        // Increase timeout for large PPTX uploads (e.g. 32MB takes >30s)
        let http_client = reqwest::Client::builder()
            .timeout(std::time::Duration::from_secs(300))
            .build()?;

        Ok(GoogleServices {
            drive,
            limiter,
            auth,
            http_client,
        })
    }

    /// Uploads a PPTX file to Google Drive and returns the File ID.
    /// Uses direct reqwest calls instead of google-drive3 to avoid library issues.
    pub async fn upload_pptx(&self, name: &str, data: Vec<u8>) -> Result<String, String> {
        // Shared folder constant removed - uploading to root

        // Get access token from authenticator
        let scopes = &["https://www.googleapis.com/auth/drive.file"];
        let token = self
            .auth
            .token(scopes)
            .await
            .map_err(|e| format!("Token Error: {}", e))?;
        let access_token = token.token().ok_or("No token string")?;

        // Step 1: Initiate resumable upload session
        // Note: No 'parents' specified means upload to user's root "My Drive"
        let metadata = serde_json::json!({
            "name": name,
            "mimeType": "application/vnd.google-apps.presentation"
        });

        let init_url = "https://www.googleapis.com/upload/drive/v3/files?uploadType=resumable";

        let init_resp = self
            .http_client
            .post(init_url)
            .bearer_auth(access_token)
            .header("Content-Type", "application/json; charset=UTF-8")
            .json(&metadata)
            .send()
            .await
            .map_err(|e| format!("Init request failed: {}", e))?;

        if !init_resp.status().is_success() {
            let status = init_resp.status();
            let body = init_resp.text().await.unwrap_or_default();
            tracing::error!("Drive Init FAILED - Status: {}, Body: {}", status, body);
            tracing::error!("Request metadata was: {}", metadata);
            return Err(format!(
                "Drive Upload Error ({} {}): {}",
                status.as_u16(),
                status.canonical_reason().unwrap_or(""),
                body
            ));
        }

        // Get the upload URI from the Location header
        let upload_uri = init_resp
            .headers()
            .get("location")
            .and_then(|h| h.to_str().ok())
            .ok_or("No upload location returned")?
            .to_string();

        tracing::info!("Got upload URI, uploading {} bytes", data.len());

        // Step 2: Upload the actual file content
        let upload_resp = self
            .http_client
            .put(&upload_uri)
            .header(
                "Content-Type",
                "application/vnd.openxmlformats-officedocument.presentationml.presentation",
            )
            .header("Content-Length", data.len().to_string())
            .body(data)
            .send()
            .await
            .map_err(|e| format!("Upload request failed: {}", e))?;

        if !upload_resp.status().is_success() {
            let status = upload_resp.status();
            let body = upload_resp.text().await.unwrap_or_default();
            return Err(format!("Drive Upload Error ({}): {}", status, body));
        }

        // Parse response to get file ID
        let file_info: serde_json::Value = upload_resp
            .json()
            .await
            .map_err(|e| format!("Failed to parse upload response: {}", e))?;

        file_info
            .get("id")
            .and_then(|id| id.as_str())
            .map(|s| s.to_string())
            .ok_or_else(|| "No file ID in response".to_string())
    }

    /// Deletes a file from Google Drive.
    pub async fn delete_file(&self, file_id: &str) -> Result<(), String> {
        self.drive
            .files()
            .delete(file_id)
            .add_scope("https://www.googleapis.com/auth/drive.file")
            .doit()
            .await
            .map_err(|e| format!("Drive Delete Error: {}", e))?;
        Ok(())
    }

    /// Orchestrates the preview generation: Get Slides -> Loop Thumbnails -> Return URLs
    pub async fn generate_previews(&self, file_id: &str) -> Result<Vec<String>, String> {
        // 1. Get Access Token for Slides API
        let scopes = &["https://www.googleapis.com/auth/presentations.readonly"];
        let token = self
            .auth
            .token(scopes)
            .await
            .map_err(|e| format!("Token Error: {}", e))?;
        let access_token = token.token().ok_or("No token string")?;

        // 2. Get Presentation Structure (Manual API Call via reqwest)
        let url = format!("https://slides.googleapis.com/v1/presentations/{}", file_id);
        let resp = self
            .http_client
            .get(&url)
            .bearer_auth(access_token)
            .send()
            .await
            .map_err(|e| format!("Slides API Request Error: {}", e))?;

        if !resp.status().is_success() {
            let status = resp.status();
            let body = resp.text().await.unwrap_or_default();
            return Err(format!("Slides API Error ({}): {}", status, body));
        }

        let presentation: Presentation = resp
            .json()
            .await
            .map_err(|e| format!("Slides JSON Parse Error: {}", e))?;

        let slides = presentation
            .slides
            .ok_or("No slides found in presentation")?;
        let mut urls = Vec::new();

        // 3. Loop and get Thumbnails with Rate Limiting
        for slide in slides {
            let page_id = slide.object_id.ok_or("Slide has no ID")?;

            // Wait for rate limiter
            self.limiter.until_ready().await;

            // Fetch thumbnail
            let thumb_url = format!(
                "https://slides.googleapis.com/v1/presentations/{}/pages/{}/thumbnail",
                file_id, page_id
            );

            let thumb_resp = self
                .http_client
                .get(&thumb_url)
                .bearer_auth(access_token)
                .send()
                .await
                .map_err(|e| format!("Thumbnail Request Error: {}", e))?;

            if !thumb_resp.status().is_success() {
                let status = thumb_resp.status();
                return Err(format!(
                    "Thumbnail API Error for slide {}: {}",
                    page_id, status
                ));
            }

            let thumb_json: ThumbnailResponse = thumb_resp
                .json()
                .await
                .map_err(|e| format!("Thumbnail JSON Parse Error for slide {}: {}", page_id, e))?;

            if let Some(content_url) = thumb_json.content_url {
                urls.push(content_url);
            } else {
                return Err(format!(
                    "Thumbnail response missing contentUrl for slide {}",
                    page_id
                ));
            }
        }

        Ok(urls)
    }

    /// Download images from URLs and convert to base64 data URLs.
    /// Handles 429 rate limiting with Retry-After header support.
    pub async fn fetch_images_as_base64(&self, urls: Vec<String>) -> Result<Vec<String>, String> {
        use base64::Engine;
        let mut data_urls = Vec::with_capacity(urls.len());

        for (idx, url) in urls.iter().enumerate() {
            let mut attempt = 0;
            let max_attempts = 5;

            loop {
                // Rate limit first
                self.limiter.until_ready().await;

                let resp = self
                    .http_client
                    .get(url)
                    .send()
                    .await
                    .map_err(|e| format!("Image fetch error: {}", e))?;

                let status = resp.status();

                if status == reqwest::StatusCode::TOO_MANY_REQUESTS {
                    // Read Retry-After header (seconds)
                    let retry_after = resp
                        .headers()
                        .get("Retry-After")
                        .and_then(|v| v.to_str().ok())
                        .and_then(|s| s.parse::<u64>().ok())
                        .unwrap_or(5); // Default 5 seconds if header missing

                    tracing::warn!(
                        "[GoogleServices] 429 on image {}/{}, Retry-After: {}s (attempt {})",
                        idx + 1,
                        urls.len(),
                        retry_after,
                        attempt + 1
                    );

                    tokio::time::sleep(std::time::Duration::from_secs(retry_after)).await;
                    attempt += 1;

                    if attempt >= max_attempts {
                        return Err(format!(
                            "Image {} failed after {} attempts due to rate limiting",
                            idx + 1,
                            max_attempts
                        ));
                    }
                    continue;
                }

                if !status.is_success() {
                    return Err(format!(
                        "Image {} fetch error: {} {}",
                        idx + 1,
                        status.as_u16(),
                        status.canonical_reason().unwrap_or("")
                    ));
                }

                // Get content type for data URL
                let content_type = resp
                    .headers()
                    .get("content-type")
                    .and_then(|v| v.to_str().ok())
                    .unwrap_or("image/png")
                    .to_string();

                // Download bytes
                let bytes = resp
                    .bytes()
                    .await
                    .map_err(|e| format!("Image {} bytes error: {}", idx + 1, e))?;

                // Encode to base64
                let b64 = base64::engine::general_purpose::STANDARD.encode(&bytes);
                let data_url = format!("data:{};base64,{}", content_type, b64);

                data_urls.push(data_url);
                tracing::info!(
                    "[GoogleServices] Image {}/{} downloaded ({} KB)",
                    idx + 1,
                    urls.len(),
                    bytes.len() / 1024
                );
                break;
            }
        }

        Ok(data_urls)
    }

    // =================================================================
    // GOOGLE SLIDES EXPORT METHODS
    // =================================================================

    /// Create a new empty Google Slides presentation
    /// Returns the presentation ID
    pub async fn create_presentation(&self, title: &str) -> Result<String, String> {
        // Rate limit
        self.limiter.until_ready().await;

        // Get access token for Slides write scope
        let scopes = &["https://www.googleapis.com/auth/presentations"];
        let token = self
            .auth
            .token(scopes)
            .await
            .map_err(|e| format!("Token Error: {}", e))?;
        let access_token = token.token().ok_or("No token string")?;

        // Create presentation request
        let body = serde_json::json!({
            "title": title
        });

        let url = "https://slides.googleapis.com/v1/presentations";
        let resp = self
            .http_client
            .post(url)
            .bearer_auth(access_token)
            .json(&body)
            .send()
            .await
            .map_err(|e| format!("Create Presentation Request Error: {}", e))?;

        if !resp.status().is_success() {
            let status = resp.status();
            let body = resp.text().await.unwrap_or_default();
            return Err(format!("Slides API Error ({}): {}", status, body));
        }

        let result: serde_json::Value = resp
            .json()
            .await
            .map_err(|e| format!("Parse Presentation Response Error: {}", e))?;

        result
            .get("presentationId")
            .and_then(|id| id.as_str())
            .map(|s| s.to_string())
            .ok_or_else(|| "No presentation ID in response".to_string())
    }

    /// Add slides with content to an existing presentation using batchUpdate
    ///
    /// # Arguments
    /// * `presentation_id` - The Google Slides presentation ID
    /// * `slides` - Vector of SlideData with title, body, and layout
    pub async fn add_slides_batch(
        &self,
        presentation_id: &str,
        slides: &[SlideData],
    ) -> Result<(), String> {
        // Rate limit (1 second delay per API rules)
        self.limiter.until_ready().await;
        tokio::time::sleep(std::time::Duration::from_secs(1)).await;

        // Get access token
        let scopes = &["https://www.googleapis.com/auth/presentations"];
        let token = self
            .auth
            .token(scopes)
            .await
            .map_err(|e| format!("Token Error: {}", e))?;
        let access_token = token.token().ok_or("No token string")?;

        // Build batchUpdate requests
        let mut requests = Vec::new();

        for (index, slide) in slides.iter().enumerate() {
            let slide_id = format!("slide_{}", index);

            // 1. Create slide with layout
            requests.push(serde_json::json!({
                "createSlide": {
                    "objectId": slide_id,
                    "insertionIndex": index + 1,  // After title slide
                    "slideLayoutReference": {
                        "predefinedLayout": slide.layout.as_deref().unwrap_or("BLANK")
                    }
                }
            }));

            // 2. Add title text box
            if !slide.title.is_empty() {
                let title_id = format!("{}_title", slide_id);
                requests.push(serde_json::json!({
                    "createShape": {
                        "objectId": title_id,
                        "shapeType": "TEXT_BOX",
                        "elementProperties": {
                            "pageObjectId": slide_id,
                            "size": {
                                "width": { "magnitude": 600, "unit": "PT" },
                                "height": { "magnitude": 50, "unit": "PT" }
                            },
                            "transform": {
                                "scaleX": 1.0,
                                "scaleY": 1.0,
                                "translateX": 30.0,
                                "translateY": 20.0,
                                "unit": "PT"
                            }
                        }
                    }
                }));
                requests.push(serde_json::json!({
                    "insertText": {
                        "objectId": title_id,
                        "text": &slide.title
                    }
                }));
                // Style title
                requests.push(serde_json::json!({
                    "updateTextStyle": {
                        "objectId": title_id,
                        "style": {
                            "bold": true,
                            "fontSize": { "magnitude": 28, "unit": "PT" },
                            "foregroundColor": {
                                "opaqueColor": {
                                    "rgbColor": { "red": 1.0, "green": 0.294, "blue": 0.0 }  // #FF4B00
                                }
                            }
                        },
                        "fields": "bold,fontSize,foregroundColor"
                    }
                }));
            }

            // 3. Add body text box
            if !slide.body.is_empty() {
                let body_id = format!("{}_body", slide_id);
                let body_text = slide.body.join("\n\n");
                requests.push(serde_json::json!({
                    "createShape": {
                        "objectId": body_id,
                        "shapeType": "TEXT_BOX",
                        "elementProperties": {
                            "pageObjectId": slide_id,
                            "size": {
                                "width": { "magnitude": 600, "unit": "PT" },
                                "height": { "magnitude": 300, "unit": "PT" }
                            },
                            "transform": {
                                "scaleX": 1.0,
                                "scaleY": 1.0,
                                "translateX": 30.0,
                                "translateY": 80.0,
                                "unit": "PT"
                            }
                        }
                    }
                }));
                requests.push(serde_json::json!({
                    "insertText": {
                        "objectId": body_id,
                        "text": body_text
                    }
                }));
                // Style body
                requests.push(serde_json::json!({
                    "updateTextStyle": {
                        "objectId": body_id,
                        "style": {
                            "fontSize": { "magnitude": 14, "unit": "PT" },
                            "foregroundColor": {
                                "opaqueColor": {
                                    "rgbColor": { "red": 0.94, "green": 0.94, "blue": 0.96 }  // Light gray
                                }
                            }
                        },
                        "fields": "fontSize,foregroundColor"
                    }
                }));
            }

            // 4. Set dark background
            requests.push(serde_json::json!({
                "updatePageProperties": {
                    "objectId": slide_id,
                    "pageProperties": {
                        "pageBackgroundFill": {
                            "solidFill": {
                                "color": {
                                    "rgbColor": { "red": 0.039, "green": 0.039, "blue": 0.039 }  // #0A0A0A
                                }
                            }
                        }
                    },
                    "fields": "pageBackgroundFill"
                }
            }));
        }

        if requests.is_empty() {
            return Ok(());
        }

        // Send batchUpdate request
        let url = format!(
            "https://slides.googleapis.com/v1/presentations/{}:batchUpdate",
            presentation_id
        );
        let body = serde_json::json!({ "requests": requests });

        let resp = self
            .http_client
            .post(&url)
            .bearer_auth(access_token)
            .json(&body)
            .send()
            .await
            .map_err(|e| format!("BatchUpdate Request Error: {}", e))?;

        if !resp.status().is_success() {
            let status = resp.status();
            let error_body = resp.text().await.unwrap_or_default();
            tracing::error!("BatchUpdate failed: {} - {}", status, error_body);
            return Err(format!(
                "Slides BatchUpdate Error ({}): {}",
                status, error_body
            ));
        }

        Ok(())
    }

    /// Get the shareable URL for a Google Slides presentation
    pub fn get_presentation_url(&self, presentation_id: &str) -> String {
        format!(
            "https://docs.google.com/presentation/d/{}/edit",
            presentation_id
        )
    }
}

/// Slide data for Google Slides export
#[derive(Debug, Clone)]
pub struct SlideData {
    pub title: String,
    pub body: Vec<String>,
    pub layout: Option<String>,
}

```
      ]]>
        </FILE>
        <FILE path="injector.rs">
            <![CDATA[
```rs
use crate::utils::coords::px_to_emu;
use serde::{Deserialize, Serialize};
use std::io::{Cursor, Read, Write};
use zip::{write::FileOptions, ZipArchive, ZipWriter};

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct SlideEdit {
    pub slide_index: usize, // 1-based index from frontend
    pub text: String,
    pub x: f64,
    pub y: f64,
    pub width: f64,
    pub height: f64,
    pub placeholder_key: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct InjectionRequest {
    pub edits: Vec<SlideEdit>,
}

pub fn inject_edits(original_pptx: &[u8], edits: Vec<SlideEdit>) -> Result<Vec<u8>, anyhow::Error> {
    let cursor = Cursor::new(original_pptx);
    let mut archive = ZipArchive::new(cursor)?;

    let mut out_buffer = Vec::new();
    let mut zip_writer = ZipWriter::new(Cursor::new(&mut out_buffer));

    // Group edits by slide index for faster lookup
    let mut edits_by_slide: std::collections::HashMap<usize, Vec<SlideEdit>> =
        std::collections::HashMap::new();
    for edit in edits {
        edits_by_slide
            .entry(edit.slide_index)
            .or_default()
            .push(edit);
    }

    for i in 0..archive.len() {
        let mut file = archive.by_index(i)?;
        let name = file.name().to_string();
        let options = FileOptions::default()
            .compression_method(file.compression())
            .unix_permissions(file.unix_mode().unwrap_or(0o644));

        let mut content = Vec::new();
        file.read_to_end(&mut content)?;

        // Check if this file is a slide that needs editing
        if name.starts_with("ppt/slides/slide") && name.ends_with(".xml") {
            // Extract number: slide1.xml -> 1
            let num_part = name
                .trim_start_matches("ppt/slides/slide")
                .trim_end_matches(".xml");

            if let Ok(idx) = num_part.parse::<usize>() {
                if let Some(slide_edits) = edits_by_slide.get(&idx) {
                    // INJECT XML HERE
                    let content_str = String::from_utf8(content.clone())?;
                    if content_str.contains("</p:spTree>") {
                        let mut new_shapes_xml = String::new();
                        for edit in slide_edits {
                            new_shapes_xml.push_str(&create_textbox_xml(edit));
                        }

                        let modified_xml = content_str.replace(
                            "</p:spTree>",
                            &format!("{}{}", new_shapes_xml, "</p:spTree>"),
                        );
                        content = modified_xml.into_bytes();
                        tracing::info!("Injected {} edits into {}", slide_edits.len(), name);
                    }
                }
            }
        }

        zip_writer.start_file(name, options)?;
        zip_writer.write_all(&content)?;
    }

    let cursor = zip_writer.finish()?;
    Ok(cursor.into_inner().to_vec())
}

fn create_textbox_xml(edit: &SlideEdit) -> String {
    let x_emu = px_to_emu(edit.x);
    let y_emu = px_to_emu(edit.y);
    let cx_emu = px_to_emu(edit.width);
    let cy_emu = px_to_emu(edit.height);
    let shape_id = 5000 + (edit.x as u32) + (edit.y as u32);
    // Use placeholder_key for name if available, otherwise shape_id
    let shape_name = edit
        .placeholder_key
        .clone()
        .map(|k| format!("Placeholder_{}", k))
        .unwrap_or(format!("Placeholder_{}", shape_id));

    format!(
        r#"
    <p:sp>
        <p:nvSpPr>
            <p:cNvPr id="{}" name="{}"/>
            <p:cNvSpPr txBox="1"/>
            <p:nvPr/>
        </p:nvSpPr>
        <p:spPr>
            <a:xfrm>
                <a:off x="{}" y="{}"/>
                <a:ext cx="{}" cy="{}"/>
            </a:xfrm>
            <a:prstGeom prst="rect">
                <a:avLst/>
            </a:prstGeom>
            <a:noFill/> 
        </p:spPr>
        <p:txBody>
            <a:bodyPr wrap="square" rtlCol="0"/>
            <a:lstStyle/>
            <a:p>
                <a:r>
                    <a:rPr lang="en-US" sz="1800" dirty="0">
                        <a:solidFill>
                            <a:srgbClr val="000000"/>
                        </a:solidFill> 
                     </a:rPr>
                    <a:t>{}</a:t>
                </a:r>
            </a:p>
        </p:txBody>
    </p:sp>
    "#,
        shape_id, shape_name, x_emu, y_emu, cx_emu, cy_emu, edit.text
    )
}

```
      ]]>
        </FILE>
        <FILE path="lib.rs">
            <![CDATA[
```rs
//! Axur Backend - Axum Server
//!
//! Auth proxy and report generation API for Axur Web.

pub mod error;
pub mod firebase;
pub mod github_storage;
pub mod google_services;
pub mod injector;
pub mod middleware;
pub mod queue;
pub mod routes;
pub mod services;
pub mod utils;

// Re-export the router creator
pub use crate::routes::create_router;

```
      ]]>
        </FILE>
        <FILE path="main.rs">
            <![CDATA[
```rs
//! Axur Backend Server Entry Point

use std::net::SocketAddr;

use axur_backend::create_router;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Load .env definitions
    dotenv::dotenv().ok();

    // Initialize tracing with explicit stdout and debug level
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::DEBUG)
        .with_target(false)
        .init();

    // Backend initialization

    // Start background queue worker
    axur_backend::queue::start_worker();
    tracing::info!("Queue worker started");

    // Initialize Firestore (Auth)
    axur_backend::firebase::init_global().await;
    tracing::info!("Firestore initialized");

    // Initialize Google Services
    // Priority: 1) Environment variables (production), 2) Local files (development)
    let google_services = if std::env::var("GOOGLE_CLIENT_ID").is_ok() {
        // Production: use environment variables
        match axur_backend::google_services::GoogleServices::from_env().await {
            Ok(service) => {
                tracing::info!("Google Services initialized (Environment Variables)");
                Some(std::sync::Arc::new(service))
            }
            Err(e) => {
                tracing::error!("Failed to initialize Google Services from env: {}", e);
                None
            }
        }
    } else {
        // Development: use local token.json file
        let client_secret_path = "config/client_secret.json";
        let token_path = "config/token.json";

        if std::path::Path::new(token_path).exists() {
            match axur_backend::google_services::GoogleServices::new(client_secret_path, token_path)
                .await
            {
                Ok(service) => {
                    tracing::info!("Google Services initialized (Local Files)");
                    Some(std::sync::Arc::new(service))
                }
                Err(e) => {
                    tracing::error!("Failed to initialize Google Services: {}", e);
                    None
                }
            }
        } else {
            tracing::warn!("Google credentials not found. Google integration disabled.");
            None
        }
    };

    let app_state = axur_backend::routes::AppState { google_services };

    // Build router (from routes module)
    let app = create_router(app_state);

    // Run server
    let port = std::env::var("PORT")
        .unwrap_or_else(|_| "3001".to_string())
        .parse::<u16>()
        .unwrap_or(3001);

    let addr = SocketAddr::from(([0, 0, 0, 0], port));
    tracing::info!(" Axur Backend listening on http://{}", addr);

    let listener = tokio::net::TcpListener::bind(addr).await?;
    axum::serve(listener, app).await?;

    Ok(())
}

```
      ]]>
        </FILE>
        <FILE path="middleware\mod.rs">
            <![CDATA[
```rs
//! Middleware module

pub mod security;

pub use security::*;

```
      ]]>
        </FILE>
        <FILE path="middleware\security.rs">
            <![CDATA[
```rs
//! Security middleware and utilities

use axum::{extract::Request, http::StatusCode, middleware::Next, response::Response};
use axum_extra::extract::CookieJar;

/// Cookie name for the auth token
pub const AUTH_COOKIE_NAME: &str = "axur_session";
/// Cookie name for the user ID (email)
pub const AUTH_USER_COOKIE_NAME: &str = "axur_user";

/// Extract token from httpOnly cookie
pub fn get_token_from_cookies(jar: &CookieJar) -> Option<String> {
    jar.get(AUTH_COOKIE_NAME).map(|c| c.value().to_string())
}

/// Extract user ID from httpOnly cookie
pub fn get_user_from_cookies(jar: &CookieJar) -> Option<String> {
    jar.get(AUTH_USER_COOKIE_NAME)
        .map(|c| c.value().to_string())
}

/// Middleware that requires authentication
pub async fn require_auth(
    jar: CookieJar,
    request: Request,
    next: Next,
) -> Result<Response, StatusCode> {
    if get_token_from_cookies(&jar).is_none() {
        return Err(StatusCode::UNAUTHORIZED);
    }

    // Extract user ID (email) from cookie and insert into request extensions
    let mut request = request;
    if let Some(user_id) = get_user_from_cookies(&jar) {
        request.extensions_mut().insert(user_id);
    } else {
        // If we have a token but no user cookie, we can't identify the user for templates
        // We could error out, or let it slide and fail in handlers.
        // Failing here is safer/clearer.
        tracing::warn!("Auth token present but axur_user cookie missing");
        return Err(StatusCode::UNAUTHORIZED);
    }

    Ok(next.run(request).await)
}

```
      ]]>
        </FILE>
        <FILE path="queue.rs">
            <![CDATA[
```rs
//! Request Queue with Token Bucket Rate Limiting
//!
//! Manages API request rates to prevent 429 errors and provides
//! real-time queue position updates to users.

use serde::{Deserialize, Serialize};
use std::collections::{HashMap, VecDeque};
use std::sync::atomic::{AtomicU32, AtomicU64, Ordering};
use std::time::Duration;
use tokio::sync::RwLock;
use uuid::Uuid;

/// Token Bucket Rate Limiter
///
/// Implements the token bucket algorithm for precise rate limiting.
/// Tokens refill at a constant rate up to capacity.
pub struct TokenBucket {
    /// Maximum tokens in the bucket
    capacity: u32,
    /// Current available tokens
    tokens: AtomicU32,
    /// Tokens added per refill
    refill_rate: u32,
    /// Time between refills
    refill_interval: Duration,
    /// Last refill timestamp (ms since epoch)
    last_refill: AtomicU64,
}

impl TokenBucket {
    /// Create a new token bucket
    pub fn new(capacity: u32, refill_rate: u32, refill_interval: Duration) -> Self {
        Self {
            capacity,
            tokens: AtomicU32::new(capacity),
            refill_rate,
            refill_interval,
            last_refill: AtomicU64::new(Self::now_ms()),
        }
    }

    fn now_ms() -> u64 {
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_millis() as u64
    }

    /// Refill tokens based on elapsed time
    fn refill(&self) {
        let now = Self::now_ms();
        let last = self.last_refill.load(Ordering::Relaxed);
        let interval_ms = self.refill_interval.as_millis() as u64;

        if now >= last + interval_ms {
            let intervals = ((now - last) / interval_ms) as u32;
            let tokens_to_add = intervals * self.refill_rate;

            let current = self.tokens.load(Ordering::Relaxed);
            let new_tokens = (current + tokens_to_add).min(self.capacity);
            self.tokens.store(new_tokens, Ordering::Relaxed);

            // Update last refill time
            let new_last = last + (intervals as u64 * interval_ms);
            self.last_refill.store(new_last, Ordering::Relaxed);
        }
    }

    /// Try to acquire a token. Returns true if successful.
    pub fn try_acquire(&self) -> bool {
        self.refill();

        loop {
            let current = self.tokens.load(Ordering::Relaxed);
            if current == 0 {
                return false;
            }

            if self
                .tokens
                .compare_exchange(current, current - 1, Ordering::SeqCst, Ordering::Relaxed)
                .is_ok()
            {
                return true;
            }
        }
    }

    /// Get time to wait for next token (if bucket is empty)
    pub fn time_until_available(&self) -> Duration {
        self.refill();

        if self.tokens.load(Ordering::Relaxed) > 0 {
            return Duration::ZERO;
        }

        let now = Self::now_ms();
        let last = self.last_refill.load(Ordering::Relaxed);
        let interval_ms = self.refill_interval.as_millis() as u64;
        let next_refill = last + interval_ms;

        if now >= next_refill {
            Duration::ZERO
        } else {
            Duration::from_millis(next_refill - now)
        }
    }

    /// Current available tokens
    pub fn available(&self) -> u32 {
        self.refill();
        self.tokens.load(Ordering::Relaxed)
    }
}

/// API type for rate limiting
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum ApiType {
    Axur,
    GitHub,
    Leapcell,
}

impl ApiType {
    /// Get rate limit configuration for each API
    pub fn rate_limit(&self) -> (u32, u32, Duration) {
        // (capacity, refill_rate, refill_interval)
        match self {
            ApiType::Axur => (60, 60, Duration::from_secs(60)), // 60/min
            ApiType::GitHub => (5000, 5000, Duration::from_secs(3600)), // 5000/hour
            ApiType::Leapcell => (100, 100, Duration::from_secs(60)), // 100/min
        }
    }
}

/// Job type for the queue
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum JobType {
    GenerateReport { tenant_id: String },
    SaveTemplate { template_name: String },
    LoadTemplate { template_id: String },
    ThreatHuntingSearch { query: String },
}

/// Job status
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "status")]
pub enum JobStatus {
    Queued { position: usize },
    Processing { started_at: u64 },
    Completed { result: serde_json::Value },
    Failed { error: String },
}

/// A job in the queue
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueueJob {
    pub id: String,
    pub user_id: String,
    pub job_type: JobType,
    pub api_type: ApiType,
    pub created_at: u64,
    pub status: JobStatus,
    pub priority: u8, // Higher = more priority
}

impl QueueJob {
    pub fn new(user_id: String, job_type: JobType, api_type: ApiType) -> Self {
        Self {
            id: Uuid::new_v4().to_string(),
            user_id,
            job_type,
            api_type,
            created_at: TokenBucket::now_ms(),
            status: JobStatus::Queued { position: 0 },
            priority: 0,
        }
    }
}

/// Request Queue Manager
pub struct RequestQueue {
    jobs: RwLock<VecDeque<QueueJob>>,
    rate_limiters: HashMap<ApiType, TokenBucket>,
    completed_jobs: RwLock<HashMap<String, QueueJob>>,
}

impl RequestQueue {
    /// Create a new request queue with rate limiters for each API
    pub fn new() -> Self {
        let mut rate_limiters = HashMap::new();

        for api_type in [ApiType::Axur, ApiType::GitHub, ApiType::Leapcell] {
            let (capacity, refill_rate, interval) = api_type.rate_limit();
            rate_limiters.insert(api_type, TokenBucket::new(capacity, refill_rate, interval));
        }

        Self {
            jobs: RwLock::new(VecDeque::new()),
            rate_limiters,
            completed_jobs: RwLock::new(HashMap::new()),
        }
    }

    /// Submit a job to the queue
    pub async fn submit(&self, mut job: QueueJob) -> String {
        let mut jobs = self.jobs.write().await;
        let position = jobs.len();
        job.status = JobStatus::Queued { position };
        let job_id = job.id.clone();
        jobs.push_back(job);
        job_id
    }

    /// Get job status by ID
    pub async fn get_job(&self, job_id: &str) -> Option<QueueJob> {
        // Check active queue first
        {
            let jobs = self.jobs.read().await;
            for (idx, job) in jobs.iter().enumerate() {
                if job.id == job_id {
                    let mut job = job.clone();
                    job.status = JobStatus::Queued { position: idx };
                    return Some(job);
                }
            }
        }

        // Check completed jobs
        {
            let completed = self.completed_jobs.read().await;
            if let Some(job) = completed.get(job_id) {
                return Some(job.clone());
            }
        }

        None
    }

    /// Get queue length
    pub async fn queue_length(&self) -> usize {
        self.jobs.read().await.len()
    }

    /// Get estimated wait time for a position
    pub fn estimate_wait_time(&self, position: usize, api_type: ApiType) -> Duration {
        if let Some(bucket) = self.rate_limiters.get(&api_type) {
            let available = bucket.available() as usize;
            if position < available {
                return Duration::ZERO;
            }

            let (_, refill_rate, interval) = api_type.rate_limit();
            let jobs_to_wait = position.saturating_sub(available);
            let intervals_needed = (jobs_to_wait as f64 / refill_rate as f64).ceil() as u64;

            interval * intervals_needed as u32
        } else {
            Duration::from_secs(position as u64 * 2) // Fallback: ~2s per job
        }
    }

    /// Try to acquire a rate limit token for an API
    pub fn can_process(&self, api_type: ApiType) -> bool {
        self.rate_limiters
            .get(&api_type)
            .map(|b| b.try_acquire())
            .unwrap_or(true)
    }

    /// Get next job that can be processed
    pub async fn pop_ready(&self) -> Option<QueueJob> {
        let mut jobs = self.jobs.write().await;

        // Find first job whose rate limit allows processing
        for i in 0..jobs.len() {
            if self
                .rate_limiters
                .get(&jobs[i].api_type)
                .map(|b| b.try_acquire())
                .unwrap_or(true)
            {
                return jobs.remove(i);
            }
        }

        None
    }

    /// Mark a job as completed
    pub async fn complete(&self, mut job: QueueJob, result: serde_json::Value) {
        job.status = JobStatus::Completed { result };
        self.completed_jobs
            .write()
            .await
            .insert(job.id.clone(), job);
    }

    /// Mark a job as failed
    pub async fn fail(&self, mut job: QueueJob, error: String) {
        job.status = JobStatus::Failed { error };
        self.completed_jobs
            .write()
            .await
            .insert(job.id.clone(), job);
    }

    /// Get all jobs for a user
    pub async fn user_jobs(&self, user_id: &str) -> Vec<QueueJob> {
        let jobs = self.jobs.read().await;
        let completed = self.completed_jobs.read().await;

        let mut result: Vec<_> = jobs
            .iter()
            .filter(|j| j.user_id == user_id)
            .cloned()
            .collect();

        result.extend(completed.values().filter(|j| j.user_id == user_id).cloned());

        result
    }
}

impl Default for RequestQueue {
    fn default() -> Self {
        Self::new()
    }
}

// Global static queue
use std::sync::OnceLock;
static QUEUE: OnceLock<RequestQueue> = OnceLock::new();

/// Get the global request queue
pub fn get_queue() -> &'static RequestQueue {
    QUEUE.get_or_init(RequestQueue::new)
}

/// Queue status for API response
#[derive(Debug, Clone, Serialize)]
pub struct QueueStatusResponse {
    pub job_id: String,
    pub status: String,
    pub position: Option<usize>,
    pub eta_seconds: Option<u64>,
    pub result: Option<serde_json::Value>,
    pub error: Option<String>,
}

impl From<&QueueJob> for QueueStatusResponse {
    fn from(job: &QueueJob) -> Self {
        match &job.status {
            JobStatus::Queued { position } => Self {
                job_id: job.id.clone(),
                status: "queued".to_string(),
                position: Some(*position),
                eta_seconds: None, // Will be filled by route
                result: None,
                error: None,
            },
            JobStatus::Processing { .. } => Self {
                job_id: job.id.clone(),
                status: "processing".to_string(),
                position: None,
                eta_seconds: None,
                result: None,
                error: None,
            },
            JobStatus::Completed { result } => Self {
                job_id: job.id.clone(),
                status: "completed".to_string(),
                position: None,
                eta_seconds: None,
                result: Some(result.clone()),
                error: None,
            },
            JobStatus::Failed { error } => Self {
                job_id: job.id.clone(),
                status: "failed".to_string(),
                position: None,
                eta_seconds: None,
                result: None,
                error: Some(error.clone()),
            },
        }
    }
}

// =========== Background Worker ===========

use std::sync::atomic::AtomicBool;

static WORKER_RUNNING: AtomicBool = AtomicBool::new(false);

/// Start the background worker for processing queued jobs.
/// Should be called once at server startup.
pub fn start_worker() {
    if WORKER_RUNNING.swap(true, Ordering::SeqCst) {
        tracing::warn!("[Queue Worker] Already running, skipping start");
        return;
    }

    tokio::spawn(async move {
        tracing::info!("[Queue Worker] Started background job processor");

        loop {
            // Check queue every 500ms
            tokio::time::sleep(Duration::from_millis(500)).await;

            let queue = get_queue();

            // Try to pop a ready job
            if let Some(mut job) = queue.pop_ready().await {
                tracing::info!(
                    "[Queue Worker] Processing job {} ({:?})",
                    job.id,
                    job.job_type
                );

                // Mark as processing
                job.status = JobStatus::Processing {
                    started_at: TokenBucket::now_ms(),
                };

                // Process based on job type
                let result = process_job(&job).await;

                // Update job status
                match result {
                    Ok(value) => {
                        job.status = JobStatus::Completed { result: value };
                        tracing::info!("[Queue Worker] Completed job {}", job.id);
                    }
                    Err(e) => {
                        job.status = JobStatus::Failed { error: e };
                        tracing::error!("[Queue Worker] Failed job {}", job.id);
                    }
                }

                // Store in completed jobs
                queue.store_completed(job).await;
            }
        }
    });
}

/// Process a job based on its type
async fn process_job(job: &QueueJob) -> Result<serde_json::Value, String> {
    match &job.job_type {
        JobType::GenerateReport { tenant_id } => {
            // Placeholder - actual report generation would happen here
            // For now, return success with tenant info
            tokio::time::sleep(Duration::from_secs(1)).await; // Simulate work
            Ok(serde_json::json!({
                "status": "report_generation_queued",
                "tenant_id": tenant_id,
                "message": "Use /api/reports/generate directly with the cookie for full report"
            }))
        }
        JobType::SaveTemplate { template_name } => {
            // Template saving via GitHub storage
            tokio::time::sleep(Duration::from_millis(500)).await;
            Ok(serde_json::json!({
                "status": "template_saved",
                "name": template_name
            }))
        }
        JobType::LoadTemplate { template_id } => {
            // Template loading
            tokio::time::sleep(Duration::from_millis(200)).await;
            Ok(serde_json::json!({
                "status": "template_loaded",
                "id": template_id
            }))
        }
        JobType::ThreatHuntingSearch { query } => {
            // TH search placeholder
            tokio::time::sleep(Duration::from_secs(2)).await;
            Ok(serde_json::json!({
                "status": "search_complete",
                "query": query,
                "results_count": 0
            }))
        }
    }
}

/// Store a completed job for status lookup
impl RequestQueue {
    pub async fn store_completed(&self, job: QueueJob) {
        let mut completed = self.completed_jobs.write().await;
        completed.insert(job.id.clone(), job);

        // Keep only last 100 completed jobs
        if completed.len() > 100 {
            let oldest: Vec<String> = completed
                .iter()
                .take(completed.len() - 100)
                .map(|(k, _)| k.clone())
                .collect();
            for key in oldest {
                completed.remove(&key);
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_token_bucket_acquire() {
        let bucket = TokenBucket::new(5, 1, Duration::from_secs(1));

        // Should be able to acquire 5 tokens
        for _ in 0..5 {
            assert!(bucket.try_acquire());
        }

        // 6th should fail
        assert!(!bucket.try_acquire());
    }

    #[test]
    fn test_token_bucket_available() {
        let bucket = TokenBucket::new(10, 5, Duration::from_secs(1));
        assert_eq!(bucket.available(), 10);

        bucket.try_acquire();
        bucket.try_acquire();
        assert_eq!(bucket.available(), 8);
    }

    #[tokio::test]
    async fn test_queue_submit() {
        let queue = RequestQueue::new();

        let job = QueueJob::new(
            "user-1".to_string(),
            JobType::GenerateReport {
                tenant_id: "t1".to_string(),
            },
            ApiType::Axur,
        );

        let job_id = queue.submit(job).await;
        assert!(!job_id.is_empty());
        assert_eq!(queue.queue_length().await, 1);
    }
}

```
      ]]>
        </FILE>
        <FILE path="routes\admin.rs">
            <![CDATA[
```rs
//! Admin API - User Management for Beta Access Control
//!
//! Endpoints for managing the `allowed_users` whitelist.
//! Only admins (role = 'admin' in allowed_users) can use these endpoints.

use axum::{
    extract::{Path, State},
    response::IntoResponse,
    routing::{delete, get, post},
    Json, Router,
};
use axum_extra::extract::CookieJar;
use serde::{Deserialize, Serialize};

use crate::error::ApiError;
use crate::middleware::AUTH_USER_COOKIE_NAME;
use crate::routes::AppState;

// ========================
// TYPES
// ========================

#[derive(Debug, Serialize, Deserialize)]
pub struct BetaReq {
    pub id: String,
    pub email: String,
    pub company: String,
    pub status: String,
    pub requested_at: Option<chrono::DateTime<chrono::Utc>>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct AllowedUser {
    pub email: String,
    pub role: String,
    pub description: Option<String>,
    pub created_at: Option<String>,
    pub added_by: Option<String>,
}

#[derive(Debug, Deserialize)]
pub struct AddUserRequest {
    pub email: String,
    #[serde(default = "default_role")]
    pub role: String,
    pub description: Option<String>,
}

fn default_role() -> String {
    "beta_tester".to_string()
}

// ========================
// ROUTES
// ========================

/// Create admin user management routes
pub fn admin_routes() -> Router<AppState> {
    Router::new()
        .route("/users", get(list_users))
        .route("/users", post(add_user))
        .route("/users/:email", delete(remove_user))
        .route("/beta/requests", get(list_beta_requests))
        .route(
            "/beta/requests/pending-count",
            get(super::beta::get_pending_count),
        )
        // Unified action endpoint: POST /beta/requests/:email/action { "action": "approve"|"reject" }
        .route(
            "/beta/requests/:email/action",
            post(handle_beta_request_action),
        )
}

// ========================
// HANDLERS
// ========================

/// Check if the caller is an admin
/// Check if the caller is an admin
async fn require_admin(jar: &CookieJar) -> Result<String, ApiError> {
    let user_email = jar
        .get(AUTH_USER_COOKIE_NAME)
        .map(|c| c.value().to_string())
        .ok_or_else(|| ApiError::Unauthorized("Not logged in".into()))?;

    // Use GitHub storage for admin check
    if let Some(storage) = crate::github_storage::get_github_storage() {
        match storage.is_admin(&user_email).await {
            Ok(true) => return Ok(user_email),
            Ok(false) => return Err(ApiError::Forbidden("Admin access required".into())),
            Err(e) => {
                tracing::error!("GitHub storage admin check failed: {}", e);
                // Fallthrough to error
            }
        }
    } else {
        tracing::error!("GitHub storage not configured");
    }

    Err(ApiError::Internal("Admin check unavailable".into()))
}

/// List all allowed users
/// List all allowed users
async fn list_users(
    State(_state): State<AppState>,
    jar: CookieJar,
) -> Result<Json<Vec<AllowedUser>>, ApiError> {
    require_admin(&jar).await?;

    // Try Firestore first
    if let Some(firestore) = crate::firebase::get_firestore() {
        match firestore.list_docs::<AllowedUser>("allowed_users").await {
            Ok(users) => return Ok(Json(users)),
            Err(e) => tracing::error!("Firestore error listing users: {}", e),
        }
    }

    // Fallback: empty list (or error if we want strict)
    tracing::warn!("Firestore unavailable for list_users");
    Ok(Json(vec![]))
}

/// Add a new user to the allowed list (and GitHub storage)
async fn add_user(
    State(_state): State<AppState>,
    jar: CookieJar,
    Json(payload): Json<AddUserRequest>,
) -> Result<impl IntoResponse, ApiError> {
    let admin_email = require_admin(&jar).await?;

    // Validate email format
    if !payload.email.contains('@') {
        return Err(ApiError::BadRequest("Invalid email format".into()));
    }

    // Validate role
    let valid_roles = ["admin", "beta_tester"];
    if !valid_roles.contains(&payload.role.as_str()) {
        return Err(ApiError::BadRequest(format!(
            "Invalid role. Must be one of: {:?}",
            valid_roles
        )));
    }

    let email_lower = payload.email.to_lowercase();
    let doc_id = email_lower.replace("@", "_at_").replace(".", "_dot_");

    // Create user object
    let user = AllowedUser {
        email: email_lower.clone(),
        role: payload.role.clone(),
        description: payload.description.clone(),
        created_at: Some(chrono::Utc::now().to_rfc3339()),
        added_by: Some(admin_email.clone()),
    };

    // 1. Save to Firestore
    if let Some(firestore) = crate::firebase::get_firestore() {
        let doc_json =
            serde_json::to_value(&user).map_err(|e| ApiError::Internal(e.to_string()))?;
        if let Err(e) = firestore.set_doc("allowed_users", &doc_id, &doc_json).await {
            tracing::error!("Failed to add user to Firestore: {}", e);
            return Err(ApiError::Internal("Failed to save user".into()));
        }
    } else {
        return Err(ApiError::Internal("Storage not available".into()));
    }

    // 2. Also update GitHub storage if configured (for redundancy/CDN)
    if let Some(_storage) = crate::github_storage::get_github_storage() {
        // Implement logic to update allowed_users.json in GitHub if needed
        // For now, we rely on Firestore as primary source of truth for writes
        // and could implement a background sync or dual-write.
        // Assuming dual-write for now if method exists, otherwise skip.
        tracing::info!(
            "User added to Firestore. GitHub sync not yet implemented for individual users."
        );
    }

    Ok(Json(serde_json::json!({
        "success": true,
        "message": format!("User {} added with role {}", payload.email, payload.role)
    })))
}

/// Remove a user from the allowed list
async fn remove_user(
    State(_state): State<AppState>,
    jar: CookieJar,
    Path(email): Path<String>,
) -> Result<impl IntoResponse, ApiError> {
    let admin_email = require_admin(&jar).await?;

    // Prevent removing yourself
    if email.to_lowercase() == admin_email.to_lowercase() {
        return Err(ApiError::BadRequest("Cannot remove yourself".into()));
    }

    let email_lower = email.to_lowercase();
    let doc_id = email_lower.replace("@", "_at_").replace(".", "_dot_");

    // 1. Remove from Firestore
    if let Some(firestore) = crate::firebase::get_firestore() {
        if let Err(e) = firestore.delete_doc("allowed_users", &doc_id).await {
            tracing::error!("Failed to remove user from Firestore: {}", e);
            return Err(ApiError::Internal("Failed to remove user".into()));
        }
    } else {
        return Err(ApiError::Internal("Storage not available".into()));
    }

    // 2. Also remove from GitHub storage if configured
    if let Some(_storage) = crate::github_storage::get_github_storage() {
        // Implement logic to remove from allowed_users.json in GitHub if needed
        // For now, logging.
        tracing::info!("User removed from Firestore. GitHub sync not yet implemented.");
    }

    Ok(Json(serde_json::json!({
        "success": true,
        "message": format!("User {} removed", email)
    })))
}

/// List all beta requests
async fn list_beta_requests(
    State(_state): State<AppState>,
    jar: CookieJar,
) -> Result<Json<Vec<BetaReq>>, ApiError> {
    require_admin(&jar).await?;

    // Try Firestore first
    if let Some(firestore) = crate::firebase::get_firestore() {
        match firestore.list_docs::<BetaRequestDoc>("beta_requests").await {
            Ok(docs) => {
                let requests: Vec<BetaReq> = docs
                    .into_iter()
                    .map(|d| BetaReq {
                        id: d.email.clone(), // Use email as ID
                        email: d.email,
                        company: d.company.unwrap_or_default(),
                        status: d.status,
                        requested_at: d.requested_at.map(|t| {
                            chrono::DateTime::parse_from_rfc3339(&t)
                                .unwrap_or_default()
                                .with_timezone(&chrono::Utc)
                        }),
                    })
                    .collect();
                return Ok(Json(requests));
            }
            Err(e) => tracing::error!("Firestore error listing beta requests: {}", e),
        }
    }

    // Fallback
    tracing::warn!("Firestore unavailable for list_beta_requests");
    Ok(Json(vec![]))
}

// Helper structs for Firestore
#[derive(Debug, serde::Deserialize)]
struct BetaRequestDoc {
    email: String,
    company: Option<String>,
    status: String,
    requested_at: Option<String>,
}

/// Admin Action on Beta Request (Approve/Reject)
#[derive(Debug, serde::Deserialize)]
pub struct BetaActionRequest {
    pub action: String, // "approve" or "reject"
}

/// Handle beta request action (approve/reject)
/// Path param is the email (sanitized or raw, we'll handle it)
async fn handle_beta_request_action(
    State(_state): State<AppState>,
    jar: CookieJar,
    Path(email): Path<String>,
    Json(payload): Json<BetaActionRequest>,
) -> Result<impl IntoResponse, ApiError> {
    let admin_email = require_admin(&jar).await?;

    let email_lower = email.to_lowercase();
    let doc_id = email_lower.replace("@", "_at_").replace(".", "_dot_");

    if let Some(firestore) = crate::firebase::get_firestore() {
        if payload.action == "approve" {
            // 1. Add to allowed_users
            let user = AllowedUser {
                email: email_lower.clone(),
                role: "beta_tester".to_string(),
                description: Some("Approved from beta request".to_string()),
                created_at: Some(chrono::Utc::now().to_rfc3339()),
                added_by: Some(admin_email.clone()),
            };
            let doc_json =
                serde_json::to_value(&user).map_err(|e| ApiError::Internal(e.to_string()))?;
            firestore
                .set_doc("allowed_users", &doc_id, &doc_json)
                .await
                .map_err(|e| ApiError::Internal(e.to_string()))?;

            // 2. Update beta_requests status
            let update = serde_json::json!({ "status": "approved" });
            firestore
                .update_doc("beta_requests", &doc_id, &update)
                .await
                .map_err(|e| ApiError::Internal(e.to_string()))?;

            tracing::info!(admin = %admin_email, user = %email_lower, "Approved beta request");
        } else if payload.action == "reject" {
            // Update beta_requests status
            let update = serde_json::json!({ "status": "rejected" });
            firestore
                .update_doc("beta_requests", &doc_id, &update)
                .await
                .map_err(|e| ApiError::Internal(e.to_string()))?;

            tracing::info!(admin = %admin_email, user = %email_lower, "Rejected beta request");
        } else {
            return Err(ApiError::BadRequest(
                "Invalid action. Use 'approve' or 'reject'".into(),
            ));
        }
    } else {
        return Err(ApiError::Internal("Storage not available".into()));
    }

    Ok(Json(serde_json::json!({
        "success": true,
        "message": format!("Action {} completed for {}", payload.action, email_lower)
    })))
}

```
      ]]>
        </FILE>
        <FILE path="routes\admin_config.rs">
            <![CDATA[
```rs
//! Admin configuration management
//!
//! Checks admin access against the database.

use serde::{Deserialize, Serialize};

/// Admin configuration structure (kept for compatibility)
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct AdminConfig {
    /// List of email addresses with admin access to logs
    #[serde(default)]
    pub allowed_emails: Vec<String>,
}

/// Check if an email has admin access to logs
pub async fn has_log_access(email: &str) -> bool {
    let email_lower = email.to_lowercase();
    let doc_id = email_lower.replace("@", "_at_").replace(".", "_dot_");

    // Check Firestore "allowed_users"
    if let Some(firestore) = crate::firebase::get_firestore() {
        match firestore
            .get_doc::<serde_json::Value>("allowed_users", &doc_id)
            .await
        {
            Ok(Some(doc)) => {
                if let Some(role) = doc.get("role").and_then(|v| v.as_str()) {
                    return role == "admin";
                }
            }
            Ok(None) => {}
            Err(e) => {
                tracing::error!("Firestore error checking admin status: {}", e);
            }
        }
    }

    // Fallback? GitHub Storage?
    // admin.rs uses GitHub storage. We should probably use that too if configured.
    if let Some(storage) = crate::github_storage::get_github_storage() {
        match storage.is_admin(email).await {
            Ok(true) => return true,
            _ => {}
        }
    }

    false
}

/// Invalidate the admin config cache (No-op as we check DB directly now)
#[allow(dead_code)]
pub async fn invalidate_cache() {
    // No-op
}

// Deprecated functions kept to avoid breaking compilation if used elsewhere
#[allow(dead_code)]
pub async fn get_admin_config() -> AdminConfig {
    // Return empty or dummy config
    AdminConfig::default()
}

```
      ]]>
        </FILE>
        <FILE path="routes\auth.rs">
            <![CDATA[
```rs
//! Authentication routes - Proxy to Axur API
//!
//! Implements the 3-step login flow:
//! 1. POST /login - Email/password  temp token + correlation
//! 2. POST /2fa - 2FA code verification  
//! 3. POST /finalize - Get master token, set httpOnly cookie

use axum::{extract::State, response::IntoResponse, Json};
use axum_extra::extract::CookieJar;
use cookie::{Cookie, SameSite};
use serde::{Deserialize, Serialize};
use serde_json::json;

use crate::error::ApiError;
use crate::middleware::{AUTH_COOKIE_NAME, AUTH_USER_COOKIE_NAME};
use crate::routes::AppState;

// Axur API URL
const AXUR_API_URL: &str = "https://api.axur.com/gateway/1.0/api";

// ========================
// REQUEST/RESPONSE TYPES
// ========================

#[derive(Debug, Deserialize)]
pub struct LoginRequest {
    pub email: String,
    pub password: String,
}

#[derive(Debug, Deserialize)]
pub struct TwoFactorRequest {
    pub code: String,
    /// Temp token from login step
    pub token: String,
    /// Correlation token from login step
    pub correlation: Option<String>,
}

#[derive(Debug, Deserialize)]
pub struct FinalizeRequest {
    pub email: String,
    pub password: String,
    pub token: String,
    pub correlation: Option<String>,
    pub device_id: String,
}

#[derive(Debug, Serialize)]
pub struct LoginResponse {
    pub success: bool,
    pub requires_2fa: bool,
    pub token: Option<String>,
    pub correlation: Option<String>,
    pub message: String,
}

#[derive(Debug, Serialize)]
pub struct TwoFactorResponse {
    pub success: bool,
    pub token: Option<String>,
    pub correlation: Option<String>,
    pub device_id: Option<String>,
    pub message: String,
}

#[derive(Debug, Serialize)]
pub struct ValidateResponse {
    pub valid: bool,
    pub message: String,
    pub is_admin: bool,
    pub has_log_access: bool,
}

// Internal Axur API response
#[derive(Debug, Deserialize)]
struct AxurAuthResponse {
    correlation: Option<String>,
    token: Option<String>,
    #[serde(rename = "deviceId")]
    device_id: Option<String>,
}

// ========================
// ROUTE HANDLERS
// ========================

/// Step 1: Initial login with email/password
/// Returns temp token and correlation for 2FA step
pub async fn login(Json(payload): Json<LoginRequest>) -> Result<Json<LoginResponse>, ApiError> {
    // Validate input
    if payload.email.is_empty() || payload.password.is_empty() {
        return Err(ApiError::BadRequest("Email and password required".into()));
    }

    // Create HTTP client
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(30))
        .build()
        .map_err(|e| ApiError::Internal(e.to_string()))?;

    // Call Axur auth endpoint
    let url = format!("{}/identity/session", AXUR_API_URL);
    tracing::info!("Login: connecting to {}", url); // Log the authenticating URL
    let resp = client
        .post(&url)
        .json(&json!({
            "email": payload.email,
            "password": payload.password
        }))
        .send()
        .await?;

    // Read full body first
    let body_bytes = resp
        .bytes()
        .await
        .map_err(|e| ApiError::Internal(e.to_string()))?;
    let body_str = String::from_utf8_lossy(&body_bytes);

    // Re-parse from string
    let mut data: AxurAuthResponse = serde_json::from_str(&body_str)
        .map_err(|e| ApiError::Internal(format!("Failed to parse Axur response: {}", e)))?;

    // Helper to extract correlation from JWT if missing
    if data.correlation.is_none() {
        if let Some(token) = &data.token {
            // JWT format: header.payload.signature
            let parts: Vec<&str> = token.split('.').collect();
            if parts.len() >= 2 {
                // Decode payload (2nd part)
                // Use standard or URL-safe base64 decoding engine
                use base64::engine::general_purpose::URL_SAFE_NO_PAD;
                use base64::{engine::general_purpose::STANDARD_NO_PAD, Engine as _};

                // Try URL safe first, then standard
                let payload_res = URL_SAFE_NO_PAD
                    .decode(parts[1])
                    .or_else(|_| STANDARD_NO_PAD.decode(parts[1]));

                if let Ok(payload_bytes) = payload_res {
                    if let Ok(claims) = serde_json::from_slice::<serde_json::Value>(&payload_bytes)
                    {
                        if let Some(crl) = claims.get("crl").and_then(|v| v.as_str()) {
                            tracing::info!("Extracted check correlation ID from token: {}", crl);
                            data.correlation = Some(crl.to_string());
                        }
                    }
                }
            }
        }
    }

    Ok(Json(LoginResponse {
        success: true,
        requires_2fa: true, // Axur always requires 2FA
        token: data.token,
        correlation: data.correlation,
        message: "Credentials validated. Please complete 2FA.".into(),
    }))
}

/// Step 2: 2FA verification
pub async fn verify_2fa(
    Json(payload): Json<TwoFactorRequest>,
) -> Result<Json<TwoFactorResponse>, ApiError> {
    // Validate input
    if payload.code.is_empty() || payload.token.is_empty() {
        tracing::error!("Missing code or token.");
        return Err(ApiError::BadRequest("Code and token required".into()));
    }
    let code: u32 = payload
        .code
        .parse()
        .map_err(|_| ApiError::BadRequest("2FA code must be numeric".into()))?;

    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(30))
        .build()
        .map_err(|e| ApiError::Internal(e.to_string()))?;

    let url = format!("{}/identity/session/tfa", AXUR_API_URL);

    let mut req = client
        .post(&url)
        .header("Authorization", format!("Bearer {}", payload.token))
        .json(&json!({"code": code}));

    if let Some(ref corr) = payload.correlation {
        req = req.header("oxref-token", corr);
    }

    let resp = req.send().await?;

    if !resp.status().is_success() {
        let status = resp.status();
        let body = resp.text().await.unwrap_or_default();
        tracing::warn!("Axur 2FA failed: {} - {}", status, body);
        return Err(ApiError::Unauthorized("Invalid 2FA code".into()));
    }

    let data: AxurAuthResponse = resp
        .json()
        .await
        .map_err(|e| ApiError::Internal(format!("Failed to parse Axur response: {}", e)))?;

    Ok(Json(TwoFactorResponse {
        success: true,
        token: data.token,
        correlation: data.correlation,
        device_id: data.device_id,
        message: "2FA verified. Please finalize login.".into(),
    }))
}

/// Step 3: Finalize login and set httpOnly cookie
pub async fn finalize(
    State(_state): State<crate::routes::AppState>,
    jar: CookieJar,
    Json(payload): Json<FinalizeRequest>,
) -> Result<impl IntoResponse, ApiError> {
    // Validate input
    if payload.token.is_empty() || payload.device_id.is_empty() {
        return Err(ApiError::BadRequest("Token and device_id required".into()));
    }

    // ========================================
    // BETA ACCESS CONTROL: Check allowed_users in Firestore
    // ========================================
    let email_lower = payload.email.to_lowercase();
    let mut is_allowed = false;

    // Try Firestore first
    if let Some(firestore) = crate::firebase::get_firestore() {
        // Check allowed_users/{email} document
        let doc_id = email_lower.replace("@", "_at_").replace(".", "_dot_");
        match firestore
            .get_doc::<serde_json::Value>("allowed_users", &doc_id)
            .await
        {
            Ok(Some(_)) => {
                is_allowed = true;
                tracing::info!(email = %payload.email, "User authorized via Firestore allowed_users");
            }
            Ok(None) => {
                tracing::debug!(email = %payload.email, "User not found in Firestore allowed_users");
            }
            Err(e) => {
                tracing::warn!(
                    "Firestore allowed_users check failed: {} - trying GitHub storage",
                    e
                );
            }
        }
    }

    // Fallback to GitHub storage if not found in Firestore
    if !is_allowed {
        if let Some(storage) = crate::github_storage::get_github_storage() {
            match storage.is_user_allowed(&email_lower).await {
                Ok(allowed) => {
                    is_allowed = allowed;
                    if allowed {
                        tracing::info!(email = %payload.email, "User authorized via GitHub storage");
                    }
                }
                Err(e) => {
                    tracing::warn!("GitHub storage check failed: {}", e);
                }
            }
        }
    }

    if !is_allowed {
        tracing::warn!(
            email = %payload.email,
            "Login denied: user not in allowed_users"
        );
        return Err(ApiError::Forbidden(
            "Access denied. You are not part of the beta program. Contact admin to request access."
                .into(),
        ));
    }
    // ========================================

    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(30))
        .build()
        .map_err(|e| ApiError::Internal(e.to_string()))?;

    let url = format!("{}/identity/session", AXUR_API_URL);

    let mut req = client
        .post(&url)
        .header("Authorization", format!("Bearer {}", payload.token))
        .header("Device-Id", &payload.device_id)
        .json(&json!({
            "email": payload.email,
            "password": payload.password
        }));

    if let Some(ref corr) = payload.correlation {
        req = req.header("oxref-token", corr);
    }

    let resp = req.send().await?;

    if !resp.status().is_success() {
        let status = resp.status();
        let body = resp.text().await.unwrap_or_default();
        tracing::warn!("Axur finalize failed: {} - {}", status, body);
        return Err(ApiError::Unauthorized("Failed to finalize session".into()));
    }

    let data: AxurAuthResponse = resp
        .json()
        .await
        .map_err(|e| ApiError::Internal(format!("Failed to parse Axur response: {}", e)))?;

    let master_token = data
        .token
        .ok_or_else(|| ApiError::Internal("No master token received".into()))?;

    // Create httpOnly secure cookie (OWASP compliant)
    let cookie = Cookie::build((AUTH_COOKIE_NAME, master_token))
        .http_only(true)
        .secure(true) // Requires HTTPS in production
        .same_site(SameSite::None)
        .path("/")
        .max_age(cookie::time::Duration::days(7))
        .build();

    let user_cookie = Cookie::build((AUTH_USER_COOKIE_NAME, payload.email))
        .http_only(true)
        .secure(true)
        .same_site(SameSite::None)
        .path("/")
        .max_age(cookie::time::Duration::days(7))
        .build();

    let updated_jar = jar.add(cookie).add(user_cookie);

    Ok((
        updated_jar,
        Json(json!({
            "success": true,
            "message": "Login complete. Session established."
        })),
    ))
}

/// Validate current session
pub async fn validate(
    State(_state): State<AppState>,
    jar: CookieJar,
) -> Result<Json<ValidateResponse>, ApiError> {
    let token = match jar.get(AUTH_COOKIE_NAME) {
        Some(c) => c.value().to_string(),
        None => {
            return Ok(Json(ValidateResponse {
                valid: false,
                message: "No session found".into(),
                is_admin: false,
                has_log_access: false,
            }))
        }
    };

    // Check admin status from GitHub storage (replaces Leapcell DB)
    let mut is_admin = false;
    if let Some(user_cookie) = jar.get(AUTH_USER_COOKIE_NAME) {
        let email = user_cookie.value();

        // Use GitHub storage with ETag caching (0 TTL = always fresh)
        if let Some(storage) = crate::github_storage::get_github_storage() {
            match storage.is_admin(email).await {
                Ok(admin) => {
                    is_admin = admin;
                    tracing::debug!("GitHub storage: {} is_admin={}", email, admin);
                }
                Err(e) => {
                    tracing::warn!("GitHub storage check failed: {} - falling back to false", e);
                }
            }
        } else {
            tracing::warn!("GitHub storage not configured - admin check skipped");
        }
    }

    // Validate token with Axur API
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(10))
        .build()
        .map_err(|e| ApiError::Internal(e.to_string()))?;

    let url = format!("{}/customers/customers", AXUR_API_URL);
    let resp = client
        .get(&url)
        .header("Authorization", format!("Bearer {}", token))
        .send()
        .await?;

    // 200 or 403 means token is valid (403 = valid but no access to this resource)
    let is_valid = resp.status().is_success() || resp.status().as_u16() == 403;

    Ok(Json(ValidateResponse {
        valid: is_valid,
        message: if is_valid {
            "Session valid".into()
        } else {
            "Session expired".into()
        },

        is_admin,
        has_log_access: is_admin,
    }))
}

/// Logout - clear session cookie
pub async fn logout(jar: CookieJar) -> impl IntoResponse {
    // Create expired cookie to clear the session
    let cookie = Cookie::build((AUTH_COOKIE_NAME, ""))
        .http_only(true)
        .secure(true)
        .same_site(SameSite::None)
        .path("/")
        .max_age(cookie::time::Duration::seconds(0))
        .build();

    let user_cookie = Cookie::build((AUTH_USER_COOKIE_NAME, ""))
        .http_only(true)
        .secure(true)
        .same_site(SameSite::None)
        .path("/")
        .max_age(cookie::time::Duration::seconds(0))
        .build();

    let updated_jar = jar.add(cookie).add(user_cookie);

    (
        updated_jar,
        Json(json!({
            "success": true,
            "message": "Logged out successfully"
        })),
    )
}

```
      ]]>
        </FILE>
        <FILE path="routes\beta.rs">
            <![CDATA[
```rs
//! Beta Access Routes - Public Registration
//!
//! Handles public requests to join the beta program.

use axum::{extract::State, response::IntoResponse, Json};
use serde::{Deserialize, Serialize};

use crate::error::ApiError;
use crate::routes::AppState;

// ========================
// TYPES
// ========================

#[derive(Debug, Deserialize)]
pub struct BetaRequestPayload {
    pub email: String,
    pub company: String,
}

#[derive(Debug, Serialize)]
pub struct BetaRequestResponse {
    pub success: bool,
    pub message: String,
}

// ========================
// HANDLERS
// ========================

/// Submit a new beta access request
pub async fn submit_beta_request(
    State(_state): State<AppState>,
    Json(payload): Json<BetaRequestPayload>,
) -> Result<impl IntoResponse, ApiError> {
    // Validate inputs
    if payload.email.trim().is_empty() || payload.company.trim().is_empty() {
        return Err(ApiError::BadRequest(
            "Email and Company are required".into(),
        ));
    }

    if !payload.email.contains('@') {
        return Err(ApiError::BadRequest("Invalid email format".into()));
    }

    let email_lower = payload.email.to_lowercase();
    let doc_id = email_lower.replace("@", "_at_").replace(".", "_dot_");

    // Try Firestore
    if let Some(firestore) = crate::firebase::get_firestore() {
        // 1. Check if already in allowed_users
        match firestore
            .get_doc::<serde_json::Value>("allowed_users", &doc_id)
            .await
        {
            Ok(Some(_)) => {
                return Ok(Json(BetaRequestResponse {
                    success: true,
                    message: "You are already a registered beta user! Please log in.".into(),
                }));
            }
            _ => {}
        }

        // 2. Check if already requested
        match firestore
            .get_doc::<BetaRequestDoc>("beta_requests", &doc_id)
            .await
        {
            Ok(Some(req)) if req.status == "pending" => {
                return Ok(Json(BetaRequestResponse {
                    success: true,
                    message: "We already have your request! We'll allow access shortly.".into(),
                }));
            }
            _ => {}
        }

        // 3. Create new beta request
        let request_doc = serde_json::json!({
            "email": email_lower,
            "company": payload.company,
            "status": "pending",
            "requested_at": chrono::Utc::now().to_rfc3339()
        });

        match firestore
            .set_doc("beta_requests", &doc_id, &request_doc)
            .await
        {
            Ok(()) => {
                tracing::info!(email = %email_lower, company = %payload.company, "New beta request submitted to Firestore");
                return Ok(Json(BetaRequestResponse {
                    success: true,
                    message: "Request received! We will notify you when your access is ready."
                        .into(),
                }));
            }
            Err(e) => {
                tracing::error!("Failed to save beta request to Firestore: {}", e);
                return Err(ApiError::Internal(format!("Failed to save request: {}", e)));
            }
        }
    }

    // Fallback error if Firestore not configured
    Err(ApiError::Internal("Storage not available".into()))
}

pub async fn check_beta_status(
    State(_state): State<AppState>,
    axum::extract::Query(params): axum::extract::Query<std::collections::HashMap<String, String>>,
) -> Result<String, ApiError> {
    let email = params
        .get("email")
        .ok_or(ApiError::BadRequest("Email required".into()))?;

    let email_lower = email.to_lowercase();
    let doc_id = email_lower.replace("@", "_at_").replace(".", "_dot_");

    // Try Firestore
    if let Some(firestore) = crate::firebase::get_firestore() {
        // 1. Check allowed_users (Approved)
        match firestore
            .get_doc::<serde_json::Value>("allowed_users", &doc_id)
            .await
        {
            Ok(Some(_)) => return Ok("approved".to_string()),
            Err(e) => tracing::warn!("Firestore error checking allowed_users: {}", e),
            _ => {}
        }

        // 2. Check beta_requests (Pending/Rejected)
        match firestore
            .get_doc::<BetaRequestDoc>("beta_requests", &doc_id)
            .await
        {
            Ok(Some(req)) => return Ok(req.status),
            Err(e) => tracing::warn!("Firestore error checking beta_requests: {}", e),
            _ => {}
        }
    }

    // Fallback or Unknown
    Ok("unknown".to_string())
}

/// Get count of pending beta requests (for admin notification badge)
pub async fn get_pending_count(
    State(_state): State<AppState>,
) -> Result<impl IntoResponse, ApiError> {
    // Try Firestore first
    if let Some(firestore) = crate::firebase::get_firestore() {
        // List all beta_requests and count pending ones
        match firestore.list_docs::<BetaRequestDoc>("beta_requests").await {
            Ok(requests) => {
                let pending = requests.iter().filter(|r| r.status == "pending").count();
                return Ok(Json(serde_json::json!({
                    "count": pending,
                    "source": "firestore"
                })));
            }
            Err(e) => {
                tracing::warn!("Firestore error getting pending count: {}", e);
            }
        }
    }

    // Fallback: return 0
    Ok(Json(
        serde_json::json!({ "count": 0, "source": "fallback" }),
    ))
}

/// Helper struct for deserializing beta requests from Firestore
#[derive(Debug, serde::Deserialize)]
struct BetaRequestDoc {
    #[allow(dead_code)]
    email: Option<String>,
    #[allow(dead_code)]
    company: Option<String>,
    status: String,
}

```
      ]]>
        </FILE>
        <FILE path="routes\feedback.rs">
            <![CDATA[
```rs
use axum::{extract::Json, http::StatusCode, response::IntoResponse};
use serde::{Deserialize, Serialize};
use serde_json::json;
use std::env;
use uuid::Uuid;

#[derive(Debug, Deserialize)]
pub struct FeedbackRequest {
    pub message: String,
    pub screenshot: Option<String>, // Base64 data URI
    pub url: String,
    pub user_agent: String,
    pub tenant_id: Option<String>,
    pub user_email: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct FeedbackResponse {
    pub success: bool,
    pub issue_url: Option<String>,
    pub message: String,
}

pub async fn submit_feedback(Json(payload): Json<FeedbackRequest>) -> impl IntoResponse {
    match process_github_feedback(payload).await {
        Ok(issue_url) => (
            StatusCode::OK,
            Json(FeedbackResponse {
                success: true,
                issue_url: Some(issue_url),
                message: "Feedback submitted successfully".to_string(),
            }),
        ),
        Err(e) => {
            tracing::error!("Failed to submit feedback to GitHub: {}", e);
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(FeedbackResponse {
                    success: false,
                    issue_url: None,
                    message: format!("Failed to submit feedback: {}", e),
                }),
            )
        }
    }
}

async fn process_github_feedback(payload: FeedbackRequest) -> anyhow::Result<String> {
    // Check for both GH_* (production) and GITHUB_* (local dev) naming conventions
    let token = env::var("GH_PAT")
        .or_else(|_| env::var("GITHUB_TOKEN"))
        .map_err(|_| anyhow::anyhow!("GH_PAT or GITHUB_TOKEN not set"))?;
    let owner = env::var("GH_OWNER")
        .or_else(|_| env::var("GITHUB_OWNER"))
        .map_err(|_| anyhow::anyhow!("GH_OWNER or GITHUB_OWNER not set"))?;
    let repo = env::var("GH_REPO")
        .or_else(|_| env::var("GITHUB_REPO"))
        .map_err(|_| anyhow::anyhow!("GH_REPO or GITHUB_REPO not set"))?;

    let client = reqwest::Client::new();
    let headers = {
        let mut h = reqwest::header::HeaderMap::new();
        h.insert(
            "Authorization",
            reqwest::header::HeaderValue::from_str(&format!("Bearer {}", token))?,
        );
        h.insert(
            "User-Agent",
            reqwest::header::HeaderValue::from_static("axur-feedback-bot"),
        );
        h.insert(
            "Accept",
            reqwest::header::HeaderValue::from_static("application/vnd.github.v3+json"),
        );
        h
    };

    // 1. Upload Screenshot if present
    let mut image_url = None;
    if let Some(screenshot_data) = payload.screenshot {
        // Simple heuristic to strip data:image/png;base64,...
        if let Some(comma_pos) = screenshot_data.find(',') {
            let base64_content = &screenshot_data[comma_pos + 1..];
            let filename = format!("uploads/{}.png", Uuid::new_v4());

            let upload_url = format!(
                "https://api.github.com/repos/{}/{}/contents/{}",
                owner, repo, filename
            );

            // GitHub API for Create File
            let body = json!({
                "message": "Upload feedback screenshot",
                "content": base64_content, // GitHub expects base64 string
                "committer": {
                    "name": "Axur Feedback Bot",
                    "email": "bot@axur.com"
                }
            });

            let res = client
                .put(&upload_url)
                .headers(headers.clone())
                .json(&body)
                .send()
                .await?;

            if !res.status().is_success() {
                let err_text = res.text().await?;
                tracing::error!("Failed to upload image to GitHub: {}", err_text);
                // Continue without image or fail? Let's continue without image but log error.
            } else {
                // Construct raw URL for the image to display in markdown
                // For private repos, raw tokens are needed, but usually clicking the link in the issue works if authenticated?
                // Actually, for private repos, images in README/Issues need special handling or tokenized URLs.
                // However, linking to the blob UI page is safe.
                // Or linking to raw.githubusercontent?
                // Let's link to the blob page: https://github.com/OWNER/REPO/blob/main/uploads/FILENAME.png
                // We don't know the branch easily? Default is usually main/master.
                // Let's assume 'main' or try to parse response content html_url.
                let resp_json: serde_json::Value = res.json().await?;
                if let Some(content) = resp_json.get("content") {
                    if let Some(html_url) = content.get("html_url").and_then(|v| v.as_str()) {
                        // This is the blob URL (viewer)
                        // For embedding image directly in issue (![alt](url)), we need raw URL.
                        // But raw URL for private repo requires token.
                        // GitHub issues for private repos usually copy assets to user-attachments.
                        // Since we are uploading to repo content:
                        // Users with access to the repo CAN see the image if we link to the Blob UI.
                        // So we will create a link: [View Screenshot](html_url)
                        image_url = Some(html_url.to_string());
                    }
                }
            }
        }
    }

    // 2. Create Issue
    let title = format!(
        "Feedback Beta: {}",
        payload.message.chars().take(50).collect::<String>()
    );

    let mut body = format!(
        "### Feedback Recibido\n\n{}\n\n***\n**Detalles Tcnicos:**\n- **Usuario:** {}\n- **Tenant:** {}\n- **URL:** {}\n- **UA:** {}\n",
        payload.message,
        payload.user_email.as_deref().unwrap_or("Anon"),
        payload.tenant_id.as_deref().unwrap_or("N/A"),
        payload.url,
        payload.user_agent
    );

    if let Some(img) = image_url {
        // Convert blob URL to raw URL for display
        // Example: https://github.com/owner/repo/blob/main/path/to/img.png
        // Becomes: https://github.com/owner/repo/raw/main/path/to/img.png
        let raw_img = img.replace("/blob/", "/raw/");

        // Append image link
        body.push_str(&format!(
            "\n\n### Captura\n[![Screenshot]({})]({})",
            raw_img, img
        ));
        body.push_str("\n*(Click en la imagen para ver en tamao completo)*");
    }

    let issue_url = format!("https://api.github.com/repos/{}/{}/issues", owner, repo);
    let issue_body = json!({
        "title": title,
        "body": body,
        "labels": ["beta-feedback", "automated"]
    });

    let res = client
        .post(&issue_url)
        .headers(headers)
        .json(&issue_body)
        .send()
        .await?;

    if !res.status().is_success() {
        let err = res.text().await?;
        return Err(anyhow::anyhow!("GitHub API Error: {}", err));
    }

    let resp_json: serde_json::Value = res.json().await?;
    let created_issue_url = resp_json["html_url"].as_str().unwrap_or("").to_string();

    Ok(created_issue_url)
}

```
      ]]>
        </FILE>
        <FILE path="routes\import_export.rs">
            <![CDATA[
```rs
//! Import/Export routes for templates
//! Handles PPTX import and export functionality

use crate::injector::{inject_edits, SlideEdit};
use crate::routes::AppState;
use axum::extract::State;
use axum::Json;
use axum_extra::extract::Multipart;
use serde::Serialize;
use tracing;
use uuid;

#[derive(Serialize)]
pub struct ImportResponse {
    pub success: bool,
    pub slides: Vec<String>,
    pub message: String,
}

/// Upload PPTX to Google Drive, generate thumbnails via Slides API, and return data URLs.
/// Uses strict Rate Limiting (4 req/sec) to stay within Free Tier.
/// Images are downloaded to base64 data URLs to avoid 429 errors on frontend.
pub async fn import_pptx(
    State(state): State<AppState>,
    mut multipart: Multipart,
) -> Result<Json<ImportResponse>, (axum::http::StatusCode, String)> {
    let mut file_data = None;
    let mut file_name = String::from("presentation.pptx");

    while let Ok(Some(field)) = multipart.next_field().await {
        let name = field.name().unwrap_or("").to_string();
        if name == "file" {
            file_name = field.file_name().unwrap_or("presentation.pptx").to_string();
            if let Ok(bytes) = field.bytes().await {
                file_data = Some(bytes.to_vec());
            }
        }
    }

    let Some(data) = file_data else {
        return Err((
            axum::http::StatusCode::BAD_REQUEST,
            "No file uploaded".to_string(),
        ));
    };

    let services = state.google_services.ok_or((
        axum::http::StatusCode::SERVICE_UNAVAILABLE,
        "Google Services not configured (missing credentials)".to_string(),
    ))?;

    let uuid = uuid::Uuid::new_v4();
    let temp_name = format!("preview_{}_{}", uuid, file_name);

    // 1. Upload to Drive
    tracing::info!("Uploading to Google Drive: {}", temp_name);
    let file_id = services
        .upload_pptx(&temp_name, data)
        .await
        .map_err(|e| (axum::http::StatusCode::INTERNAL_SERVER_ERROR, e))?;

    // 2. Generate Previews (Rate Limited) - get Google content URLs
    tracing::info!("Generating previews for file ID: {}", file_id);
    let google_urls = services
        .generate_previews(&file_id)
        .await
        .map_err(|e| (axum::http::StatusCode::INTERNAL_SERVER_ERROR, e))?;

    // 3. Download images as base64 to avoid 429 on frontend
    // Uses Retry-After header handling for proper rate limiting
    tracing::info!("Downloading {} images as base64...", google_urls.len());
    let data_urls = services
        .fetch_images_as_base64(google_urls)
        .await
        .map_err(|e| {
            // Attempt cleanup on error
            let services_clone = services.clone();
            let file_id_clone = file_id.clone();
            tokio::spawn(async move {
                let _ = services_clone.delete_file(&file_id_clone).await;
            });
            (axum::http::StatusCode::INTERNAL_SERVER_ERROR, e)
        })?;

    // 4. Cleanup
    tracing::info!("Cleaning up file from Drive: {}", file_id);
    let _ = services.delete_file(&file_id).await;

    Ok(Json(ImportResponse {
        success: true,
        slides: data_urls, // Now returns base64 data URLs instead of Google URLs
        message: "Successfully generated previews with embedded images".to_string(),
    }))
}

/// Inject placeholders into PPTX and download
pub async fn inject_pptx(
    mut multipart: Multipart,
) -> Result<impl axum::response::IntoResponse, (axum::http::StatusCode, String)> {
    let mut file_data = None;
    let mut file_name = String::from("presentation.pptx");
    let mut edits = Vec::new();

    while let Ok(Some(field)) = multipart.next_field().await {
        let name = field.name().unwrap_or("").to_string();

        if name == "file" {
            file_name = field.file_name().unwrap_or("presentation.pptx").to_string();
            if let Ok(bytes) = field.bytes().await {
                file_data = Some(bytes.to_vec());
            }
        } else if name == "edits" {
            if let Ok(text) = field.text().await {
                if let Ok(parsed_edits) = serde_json::from_str::<Vec<SlideEdit>>(&text) {
                    edits = parsed_edits;
                } else {
                    return Err((
                        axum::http::StatusCode::BAD_REQUEST,
                        "Invalid JSON in 'edits' field".to_string(),
                    ));
                }
            }
        }
    }

    let Some(data) = file_data else {
        return Err((
            axum::http::StatusCode::BAD_REQUEST,
            "No file uploaded".to_string(),
        ));
    };

    match inject_edits(&data, edits) {
        Ok(modified_bytes) => {
            let filename_header = format!("attachment; filename=\"injected_{}\"", file_name);

            // We need to return the header string OWNED or use a builder
            let mut res = axum::response::Response::new(axum::body::Body::from(modified_bytes));
            res.headers_mut().insert(
                axum::http::header::CONTENT_TYPE,
                axum::http::HeaderValue::from_static(
                    "application/vnd.openxmlformats-officedocument.presentationml.presentation",
                ),
            );
            res.headers_mut().insert(
                axum::http::header::CONTENT_DISPOSITION,
                axum::http::HeaderValue::from_str(&filename_header).unwrap(),
            );

            Ok(res)
        }
        Err(e) => Err((
            axum::http::StatusCode::INTERNAL_SERVER_ERROR,
            format!("Injection failed: {}", e),
        )),
    }
}

// =================================================================
// GOOGLE SLIDES EXPORT
// =================================================================

use crate::google_services::SlideData;
use serde::Deserialize;

/// Request to export slides to Google Slides
#[derive(Deserialize)]
pub struct ExportSlidesRequest {
    /// Title for the new presentation
    pub title: String,
    /// Array of slide data (title + body content)
    pub slides: Vec<ExportSlideData>,
}

#[derive(Deserialize)]
pub struct ExportSlideData {
    pub title: String,
    pub body: Vec<String>,
    pub layout: Option<String>,
}

/// Response from export_to_slides
#[derive(Serialize)]
pub struct ExportSlidesResponse {
    pub success: bool,
    pub presentation_id: String,
    pub presentation_url: String,
    pub slides_count: usize,
    pub message: String,
}

/// Export slides to Google Slides presentation
///
/// Creates a new Google Slides presentation and populates it with the provided slides.
/// Uses rate limiting (1s delay between API calls) to stay within free tier.
///
/// POST /api/export/slides
pub async fn export_to_slides(
    State(state): State<AppState>,
    Json(request): Json<ExportSlidesRequest>,
) -> Result<Json<ExportSlidesResponse>, (axum::http::StatusCode, String)> {
    let services = state.google_services.ok_or((
        axum::http::StatusCode::SERVICE_UNAVAILABLE,
        "Google Services not configured (missing credentials)".to_string(),
    ))?;

    tracing::info!(
        "Creating Google Slides presentation: {} ({} slides)",
        request.title,
        request.slides.len()
    );

    // 1. Create new presentation
    let presentation_id = services
        .create_presentation(&request.title)
        .await
        .map_err(|e| (axum::http::StatusCode::INTERNAL_SERVER_ERROR, e))?;

    tracing::info!("Created presentation: {}", presentation_id);

    // 2. Convert to SlideData format
    let slide_data: Vec<SlideData> = request
        .slides
        .into_iter()
        .map(|s| SlideData {
            title: s.title,
            body: s.body,
            layout: s.layout,
        })
        .collect();

    // 3. Add slides to presentation
    if !slide_data.is_empty() {
        services
            .add_slides_batch(&presentation_id, &slide_data)
            .await
            .map_err(|e| (axum::http::StatusCode::INTERNAL_SERVER_ERROR, e))?;
    }

    // 4. Get presentation URL
    let presentation_url = services.get_presentation_url(&presentation_id);
    let slides_count = slide_data.len();

    tracing::info!("Export complete: {}", presentation_url);

    Ok(Json(ExportSlidesResponse {
        success: true,
        presentation_id,
        presentation_url,
        slides_count,
        message: format!(
            "Successfully exported {} slides to Google Slides",
            slides_count
        ),
    }))
}

// =================================================================
// PPTX GENERATION WITH REAL DATA
// =================================================================

use std::collections::HashMap;

/// Request to generate PPTX with real report data
#[derive(Deserialize)]
#[allow(dead_code)]
pub struct GeneratePptxRequest {
    /// Placeholder edits from the template (with placeholder_key)
    pub edits: Vec<SlideEdit>,
    /// Pre-mapped placeholder values (key -> value)
    pub placeholder_values: HashMap<String, String>,
}

/// Response for PPTX generation
#[derive(Serialize)]
pub struct GeneratePptxResponse {
    pub success: bool,
    pub message: String,
    /// Base64 encoded PPTX file
    pub pptx_base64: Option<String>,
}

/// Generate PPTX with real data from report
///
/// Takes: PPTX file + template edits + placeholder_values (already mapped)
/// Returns: Modified PPTX with placeholder values replaced by real data
pub async fn generate_pptx_report(
    mut multipart: Multipart,
) -> Result<impl axum::response::IntoResponse, (axum::http::StatusCode, String)> {
    let mut file_data = None;
    let mut file_name = String::from("report.pptx");
    let mut edits: Vec<SlideEdit> = Vec::new();
    let mut placeholder_values: HashMap<String, String> = HashMap::new();

    while let Ok(Some(field)) = multipart.next_field().await {
        let name = field.name().unwrap_or("").to_string();

        if name == "file" {
            file_name = field.file_name().unwrap_or("report.pptx").to_string();
            if let Ok(bytes) = field.bytes().await {
                file_data = Some(bytes.to_vec());
            }
        } else if name == "edits" {
            if let Ok(text) = field.text().await {
                if let Ok(parsed_edits) = serde_json::from_str::<Vec<SlideEdit>>(&text) {
                    edits = parsed_edits;
                }
            }
        } else if name == "placeholder_values" {
            if let Ok(text) = field.text().await {
                if let Ok(parsed_values) = serde_json::from_str::<HashMap<String, String>>(&text) {
                    placeholder_values = parsed_values;
                }
            }
        }
    }

    let Some(data) = file_data else {
        return Err((
            axum::http::StatusCode::BAD_REQUEST,
            "No PPTX file uploaded".to_string(),
        ));
    };

    if placeholder_values.is_empty() {
        return Err((
            axum::http::StatusCode::BAD_REQUEST,
            "No placeholder_values provided".to_string(),
        ));
    }

    // Replace placeholder text with real values
    let resolved_edits: Vec<SlideEdit> = edits
        .into_iter()
        .map(|mut edit| {
            if let Some(key) = &edit.placeholder_key {
                if let Some(real_value) = placeholder_values.get(key) {
                    edit.text = real_value.clone();
                }
            }
            edit
        })
        .collect();

    tracing::info!(
        "Generating PPTX report: {} edits mapped from {} placeholder values",
        resolved_edits.len(),
        placeholder_values.len()
    );

    match inject_edits(&data, resolved_edits) {
        Ok(modified_bytes) => {
            // Return as base64 for easier handling
            let base64_pptx =
                base64::Engine::encode(&base64::engine::general_purpose::STANDARD, &modified_bytes);

            Ok(Json(GeneratePptxResponse {
                success: true,
                message: format!("Generated PPTX report: {}", file_name),
                pptx_base64: Some(base64_pptx),
            }))
        }
        Err(e) => Err((
            axum::http::StatusCode::INTERNAL_SERVER_ERROR,
            format!("PPTX generation failed: {}", e),
        )),
    }
}

```
      ]]>
        </FILE>
        <FILE path="routes\logs_api.rs">
            <![CDATA[
```rs
//! Logs API - Fetch and list logs from Firestore (Hybrid)
//!
//! - Provides endpoints to browse and search logs.
//! - Fetches metadata from Firestore (Daily sharding) and content from GitHub if truncated.

use axum::{
    extract::{Path, Query},
    http::StatusCode,
    response::IntoResponse,
    Json,
};
use serde::{Deserialize, Serialize};

use super::admin_config;
use super::remote_log::RemoteLogConfig;
use base64::{engine::general_purpose::STANDARD as BASE64, Engine as _};
use chrono::{DateTime, Duration, Utc};

/// Query parameters for listing logs
#[derive(Debug, Deserialize)]
pub struct ListLogsQuery {
    /// Date filter in YYYY-MM-DD format
    pub date: Option<String>,
    /// Category filter
    pub category: Option<String>,
    /// Maximum number of results
    pub limit: Option<i64>,
    /// Offset for pagination
    pub offset: Option<i64>,
}

/// Log file entry in the list
#[derive(Debug, Serialize, Deserialize)]
pub struct LogEntry {
    pub id: String,
    pub timestamp: String,
    pub category: String,
    pub message: String,
    #[serde(default)]
    pub content: String,
    #[serde(default)]
    pub github_path: Option<String>,
}

/// Response for listing logs
#[derive(Debug, Serialize)]
pub struct ListLogsResponse {
    pub success: bool,
    pub files: Vec<LogEntryInternal>,
    pub total: i64,
    pub message: String,
}

#[derive(Debug, Serialize)]
pub struct LogEntryInternal {
    pub name: String, // timestamp + category
    pub path: String, // ID
    pub size: u64,
    pub sha: String, // ID
    pub download_url: Option<String>,
}

/// Response for getting log content
#[derive(Debug, Serialize)]
pub struct LogContentResponse {
    pub success: bool,
    pub filename: String,
    pub content: String,
    pub size: u64,
}

#[derive(Debug, Serialize)]
pub struct DailyStats {
    pub date: String,
    pub reports: i64,
    pub errors: i64,
    pub th_queries: i64,
    pub total: i64,
}

#[derive(Debug, Serialize)]
pub struct StatsResponse {
    pub success: bool,
    pub period: String,
    pub total_reports: i64,
    pub total_errors: i64,
    pub daily_stats: Vec<DailyStats>,
    pub message: String,
}

/// List available log files
/// GET /api/logs
pub async fn list_logs(Query(params): Query<ListLogsQuery>) -> impl IntoResponse {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::SERVICE_UNAVAILABLE,
                Json(ListLogsResponse {
                    success: false,
                    files: vec![],
                    total: 0,
                    message: "Firestore not available".to_string(),
                }),
            )
        }
    };

    let limit = params.limit.unwrap_or(50) as usize;
    let offset = params.offset.unwrap_or(0) as usize;

    // Build date range
    let date_str = params
        .date
        .unwrap_or_else(|| Utc::now().format("%Y-%m-%d").to_string());

    // Sharding path: system_logs/{date}/entries
    let path = format!("system_logs/{}/entries", date_str);

    // Fetch logs from Firestore
    let logs_res = firestore.list_docs::<LogEntry>(&path).await;

    match logs_res {
        Ok(mut logs) => {
            // Filter by category if needed
            if let Some(cat) = &params.category {
                logs.retain(|l| &l.category == cat);
            }

            // Sort by timestamp DESC
            logs.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));

            let total = logs.len() as i64;

            // Pagination
            let logs_page: Vec<LogEntry> = logs.into_iter().skip(offset).take(limit).collect();

            let files: Vec<LogEntryInternal> = logs_page
                .into_iter()
                .map(|row| {
                    let ts = DateTime::parse_from_rfc3339(&row.timestamp)
                        .map(|dt| dt.format("%H:%M:%S").to_string())
                        .unwrap_or_else(|_| row.timestamp.clone());

                    LogEntryInternal {
                        name: format!("{} - {}", ts, row.message),
                        path: row.id.clone(),
                        size: 0, // Unknown size without content
                        sha: row.id.clone(),
                        download_url: None,
                    }
                })
                .collect();

            (
                StatusCode::OK,
                Json(ListLogsResponse {
                    success: true,
                    files,
                    total,
                    message: "OK".to_string(),
                }),
            )
        }
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(ListLogsResponse {
                success: false,
                files: vec![],
                total: 0,
                message: format!("Firestore error: {}", e),
            }),
        ),
    }
}

/// Helper to fetch content from GitHub
async fn fetch_from_github(path: &str) -> Option<String> {
    let config = RemoteLogConfig::from_env()?;
    let client = reqwest::Client::new();
    let url = format!(
        "https://api.github.com/repos/{}/{}/contents/{}",
        config.owner, config.repo, path
    );

    let res = client
        .get(&url)
        .header("Authorization", format!("Bearer {}", config.token))
        .header("User-Agent", "axur-log-viewer")
        .header("Accept", "application/vnd.github.v3+json")
        .send()
        .await
        .ok()?;

    if !res.status().is_success() {
        return None;
    }

    let file_info: serde_json::Value = res.json().await.ok()?;

    let encoded = file_info.get("content").and_then(|c| c.as_str())?;
    let clean = encoded.replace('\n', "");

    match BASE64.decode(&clean) {
        Ok(bytes) => Some(String::from_utf8_lossy(&bytes).to_string()),
        Err(_) => None,
    }
}

/// Get specific log file content
/// GET /api/logs/content/*path
pub async fn get_log_content(Path(id_str): Path<String>) -> impl IntoResponse {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::SERVICE_UNAVAILABLE,
                Json(LogContentResponse {
                    success: false,
                    filename: String::new(),
                    content: "Firestore not available".to_string(),
                    size: 0,
                }),
            )
        }
    };

    // Extract date from ID: YYYY-MM-DD_UUID
    let parts: Vec<&str> = id_str.splitn(2, '_').collect();
    if parts.len() != 2 {
        return (
            StatusCode::BAD_REQUEST,
            Json(LogContentResponse {
                success: false,
                filename: String::new(),
                content: "Invalid ID format (missing date prefix)".to_string(),
                size: 0,
            }),
        );
    }
    let date_str = parts[0];
    let path = format!("system_logs/{}/entries", date_str);

    let res = firestore.get_doc::<LogEntry>(&path, &id_str).await;

    match res {
        Ok(Some(mut row)) => {
            // Check if content is truncated/missing
            let is_truncated = row.content.contains("... (truncated");

            if (row.content.is_empty() || is_truncated) && row.github_path.is_some() {
                if let Some(gh_path) = row.github_path {
                    if let Some(full_content) = fetch_from_github(&gh_path).await {
                        row.content = full_content;
                    }
                }
            }

            (
                StatusCode::OK,
                Json(LogContentResponse {
                    success: true,
                    filename: row.message,
                    content: row.content.clone(),
                    size: row.content.len() as u64,
                }),
            )
        }
        Ok(None) => (
            StatusCode::NOT_FOUND,
            Json(LogContentResponse {
                success: false,
                filename: String::new(),
                content: "Log not found".to_string(),
                size: 0,
            }),
        ),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(LogContentResponse {
                success: false,
                filename: String::new(),
                content: format!("Firestore error: {}", e),
                size: 0,
            }),
        ),
    }
}

/// List available dates with logs
/// GET /api/logs/dates
pub async fn list_log_dates() -> impl IntoResponse {
    // For now, let's just return current year structure to match frontend expectations
    let years = vec!["2024".to_string(), "2025".to_string()];

    (
        StatusCode::OK,
        Json(serde_json::json!({
            "success": true,
            "years": years,
            "message": "OK"
        })),
    )
}

/// List categories for a specific date
/// GET /api/logs/categories?date=YYYY/MM/DD
pub async fn list_log_categories(Query(params): Query<ListLogsQuery>) -> impl IntoResponse {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::SERVICE_UNAVAILABLE,
                Json(serde_json::json!({
                    "success": false,
                    "categories": [],
                    "message": "Firestore not available"
                })),
            )
        }
    };

    let date_str = params
        .date
        .unwrap_or_else(|| Utc::now().format("%Y-%m-%d").to_string());

    let path = format!("system_logs/{}/entries", date_str);

    // Efficiently, we should just list and collect distinct categories.
    // Since we fetch all metadata for a day anyway (usually < 100 logs?), this is fine.
    match firestore.list_docs::<LogEntry>(&path).await {
        Ok(logs) => {
            let mut categories: Vec<String> = logs.into_iter().map(|l| l.category).collect();
            categories.sort();
            categories.dedup();

            (
                StatusCode::OK,
                Json(serde_json::json!({
                    "success": true,
                    "categories": categories,
                    "date": date_str,
                    "message": "OK"
                })),
            )
        }
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({
                "success": false,
                "categories": [],
                "message": format!("Firestore error: {}", e)
            })),
        ),
    }
}

/// Query parameters for access check
#[derive(Debug, Deserialize)]
pub struct AccessCheckQuery {
    pub email: String,
}

/// Response for access check
#[derive(Debug, Serialize)]
pub struct AccessCheckResponse {
    pub has_access: bool,
    pub message: String,
}

/// Check if user has access to logs
/// GET /api/logs/access?email=user@example.com
pub async fn check_log_access(Query(params): Query<AccessCheckQuery>) -> impl IntoResponse {
    let has_access = admin_config::has_log_access(&params.email).await;

    (
        StatusCode::OK,
        Json(AccessCheckResponse {
            has_access,
            message: if has_access {
                "Access granted".to_string()
            } else {
                "Access denied - not in admin list".to_string()
            },
        }),
    )
}

/// Get analytics stats for the dashboard (last N days)
/// GET /api/logs/stats?days=7
#[derive(Deserialize)]
pub struct StatsQuery {
    pub days: Option<i64>,
}

pub async fn get_log_stats(Query(params): Query<StatsQuery>) -> impl IntoResponse {
    let days = params.days.unwrap_or(7);
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::SERVICE_UNAVAILABLE,
                Json(StatsResponse {
                    success: false,
                    period: format!("{}d", days),
                    total_reports: 0,
                    total_errors: 0,
                    daily_stats: vec![],
                    message: "Firestore not available".to_string(),
                }),
            )
        }
    };

    let mut daily_stats = Vec::new();
    let mut total_reports = 0;
    let mut total_errors = 0;

    // Parallel fetch for last N days? Or sequential to be nice to rate limit?
    // Sequential for safety. 7 days = 7 writes/reads. 2000 reads/hour limit.
    // 7 reads is fine.

    for i in (0..days).rev() {
        let d = Utc::now() - Duration::days(i);
        let date_str = d.format("%Y-%m-%d").to_string();
        let path = format!("system_logs/{}/entries", date_str);

        let mut stats = DailyStats {
            date: date_str.clone(),
            reports: 0,
            errors: 0,
            th_queries: 0,
            total: 0,
        };

        if let Ok(logs) = firestore.list_docs::<LogEntry>(&path).await {
            stats.total = logs.len() as i64;
            for log in logs {
                if log.category.contains("report") {
                    stats.reports += 1;
                    total_reports += 1;
                } else if log.category.contains("error") {
                    stats.errors += 1;
                    total_errors += 1;
                } else if log.category.contains("threat") {
                    stats.th_queries += 1;
                }
            }
        }

        daily_stats.push(stats);
    }

    (
        StatusCode::OK,
        Json(StatsResponse {
            success: true,
            period: format!("{}d", days),
            total_reports,
            total_errors,
            daily_stats,
            message: "OK".to_string(),
        }),
    )
}

```
      ]]>
        </FILE>
        <FILE path="routes\marketplace.rs">
            <![CDATA[
```rs
//! Marketplace API routes (Firestore)
//!
//! Browse, download, and rate published templates

use axum::{
    extract::{Path, Query, State},
    http::StatusCode,
    response::IntoResponse,
    Extension, Json,
};
use serde::{Deserialize, Serialize};

use crate::routes::AppState;

// ==================== TYPES ====================

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct MarketplaceTemplate {
    pub id: String,
    pub template_id: String,
    pub name: String,
    pub description: Option<String>,
    pub author_name: Option<String>,
    pub downloads: i32,
    pub rating: f64,
    pub rating_count: i32,
    pub featured: bool,
    pub approved: bool,
    pub published_at: String,
    pub author_id: String,
}

#[derive(Debug, Deserialize)]
pub struct MarketplaceQuery {
    pub limit: Option<i32>,
    pub offset: Option<i32>,
    pub featured: Option<bool>,
}

#[derive(Debug, Deserialize)]
pub struct RateTemplateRequest {
    pub rating: i32,
}

#[derive(Debug, Serialize)]
pub struct MarketplaceResponse {
    pub success: bool,
    pub message: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub template_id: Option<String>,
}

// ==================== PUBLIC ENDPOINTS ====================

/// GET /api/marketplace - Browse approved templates
pub async fn list_marketplace(
    State(_state): State<AppState>,
    Query(params): Query<MarketplaceQuery>,
) -> impl IntoResponse {
    let limit = params.limit.unwrap_or(20).min(50) as usize;
    let offset = params.offset.unwrap_or(0) as usize;
    let featured_only = params.featured.unwrap_or(false);

    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            // Fallback mock data
            return fallback_mock_response();
        }
    };

    // Fetch all approved templates
    // Optimization: In real app, we'd use Firestore query/index.
    // Here we fetch all and filter in memory since dataset is expected to be small (<100).
    match firestore
        .list_docs::<MarketplaceTemplate>("marketplace_templates")
        .await
    {
        Ok(all_docs) => {
            let mut filtered: Vec<MarketplaceTemplate> = all_docs
                .into_iter()
                .filter(|t| t.approved && (!featured_only || t.featured))
                .collect();

            // Sort by downloads desc
            filtered.sort_by(|a, b| b.downloads.cmp(&a.downloads));

            // Pagination
            let total = filtered.len();
            let paged: Vec<MarketplaceTemplate> =
                filtered.into_iter().skip(offset).take(limit).collect();

            (
                StatusCode::OK,
                Json(serde_json::json!({
                    "success": true,
                    "templates": paged,
                    "total": total
                })),
            )
        }
        Err(_) => fallback_mock_response(),
    }
}

fn fallback_mock_response() -> (StatusCode, Json<serde_json::Value>) {
    let mock_templates = vec![
        MarketplaceTemplate {
            id: "1".to_string(),
            template_id: "1".to_string(),
            name: "Executive Summary".to_string(),
            description: Some("A concise template for executive presentations.".to_string()),
            author_name: Some("Axur".to_string()),
            downloads: 1250,
            rating: 4.8,
            rating_count: 100,
            featured: true,
            approved: true,
            published_at: "2024-01-01".to_string(),
            author_id: "system".to_string(),
        },
        MarketplaceTemplate {
            id: "2".to_string(),
            template_id: "2".to_string(),
            name: "Technical Deep Dive".to_string(),
            description: Some("Detailed technical analysis for security teams.".to_string()),
            author_name: Some("Community".to_string()),
            downloads: 342,
            rating: 4.5,
            rating_count: 50,
            featured: false,
            approved: true,
            published_at: "2024-02-15".to_string(),
            author_id: "community_user_1".to_string(),
        },
        MarketplaceTemplate {
            id: "3".to_string(),
            template_id: "3".to_string(),
            name: "Risk Focus".to_string(),
            description: Some("Highlights risk scores and critical metrics.".to_string()),
            author_name: Some("Community".to_string()),
            downloads: 189,
            rating: 4.2,
            rating_count: 30,
            featured: false,
            approved: true,
            published_at: "2024-03-10".to_string(),
            author_id: "community_user_2".to_string(),
        },
        MarketplaceTemplate {
            id: "5".to_string(),
            template_id: "5".to_string(),
            name: "Compliance Report".to_string(),
            description: Some("Formatted for regulatory compliance requirements.".to_string()),
            author_name: Some("Axur Compliance".to_string()),
            downloads: 98,
            rating: 4.0,
            rating_count: 20,
            featured: false,
            approved: true,
            published_at: "2024-04-05".to_string(),
            author_id: "axur_compliance_team".to_string(),
        },
    ];

    (
        StatusCode::OK,
        Json(serde_json::json!({
            "success": true,
            "message": "Loaded mock templates (Fallback)",
            "templates": mock_templates,
            "total": mock_templates.len()
        })),
    )
}

// ==================== PROTECTED ENDPOINTS ====================

/// POST /api/templates/:id/publish
pub async fn publish_template(
    State(_state): State<AppState>,
    Extension(user_id): Extension<String>,
    Path(template_id): Path<String>,
) -> impl IntoResponse {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(MarketplaceResponse {
                    success: false,
                    message: "Storage not available".to_string(),
                    template_id: None,
                }),
            );
        }
    };

    // 1. Fetch user template metadata to get name/description
    // Path: user_templates/{user_id}/items/{template_id}
    let template_meta: serde_json::Value = match firestore
        .get_doc(&format!("user_templates/{}/items", user_id), &template_id)
        .await
    {
        Ok(Some(doc)) => doc,
        Ok(None) => {
            return (
                StatusCode::NOT_FOUND,
                Json(MarketplaceResponse {
                    success: false,
                    message: "Template not found".to_string(),
                    template_id: None,
                }),
            );
        }
        Err(e) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(MarketplaceResponse {
                    success: false,
                    message: e.to_string(),
                    template_id: None,
                }),
            );
        }
    };

    // 2. Check if already published (by template_id)
    // We need to search marketplace_templates where template_id == X
    // Inefficient without index.
    // For now, we'll use a deterministic ID for marketplace entry: "publish_{template_id}"
    // This enforces 1:1 mapping.
    let marketplace_id = format!("pub_{}", template_id);

    if let Ok(Some(_)) = firestore
        .get_doc::<serde_json::Value>("marketplace_templates", &marketplace_id)
        .await
    {
        return (
            StatusCode::CONFLICT,
            Json(MarketplaceResponse {
                success: false,
                message: "Already published".to_string(),
                template_id: Some(template_id),
            }),
        );
    }

    // 3. Create Marketplace Entry
    let entry = MarketplaceTemplate {
        id: marketplace_id.clone(),
        template_id: template_id.clone(),
        name: template_meta
            .get("name")
            .and_then(|v| v.as_str())
            .unwrap_or("Untitled")
            .to_string(),
        description: template_meta
            .get("description")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string()),
        author_name: Some("User".to_string()), // Placeholder as we don't have user profiles
        downloads: 0,
        rating: 0.0,
        rating_count: 0,
        featured: false,
        approved: false, // Requires admin approval
        published_at: chrono::Utc::now().to_rfc3339(),
        author_id: user_id,
    };

    match firestore
        .set_doc("marketplace_templates", &marketplace_id, &entry)
        .await
    {
        Ok(_) => (
            StatusCode::CREATED,
            Json(MarketplaceResponse {
                success: true,
                message: "Submitted for review".to_string(),
                template_id: Some(template_id),
            }),
        ),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(MarketplaceResponse {
                success: false,
                message: e.to_string(),
                template_id: None,
            }),
        ),
    }
}

/// POST /api/marketplace/:id/download
pub async fn download_template(
    State(_state): State<AppState>,
    Extension(_user_id): Extension<String>,
    Path(id): Path<String>, // This is marketplace ID
) -> impl IntoResponse {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(MarketplaceResponse {
                    success: false,
                    message: "Storage not available".to_string(),
                    template_id: None,
                }),
            );
        }
    };

    // Get current doc
    let mut doc: MarketplaceTemplate = match firestore.get_doc("marketplace_templates", &id).await {
        Ok(Some(d)) => d,
        Ok(None) => {
            return (
                StatusCode::NOT_FOUND,
                Json(MarketplaceResponse {
                    success: false,
                    message: "Not found".to_string(),
                    template_id: None,
                }),
            );
        }
        Err(e) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(MarketplaceResponse {
                    success: false,
                    message: e.to_string(),
                    template_id: None,
                }),
            );
        }
    };

    // Increment downloads
    doc.downloads += 1;

    // Update
    match firestore.set_doc("marketplace_templates", &id, &doc).await {
        Ok(_) => (
            StatusCode::OK,
            Json(MarketplaceResponse {
                success: true,
                message: "Template downloaded".to_string(),
                template_id: Some(doc.template_id),
            }),
        ),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(MarketplaceResponse {
                success: false,
                message: e.to_string(),
                template_id: None,
            }),
        ),
    }
}

/// POST /api/marketplace/:id/rate
pub async fn rate_template(
    State(_state): State<AppState>,
    Extension(_user_id): Extension<String>,
    Path(id): Path<String>,
    Json(req): Json<RateTemplateRequest>,
) -> impl IntoResponse {
    if req.rating < 1 || req.rating > 5 {
        return (
            StatusCode::BAD_REQUEST,
            Json(MarketplaceResponse {
                success: false,
                message: "Rating 1-5".to_string(),
                template_id: None,
            }),
        );
    }

    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(MarketplaceResponse {
                    success: false,
                    message: "Storage not available".to_string(),
                    template_id: None,
                }),
            );
        }
    };

    let mut doc: MarketplaceTemplate = match firestore.get_doc("marketplace_templates", &id).await {
        Ok(Some(d)) => d,
        _ => {
            return (
                StatusCode::NOT_FOUND,
                Json(MarketplaceResponse {
                    success: false,
                    message: "Not found".to_string(),
                    template_id: None,
                }),
            );
        }
    };

    // Calc new rating
    let total_rating = doc.rating * (doc.rating_count as f64) + (req.rating as f64);
    doc.rating_count += 1;
    doc.rating = total_rating / (doc.rating_count as f64);

    match firestore.set_doc("marketplace_templates", &id, &doc).await {
        Ok(_) => (
            StatusCode::OK,
            Json(MarketplaceResponse {
                success: true,
                message: "Rated".to_string(),
                template_id: Some(id),
            }),
        ),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(MarketplaceResponse {
                success: false,
                message: e.to_string(),
                template_id: None,
            }),
        ),
    }
}

// ==================== ADMIN ENDPOINTS ====================

/// GET /api/admin/marketplace/pending
pub async fn list_pending_templates(
    State(_state): State<AppState>,
    Extension(_user_id): Extension<String>,
) -> impl IntoResponse {
    // NOTE: Real admin check should happen in middleware or here via Firestore 'allowed_users'
    // For now we assume middleware did it or we skip strictly for this migration step.
    // However, `admin.rs` migration handled this.
    // If we want strict check:
    // let is_admin = check_admin(...).await;

    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({"error": "No storage"})),
            )
                .into_response()
        }
    };

    match firestore
        .list_docs::<MarketplaceTemplate>("marketplace_templates")
        .await
    {
        Ok(all) => {
            let pending: Vec<MarketplaceTemplate> =
                all.into_iter().filter(|t| !t.approved).collect();
            (
                StatusCode::OK,
                Json(serde_json::json!({ "success": true, "pending": pending })),
            )
                .into_response()
        }
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({ "success": false, "error": e.to_string() })),
        )
            .into_response(),
    }
}

/// POST /api/admin/marketplace/:id/approve
pub async fn approve_template(
    State(_state): State<AppState>,
    Extension(_user_id): Extension<String>,
    Path(id): Path<String>,
) -> impl IntoResponse {
    update_approval(&id, true).await
}

/// POST /api/admin/marketplace/:id/reject
pub async fn reject_template(
    State(_state): State<AppState>,
    Extension(_user_id): Extension<String>,
    Path(id): Path<String>,
) -> impl IntoResponse {
    // Deleting the marketplace entry
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(MarketplaceResponse {
                    success: false,
                    message: "No storage".into(),
                    template_id: None,
                }),
            )
                .into_response()
        }
    };

    match firestore.delete_doc("marketplace_templates", &id).await {
        Ok(_) => (
            StatusCode::OK,
            Json(MarketplaceResponse {
                success: true,
                message: "Rejected/Deleted".to_string(),
                template_id: Some(id),
            }),
        )
            .into_response(),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(MarketplaceResponse {
                success: false,
                message: e.to_string(),
                template_id: None,
            }),
        )
            .into_response(),
    }
}

async fn update_approval(id: &str, approved: bool) -> axum::response::Response {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(MarketplaceResponse {
                    success: false,
                    message: "No storage".into(),
                    template_id: None,
                }),
            )
                .into_response()
        }
    };

    // We fetch, update, save.
    let mut doc: MarketplaceTemplate = match firestore.get_doc("marketplace_templates", id).await {
        Ok(Some(d)) => d,
        _ => {
            return (
                StatusCode::NOT_FOUND,
                Json(MarketplaceResponse {
                    success: false,
                    message: "Not found".into(),
                    template_id: None,
                }),
            )
                .into_response()
        }
    };

    doc.approved = approved;

    match firestore.set_doc("marketplace_templates", id, &doc).await {
        Ok(_) => (
            StatusCode::OK,
            Json(MarketplaceResponse {
                success: true,
                message: if approved {
                    "Approved".to_string()
                } else {
                    "Updated".to_string()
                },
                template_id: Some(id.to_string()),
            }),
        )
            .into_response(),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(MarketplaceResponse {
                success: false,
                message: e.to_string(),
                template_id: None,
            }),
        )
            .into_response(),
    }
}

// ==================== HELPERS ====================

// The check_admin helper is no longer needed here as admin checks are assumed to be handled
// by middleware or other mechanisms in a Firestore context, or directly within the admin functions
// by filtering on the 'approved' field.
// If a specific admin user check is required, it would involve fetching user data from Firestore.
// For this migration, we're removing the SQL-specific check.

```
      ]]>
        </FILE>
        <FILE path="routes\mod.rs">
            <![CDATA[
```rs
//! Route handlers

pub mod admin; // Admin user management
pub mod admin_config; // Admin access control
pub mod auth;
pub mod beta;
pub mod feedback;
pub mod import_export;
pub mod logs_api; // Log viewing API
pub mod marketplace; // Template marketplace
pub mod queue; // Request queue with rate limiting
pub mod remote_log; // Private GitHub log uploads
pub mod report;
pub mod status; // Production health checks
pub mod storage; // GitHub storage for user data
pub mod templates; // Template CRUD // Beta registration

use axum::{
    extract::DefaultBodyLimit,
    http::{header, HeaderValue, Method},
    routing::{delete, get, post, put},
    Router,
};
use tower_http::cors::CorsLayer;
use tower_http::trace::TraceLayer;

#[derive(Clone)]
pub struct AppState {
    pub google_services: Option<std::sync::Arc<crate::google_services::GoogleServices>>,
}

/// Create the main router with all routes and middleware
pub fn create_router(state: AppState) -> Router {
    // CORS configuration - allow frontend origins (dev + production)
    let cors = CorsLayer::new()
        .allow_origin([
            // Development
            "http://localhost:3000"
                .parse::<HeaderValue>()
                .expect("Static header valid"),
            "http://localhost:8080"
                .parse::<HeaderValue>()
                .expect("Static header valid"),
            "http://127.0.0.1:3000"
                .parse::<HeaderValue>()
                .expect("Static header valid"),
            "http://127.0.0.1:8080"
                .parse::<HeaderValue>()
                .expect("Static header valid"),
            "http://localhost:8081"
                .parse::<HeaderValue>()
                .expect("Static header valid"),
            "http://127.0.0.1:8081"
                .parse::<HeaderValue>()
                .expect("Static header valid"),
            // Production (Cloudflare Pages)
            "https://axtool.pages.dev"
                .parse::<HeaderValue>()
                .expect("Static header valid"),
            // Leapcell
            "https://axur-tool-maisonnat2655-5j70lozi.leapcell.dev"
                .parse::<HeaderValue>()
                .expect("Static header valid"),
            "https://axur-tool-maisonnat2655-dc5ya68vc4dbqraqq0.leapcell-async.dev"
                .parse::<HeaderValue>()
                .expect("Static header valid"),
        ])
        .allow_methods([
            Method::GET,
            Method::POST,
            Method::PUT,
            Method::DELETE,
            Method::OPTIONS,
        ])
        .allow_headers([
            header::CONTENT_TYPE,
            header::AUTHORIZATION,
            header::COOKIE,
            header::ACCEPT,
        ])
        .expose_headers([header::SET_COOKIE, header::CONTENT_TYPE])
        .allow_credentials(true)
        .max_age(std::time::Duration::from_secs(3600)); // Cache preflight for 1 hour

    // Public routes (Auth, Health, Status) - Note: finalize needs state
    let public_routes: Router<AppState> = Router::new()
        .route("/health", get(health_check))
        .route("/api/health", get(status::health)) // Lightweight health for cold start detection
        .route("/api/status", get(status::full_status))
        .route("/api/public/beta-request", post(beta::submit_beta_request))
        .route("/api/public/beta-status", get(beta::check_beta_status))
        .route("/api/auth/login", post(auth::login))
        .route("/api/auth/2fa", post(auth::verify_2fa))
        .route("/api/auth/finalize", post(auth::finalize)) // Needs State for beta check
        .route("/api/auth/validate", get(auth::validate))
        .route("/api/auth/logout", post(auth::logout))
        // Marketplace (browse is public)
        .route("/api/marketplace", get(marketplace::list_marketplace))
        // Template GET is public (mock templates don't need auth)
        .route("/api/templates/:id", get(templates::get_template));

    // Protected routes (Require Authentication)
    let protected_routes: Router<AppState> = Router::new()
        .route("/api/tenants", get(report::list_tenants))
        .route("/api/report/generate", post(report::generate_report))
        .route("/api/export/inject", post(import_export::inject_pptx))
        .route(
            "/api/export/generate-pptx",
            post(import_export::generate_pptx_report),
        )
        .route("/api/import/pptx", post(import_export::import_pptx))
        .route("/api/export/slides", post(import_export::export_to_slides)) // Google Slides export
        .route(
            "/api/threat-hunting/preview",
            post(report::threat_hunting_preview),
        )
        .route(
            "/api/threat-hunting/preview-stream",
            get(report::threat_hunting_preview_stream),
        )
        .route(
            "/api/reports/generate-stream",
            get(report::generate_report_stream),
        )
        .route("/api/feedback", post(feedback::submit_feedback))
        .route("/api/logs/sync", post(remote_log::sync_logs))
        // Log viewer API
        .route("/api/logs", get(logs_api::list_logs))
        .route("/api/logs/dates", get(logs_api::list_log_dates))
        .route("/api/logs/categories", get(logs_api::list_log_categories))
        .route("/api/logs/content/*path", get(logs_api::get_log_content))
        .route("/api/logs/access", get(logs_api::check_log_access))
        .route("/api/logs/stats", get(logs_api::get_log_stats))
        // Template CRUD API
        .route("/api/templates", get(templates::list_templates))
        .route("/api/templates", post(templates::create_template))
        // GET /api/templates/:id is in public routes (mock templates)
        .route("/api/templates/:id", put(templates::update_template))
        .route("/api/templates/:id", delete(templates::delete_template))
        .route("/api/templates/:id/pptx", get(templates::get_template_pptx))
        // Auto-save endpoints (DB-only, faster than GitHub)
        .route(
            "/api/templates/quick-save",
            post(templates::quick_save_template),
        )
        .route(
            "/api/templates/quick-load/:id",
            get(templates::quick_load_template),
        )
        .route(
            "/api/templates/:id/publish",
            post(marketplace::publish_template),
        )
        // Marketplace user actions
        .route(
            "/api/marketplace/:id/download",
            post(marketplace::download_template),
        )
        .route(
            "/api/marketplace/:id/rate",
            post(marketplace::rate_template),
        )
        // Admin moderation
        .route(
            "/api/admin/marketplace/pending",
            get(marketplace::list_pending_templates),
        )
        .route(
            "/api/admin/marketplace/:id/approve",
            post(marketplace::approve_template),
        )
        .route(
            "/api/admin/marketplace/:id/reject",
            post(marketplace::reject_template),
        )
        // Admin user management (Beta access control)
        .nest("/api/admin", admin::admin_routes())
        .route_layer(axum::middleware::from_fn(crate::middleware::require_auth));

    // Queue routes (public - uses global queue, no AppState needed)
    let queue_routes: Router<AppState> = queue::queue_routes().with_state(());

    // Storage routes (user templates via GitHub, no AppState needed)
    let storage_routes: Router<AppState> = storage::storage_routes().with_state(());

    let app: Router<AppState> = Router::new()
        .merge(public_routes)
        .merge(protected_routes)
        .nest("/api/queue", queue_routes)
        .nest("/api/storage", storage_routes)
        .layer(DefaultBodyLimit::max(50 * 1024 * 1024)) // 50MB limit
        .layer(TraceLayer::new_for_http())
        .layer(cors);

    let app_with_state = app.with_state(state);

    // Firestore is lazy-loaded via firebase::get_firestore(), no global pool needed
    app_with_state
}

/// Health check endpoint
async fn health_check() -> axum::Json<serde_json::Value> {
    axum::Json(serde_json::json!({
        "status": "ok",
        "service": "axur-backend",
        "version": env!("CARGO_PKG_VERSION")
    }))
}

```
      ]]>
        </FILE>
        <FILE path="routes\queue.rs">
            <![CDATA[
```rs
//! Queue Routes - API endpoints for queue status and job submission

use axum::{
    extract::Path,
    response::{
        sse::{Event, Sse},
        IntoResponse,
    },
    routing::{get, post},
    Json, Router,
};
use futures::stream::{self, Stream};
use serde::Deserialize;
use std::{convert::Infallible, time::Duration};

use crate::queue::{get_queue, ApiType, JobStatus, JobType, QueueJob, QueueStatusResponse};

/// Create queue routes (no state needed - uses global queue)
pub fn queue_routes() -> Router {
    Router::new()
        .route("/submit", post(submit_job))
        .route("/status/:job_id", get(get_job_status))
        .route("/stream/:job_id", get(stream_job_status))
        .route("/length", get(get_queue_length))
}

/// Request body for job submission
#[derive(Debug, Deserialize)]
pub struct SubmitJobRequest {
    pub user_id: String,
    pub job_type: String,
    pub params: serde_json::Value,
}

/// Submit a new job to the queue
async fn submit_job(Json(req): Json<SubmitJobRequest>) -> impl IntoResponse {
    let queue = get_queue();

    // Parse job type
    let (job_type, api_type) = match req.job_type.as_str() {
        "generate_report" => {
            let tenant_id = req
                .params
                .get("tenant_id")
                .and_then(|v| v.as_str())
                .unwrap_or("default")
                .to_string();
            (JobType::GenerateReport { tenant_id }, ApiType::Axur)
        }
        "save_template" => {
            let template_name = req
                .params
                .get("template_name")
                .and_then(|v| v.as_str())
                .unwrap_or("unnamed")
                .to_string();
            (JobType::SaveTemplate { template_name }, ApiType::GitHub)
        }
        "load_template" => {
            let template_id = req
                .params
                .get("template_id")
                .and_then(|v| v.as_str())
                .unwrap_or("default")
                .to_string();
            (JobType::LoadTemplate { template_id }, ApiType::GitHub)
        }
        _ => {
            return Json(serde_json::json!({
                "error": "Unknown job type"
            }));
        }
    };

    let job = QueueJob::new(req.user_id, job_type, api_type);
    let job_id = queue.submit(job).await;
    let position = queue.queue_length().await;
    let eta = queue.estimate_wait_time(position, api_type);

    Json(serde_json::json!({
        "job_id": job_id,
        "position": position,
        "eta_seconds": eta.as_secs()
    }))
}

/// Get current job status
async fn get_job_status(Path(job_id): Path<String>) -> impl IntoResponse {
    let queue = get_queue();

    match queue.get_job(&job_id).await {
        Some(job) => {
            let mut response = QueueStatusResponse::from(&job);

            // Add ETA if queued
            if let Some(position) = response.position {
                let eta = queue.estimate_wait_time(position, job.api_type);
                response.eta_seconds = Some(eta.as_secs());
            }

            Json(serde_json::json!(response))
        }
        None => Json(serde_json::json!({
            "error": "Job not found"
        })),
    }
}

/// Get queue length
async fn get_queue_length() -> impl IntoResponse {
    let queue = get_queue();
    let length = queue.queue_length().await;
    Json(serde_json::json!({
        "length": length
    }))
}

/// Server-Sent Events stream for job status
async fn stream_job_status(
    Path(job_id): Path<String>,
) -> Sse<impl Stream<Item = Result<Event, Infallible>>> {
    let stream = stream::unfold((job_id, 0u32), |(job_id, tick)| async move {
        // Poll every 2 seconds, max 300 ticks (10 minutes)
        if tick > 300 {
            return None;
        }

        tokio::time::sleep(Duration::from_secs(2)).await;

        let queue = get_queue();
        let event = match queue.get_job(&job_id).await {
            Some(job) => {
                let response = QueueStatusResponse::from(&job);
                let data = serde_json::to_string(&response).unwrap_or_default();

                // If completed or failed, this will be the last event
                let is_final = matches!(
                    &job.status,
                    JobStatus::Completed { .. } | JobStatus::Failed { .. }
                );

                if is_final {
                    return Some((
                        Ok(Event::default().data(data).event("complete")),
                        (job_id, 301), // Stop after this
                    ));
                }

                Event::default().data(data).event("update")
            }
            None => Event::default()
                .data(r#"{"error":"Job not found"}"#)
                .event("error"),
        };

        Some((Ok(event), (job_id, tick + 1)))
    });

    Sse::new(stream).keep_alive(
        axum::response::sse::KeepAlive::new()
            .interval(Duration::from_secs(15))
            .text("ping"),
    )
}

```
      ]]>
        </FILE>
        <FILE path="routes\remote_log.rs">
            <![CDATA[
```rs
//! Remote logging module - Hybrid (Firestore + GitHub)
//!
//! - Writes full log content to GitHub (Unlimited storage)
//! - Writes metadata and indexed fields to Firestore (Fast queries)
//! - Uses daily sharding for Firestore collections to optimize cost/performance.

use axum::http::StatusCode;
use base64::{engine::general_purpose::STANDARD as BASE64, Engine as _};
use serde_json::json;
use uuid::Uuid;

/// Configuration for remote logging (GitHub)
pub struct RemoteLogConfig {
    pub token: String,
    pub owner: String,
    pub repo: String,
}

impl RemoteLogConfig {
    /// Load config from environment variables
    pub fn from_env() -> Option<Self> {
        let token = std::env::var("GH_PAT")
            .or_else(|_| std::env::var("GITHUB_TOKEN"))
            .ok()?;

        let owner = std::env::var("GH_OWNER")
            .or_else(|_| std::env::var("GITHUB_OWNER"))
            .ok()?;

        let repo = std::env::var("GH_LOGS_REPO")
            .or_else(|_| std::env::var("GITHUB_LOGS_REPO"))
            .unwrap_or_else(|_| "axur-logs-private".to_string());

        Some(Self { token, owner, repo })
    }
}

/// Get the SHA of an existing file (if it exists)
async fn get_file_sha(config: &RemoteLogConfig, path: &str) -> Option<String> {
    let client = reqwest::Client::new();
    let url = format!(
        "https://api.github.com/repos/{}/{}/contents/{}",
        config.owner, config.repo, path
    );

    let res = client
        .get(&url)
        .header("Authorization", format!("Bearer {}", config.token))
        .header("User-Agent", "axur-bot")
        .header("Accept", "application/vnd.github.v3+json")
        .send()
        .await
        .ok()?;

    if res.status().is_success() {
        let json: serde_json::Value = res.json().await.ok()?;
        json.get("sha")
            .and_then(|s| s.as_str())
            .map(|s| s.to_string())
    } else {
        None
    }
}

/// Upload a file to the private GitHub repository
async fn upload_to_github(
    config: &RemoteLogConfig,
    path: &str,
    content: &str,
    message: &str,
) -> Result<String, String> {
    let upload_url = format!(
        "https://api.github.com/repos/{}/{}/contents/{}",
        config.owner, config.repo, path
    );

    let encoded_content = BASE64.encode(content.as_bytes());

    let perform_upload = |sha: Option<String>| async {
        let mut body_map = serde_json::Map::new();
        body_map.insert("message".to_string(), json!(message));
        body_map.insert("content".to_string(), json!(encoded_content));

        // Committer is optional, GitHub uses authenticated user by default
        body_map.insert(
            "committer".to_string(),
            json!({
                "name": "Axur Bot",
                "email": "bot@axur.local"
            }),
        );

        if let Some(s) = sha {
            body_map.insert("sha".to_string(), json!(s));
        }

        let body = serde_json::Value::Object(body_map);
        let client = reqwest::Client::new();

        client
            .put(&upload_url)
            .header("Authorization", format!("Bearer {}", config.token))
            .header("User-Agent", "axur-bot")
            .header("Accept", "application/vnd.github.v3+json")
            .json(&body)
            .send()
            .await
    };

    let res = perform_upload(None).await.map_err(|e| e.to_string())?;

    if res.status().is_success() {
        let resp_json: serde_json::Value = res.json().await.map_err(|e| e.to_string())?;
        return Ok(resp_json
            .get("content")
            .and_then(|c| c.get("html_url"))
            .and_then(|u| u.as_str())
            .unwrap_or("")
            .to_string());
    }

    // Handle conflict (update)
    if res.status() == reqwest::StatusCode::CONFLICT
        || res.status() == reqwest::StatusCode::UNPROCESSABLE_ENTITY
    {
        if let Some(sha) = get_file_sha(config, path).await {
            let retry_res = perform_upload(Some(sha)).await.map_err(|e| e.to_string())?;
            if retry_res.status().is_success() {
                let resp_json: serde_json::Value =
                    retry_res.json().await.map_err(|e| e.to_string())?;
                return Ok(resp_json
                    .get("content")
                    .and_then(|c| c.get("html_url"))
                    .and_then(|u| u.as_str())
                    .unwrap_or("")
                    .to_string());
            }
        }
    }

    Err(format!("GitHub upload failed: {}", res.status()))
}

/// Upload a log entry (Hybrid: GitHub + Firestore)
pub async fn upload_log(category: &str, filename: &str, content: &str) -> Result<String, String> {
    let now = chrono::Utc::now();
    let message = format!("Log: {} - {}", category, filename);

    // 1. Upload to GitHub
    let mut github_url = String::new();
    let mut github_path = String::new();

    if let Some(config) = RemoteLogConfig::from_env() {
        let date_folder = now.format("%Y/%m/%d").to_string();
        github_path = format!("logs/{}/{}/{}", date_folder, category, filename);

        match upload_to_github(&config, &github_path, content, &message).await {
            Ok(url) => github_url = url,
            Err(e) => tracing::warn!("GitHub upload failed: {}, continuing to DB", e),
        }
    }

    // 2. Insert into Firestore
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => return Err("Firestore not available".to_string()),
    };

    let level = if category.contains("error") {
        "error"
    } else if category.contains("warn") {
        "warn"
    } else {
        "info"
    };

    // Truncate content for DB
    let max_db_content_size = 2000;
    let db_content = if content.len() > max_db_content_size {
        format!(
            "{}... (truncated, see GitHub)",
            &content[..max_db_content_size]
        )
    } else {
        content.to_string()
    };

    let metadata = serde_json::from_str::<serde_json::Value>(content).unwrap_or(json!({}));

    // Sharding by Date: system_logs/{YYYY-MM-DD}/entries/{ID}
    let date_key = now.format("%Y-%m-%d").to_string();
    let uuid_val = Uuid::new_v4();
    let id = format!("{}_{}", date_key, uuid_val); // Prefix with date for easier lookup if needed

    let log_entry = json!({
        "id": id,
        "timestamp": now.to_rfc3339(),
        "category": category,
        "message": message,
        "level": level,
        "content": db_content,
        "metadata": metadata,
        "github_path": github_path,
        "github_html_url": github_url
    });

    // Ensure the daily document exists (creating it is cheap/idempotent with set)
    // Actually, we don't strictly need the parent doc to exist to add to subcollection in Firestore Native?
    // In Datastore mode yes, in Native mode usually yes for listing.
    // We'll create a dummy doc for the date to enable listing dates.
    // Optimistic: Assume it exists or we create it once per day.
    // For now we just write to subcollection. If we want to list dates, we should write a date doc.
    // Let's write the log first.

    let path = format!("system_logs/{}/entries", date_key);
    match firestore.set_doc(&path, &id, &log_entry).await {
        Ok(_) => {
            // Also ensure date doc exists? - optimization: do this only on distinct dates?
            // Too expensive to check every time.
            // We'll assume the client 'list dates' will list root collection `system_logs`.
            // Depending on Firestore, empty docs (only having subcollections) might show up or not.
            Ok(id)
        }
        Err(e) => Err(format!("Firestore error: {}", e)),
    }
}

/// Upload multiple logs in batch (fire-and-forget style)
pub fn upload_log_async(category: &str, filename: &str, content: String) {
    let category = category.to_string();
    let filename = filename.to_string();

    tokio::spawn(async move {
        match upload_log(&category, &filename, &content).await {
            Ok(id) => tracing::debug!("Log saved: {}", id),
            Err(e) => tracing::warn!("Failed to save log: {}", e),
        }
    });
}

/// Upload a generated report (Hybrid)
pub fn upload_report_async(tenant: &str, filename: &str, content: String) {
    let _tenant = tenant.to_string();
    let filename = filename.to_string();
    let category = "reports".to_string();

    tokio::spawn(async move {
        if let Err(e) = upload_log(&category, &filename, &content).await {
            tracing::warn!("Failed to archive report: {}", e);
        }
    });
}

/// Convenience function for uploading JSON debug logs
pub fn upload_debug_json(category: &str, data: &serde_json::Value) {
    let filename = format!(
        "{}_{}.json",
        category,
        chrono::Utc::now().format("%H%M%S_%3f")
    );

    let content = serde_json::to_string_pretty(data).unwrap_or_default();
    upload_log_async(category, &filename, content);
}

/// Log API request with metadata
pub fn log_request<T: serde::Serialize>(operation: &str, payload: &T, tenant_id: Option<&str>) {
    // Firestore Analytics
    if let Some(firestore) = crate::firebase::get_firestore() {
        let op = operation.to_string();
        let tid = tenant_id.map(|s| s.to_string());
        let props = serde_json::to_value(payload).unwrap_or(json!({}));

        tokio::spawn(async move {
            let now = chrono::Utc::now();
            let date_key = now.format("%Y-%m-%d").to_string();
            let id = Uuid::new_v4().to_string();

            let event = json!({
                "event_type": "api_request",
                "tenant_id": tid,
                "timestamp": now.to_rfc3339(),
                "properties": { "operation": op, "payload": props }
            });

            let _ = firestore
                .set_doc(
                    &format!("analytics_events/{}/events", date_key),
                    &id,
                    &event,
                )
                .await;
        });
    }

    let log_data = serde_json::json!({
        "type": "request",
        "operation": operation,
        "timestamp": chrono::Utc::now().to_rfc3339(),
        "tenant_id": tenant_id,
        "payload": payload
    });

    upload_debug_json(&format!("{}_requests", operation), &log_data);
}

/// Log API response with performance data
pub fn log_response<T: serde::Serialize>(
    operation: &str,
    response: &T,
    duration_ms: u128,
    tenant_id: Option<&str>,
    success: bool,
) {
    if let Some(firestore) = crate::firebase::get_firestore() {
        let op = operation.to_string();
        let tid = tenant_id.map(|s| s.to_string());
        // Avoid cloning large response if not needed? Properties can be simplified.
        let props = json!({
            "operation": op,
            "duration_ms": duration_ms as i64,
            "success": success
        });

        tokio::spawn(async move {
            let now = chrono::Utc::now();
            let date_key = now.format("%Y-%m-%d").to_string();
            let id = Uuid::new_v4().to_string();

            let event = json!({
                "event_type": "api_response",
                "tenant_id": tid,
                "timestamp": now.to_rfc3339(),
                "properties": props
            });

            let _ = firestore
                .set_doc(
                    &format!("analytics_events/{}/events", date_key),
                    &id,
                    &event,
                )
                .await;
        });
    }

    let log_data = serde_json::json!({
        "type": "response",
        "operation": operation,
        "timestamp": chrono::Utc::now().to_rfc3339(),
        "duration_ms": duration_ms,
        "tenant_id": tenant_id,
        "success": success,
        "response": response
    });

    upload_debug_json(&format!("{}_responses", operation), &log_data);
}

/// Log error with context
pub fn log_error(
    operation: &str,
    error_code: &str,
    error_message: &str,
    tenant_id: Option<&str>,
    context: serde_json::Value,
) {
    if let Some(firestore) = crate::firebase::get_firestore() {
        let op = operation.to_string();
        let code = error_code.to_string();
        let msg = error_message.to_string();
        let tid = tenant_id.map(|s| s.to_string());
        let ctx = context.clone();

        tokio::spawn(async move {
            let now = chrono::Utc::now();
            let date_key = now.format("%Y-%m-%d").to_string();
            let id = Uuid::new_v4().to_string();

            let event = json!({
                "event_type": "error",
                "tenant_id": tid,
                "timestamp": now.to_rfc3339(),
                "properties": {
                   "operation": op,
                   "error_code": code,
                   "error_message": msg,
                   "context": ctx
                }
            });

            let _ = firestore
                .set_doc(
                    &format!("analytics_events/{}/events", date_key),
                    &id,
                    &event,
                )
                .await;
        });
    }

    let log_data = serde_json::json!({
        "type": "error",
        "operation": operation,
        "timestamp": chrono::Utc::now().to_rfc3339(),
        "error_code": error_code,
        "error_message": error_message,
        "tenant_id": tenant_id,
        "context": context
    });

    upload_debug_json("errors", &log_data);
}

/// Log performance metrics with breakdown
pub fn log_performance(
    operation: &str,
    total_duration_ms: u128,
    breakdown: serde_json::Value,
    tenant_id: Option<&str>,
) {
    let log_data = serde_json::json!({
        "type": "performance",
        "operation": operation,
        "timestamp": chrono::Utc::now().to_rfc3339(),
        "total_duration_ms": total_duration_ms,
        "breakdown": breakdown,
        "tenant_id": tenant_id
    });

    upload_debug_json("performance_metrics", &log_data);
}

/// Log feature usage event
pub fn log_feature_usage(
    feature: &str,
    tenant_id: Option<&str>,
    success: bool,
    metadata: Option<serde_json::Value>,
) {
    if let Some(firestore) = crate::firebase::get_firestore() {
        let feat = feature.to_string();
        let tid = tenant_id.map(|s| s.to_string());
        let meta = metadata.clone().unwrap_or(json!({}));

        tokio::spawn(async move {
            let now = chrono::Utc::now();
            let date_key = now.format("%Y-%m-%d").to_string();
            let id = Uuid::new_v4().to_string();

            let event = json!({
                "event_type": "feature_usage",
                "tenant_id": tid,
                "timestamp": now.to_rfc3339(),
                "properties": {
                   "feature": feat,
                   "success": success,
                   "metadata": meta
                }
            });

            let _ = firestore
                .set_doc(
                    &format!("analytics_events/{}/events", date_key),
                    &id,
                    &event,
                )
                .await;
        });
    }

    let log_data = serde_json::json!({
        "type": "feature_usage",
        "feature": feature,
        "timestamp": chrono::Utc::now().to_rfc3339(),
        "tenant_id": tenant_id,
        "success": success,
        "metadata": metadata
    });

    upload_debug_json("feature_usage", &log_data);
}

// ==================== HTTP ENDPOINT ====================

use axum::{response::IntoResponse, Json};
use serde::Serialize;

#[derive(Serialize)]
pub struct SyncLogsResponse {
    pub success: bool,
    pub uploaded: usize,
    pub failed: usize,
    pub message: String,
}

/// Endpoint to sync all local debug logs to the database
/// POST /api/logs/sync
pub async fn sync_logs() -> impl IntoResponse {
    let debug_dir = std::path::Path::new("debug_logs");
    if !debug_dir.exists() {
        return (
            StatusCode::OK,
            Json(SyncLogsResponse {
                success: true,
                uploaded: 0,
                failed: 0,
                message: "No debug_logs directory found".to_string(),
            }),
        );
    }

    let mut uploaded = 0;
    let mut failed = 0;

    // Read all files in debug_logs
    if let Ok(entries) = std::fs::read_dir(debug_dir) {
        for entry in entries.flatten() {
            let path = entry.path();
            if path.is_file() {
                let filename = path
                    .file_name()
                    .and_then(|n| n.to_str())
                    .unwrap_or("unknown")
                    .to_string();

                // Determine category from filename
                let category = if filename.starts_with("th_") {
                    "threat_hunting"
                } else if filename.starts_with("exposure_") {
                    "exposure_api"
                } else if filename.starts_with("fetch_") {
                    "fetch_operations"
                } else {
                    "misc"
                };

                // Read and upload
                if let Ok(content) = std::fs::read_to_string(&path) {
                    match upload_log(category, &filename, &content).await {
                        Ok(_) => {
                            uploaded += 1;
                            // Delete local file after successful upload
                            let _ = std::fs::remove_file(&path);
                        }
                        Err(e) => {
                            tracing::warn!("Failed to upload {}: {}", filename, e);
                            failed += 1;
                        }
                    }
                }
            }
        }
    }

    (
        StatusCode::OK,
        Json(SyncLogsResponse {
            success: failed == 0,
            uploaded,
            failed,
            message: format!("Synced {} files to DB, {} failed", uploaded, failed),
        }),
    )
}

```
      ]]>
        </FILE>
        <FILE path="routes\report.rs">
            <![CDATA[
```rs
//! Report generation routes
//!
//! Endpoints for listing tenants and generating HTML reports.
//! Includes structured error codes for better debugging.

use axum::extract::State;
use axum::response::sse::{Event, KeepAlive, Sse};
use axum::{Extension, Json};
use axum_extra::extract::CookieJar;
use futures::stream::Stream;
use serde::{Deserialize, Serialize};
use std::convert::Infallible;
use uuid::Uuid;

use crate::error::ApiError;
use crate::middleware::AUTH_COOKIE_NAME;
use crate::routes::templates::{self, GitHubConfig};
use crate::routes::AppState;
use crate::services::report_service::{
    classify_error, get_user_friendly_message, GenerateReportRequest, GenerateReportResponse,
    ReportService, TenantResponse,
};
use axur_core::api::report::{
    fetch_available_tenants, fetch_full_report, fetch_tagged_tickets_for_preview,
    preview_threat_hunting,
};
use axur_core::error_codes::{self, ErrorCode};
use axur_core::i18n::{get_dictionary, Language, Translations};
use axur_core::report::html::{generate_full_report_html, generate_report_with_plugins};
use axur_core::report::OfflineAssets;
use std::time::Instant;

fn default_language() -> String {
    "es".to_string()
}

// ========================
// REQUEST/RESPONSE TYPES
// ========================

// REQUEST/RESPONSE TYPES MOVED TO services::report_service
// Kept ThreatHunting types here for now as they are not migrated yet.

#[derive(Debug, Deserialize, Serialize)]
pub struct ThreatHuntingPreviewRequest {
    pub tenant_id: String,
    pub story_tag: String,
    #[serde(default)]
    pub use_user_credits: bool,
}

#[derive(Debug, Serialize)]
pub struct ThreatHuntingPreviewResponse {
    pub success: bool,
    pub preview: Option<axur_core::api::report::ThreatHuntingPreview>,
    pub message: String,
}

// ========================
// ROUTE HANDLERS
// ========================

/// List available tenants for the authenticated user
pub async fn list_tenants(jar: CookieJar) -> Result<Json<Vec<TenantResponse>>, ApiError> {
    let token = jar
        .get(AUTH_COOKIE_NAME)
        .map(|c| c.value().to_string())
        .ok_or_else(|| ApiError::Unauthorized("No session found".into()))?;

    let tenants = fetch_available_tenants(&token)
        .await
        .map_err(|e| ApiError::ExternalApi(format!("Failed to fetch tenants: {}", e)))?;

    let response: Vec<TenantResponse> = tenants
        .into_iter()
        .map(|t| TenantResponse {
            key: t.key,
            name: t.name,
        })
        .collect();

    Ok(Json(response))
}

/// Generate HTML report for a tenant with structured error handling
pub async fn generate_report(
    State(_state): State<AppState>,
    Extension(user_id): Extension<String>,
    jar: CookieJar,
    Json(payload): Json<GenerateReportRequest>,
) -> Result<Json<GenerateReportResponse>, ApiError> {
    // Validate input
    if payload.tenant_id.is_empty() {
        let code = error_codes::report::invalid_date_range();
        return Ok(Json(GenerateReportResponse {
            success: false,
            html: None,
            company_name: None,
            message: "Tenant ID is required".into(),
            error_code: Some(code.code()),
            error_message: Some(get_user_friendly_message(&code)),
        }));
    }
    if payload.from_date.is_empty() || payload.to_date.is_empty() {
        let code = error_codes::report::invalid_date_range();
        return Ok(Json(GenerateReportResponse {
            success: false,
            html: None,
            company_name: None,
            message: "Date range is required".into(),
            error_code: Some(code.code()),
            error_message: Some(get_user_friendly_message(&code)),
        }));
    }

    let token = jar
        .get(AUTH_COOKIE_NAME)
        .map(|c| c.value().to_string())
        .ok_or_else(|| ApiError::Unauthorized("No session found".into()))?;

    tracing::info!(
        "Generating report for tenant {} from {} to {} with story_tag: {:?}",
        payload.tenant_id,
        payload.from_date,
        payload.to_date,
        payload.story_tag
    );

    //  Log request
    crate::routes::remote_log::log_request("report_generate", &payload, Some(&payload.tenant_id));

    let start_time = Instant::now();

    // Delegate to ReportService (Safe & Modular)
    let response = ReportService::generate_report(&payload, &token, &user_id).await?;

    //  Log successful response (Service handles logic, Handler handles HTTP logging)
    crate::routes::remote_log::log_response(
        "report_generate",
        &response,
        start_time.elapsed().as_millis(),
        Some(&payload.tenant_id),
        true,
    );

    //  Log feature usage (simplified)
    crate::routes::remote_log::log_feature_usage(
        "report_generation",
        Some(&payload.tenant_id),
        true,
        Some(serde_json::json!({
            "include_threat_intel": payload.include_threat_intel,
            "language": &payload.language,
            "has_story_tag": payload.story_tag.is_some(),
        })),
    );

    //  Archive report to GitHub (async)
    if let (Some(html), Some(company_name)) = (&response.html, &response.company_name) {
        let filename = format!(
            "{}_{}_report.html",
            company_name.replace(' ', "_"),
            chrono::Utc::now().format("%Y-%m-%d_%H%M%S")
        );
        crate::routes::remote_log::upload_report_async(company_name, &filename, html.clone());
    }

    Ok(Json(response))
}

/// Preview Threat Hunting results without consuming full credits
/// Returns counts and estimated credits for user confirmation
pub async fn threat_hunting_preview(
    jar: CookieJar,
    Json(payload): Json<ThreatHuntingPreviewRequest>,
) -> Result<Json<ThreatHuntingPreviewResponse>, ApiError> {
    let token = jar
        .get(AUTH_COOKIE_NAME)
        .map(|c| c.value().to_string())
        .ok_or_else(|| ApiError::Unauthorized("No session found".into()))?;

    tracing::info!(
        tenant = %payload.tenant_id,
        story_tag = %payload.story_tag,
        "Starting Threat Hunting preview"
    );

    //  Log request
    crate::routes::remote_log::log_request("th_preview", &payload, Some(&payload.tenant_id));

    //  Start performance tracking
    let start_time = std::time::Instant::now();

    // FIXED: Fetch actual tickets with the story_tag instead of using tag as domain
    let tickets = match axur_core::api::report::fetch_tagged_tickets_for_preview(
        &token,
        &payload.tenant_id,
        &payload.story_tag,
    )
    .await
    {
        Ok(t) => {
            tracing::info!(
                "Fetched {} tickets with tag '{}'",
                t.len(),
                payload.story_tag
            );
            t
        }
        Err(e) => {
            tracing::warn!("Failed to fetch tagged tickets: {}, using empty list", e);
            vec![]
        }
    };

    if tickets.is_empty() {
        return Ok(Json(ThreatHuntingPreviewResponse {
            success: false,
            preview: None,
            message: format!(
                "No tickets found with tag '{}' in tenant {}. Please verify the tag exists.",
                payload.story_tag, payload.tenant_id
            ),
        }));
    }

    match preview_threat_hunting(
        &token,
        &payload.tenant_id,
        &tickets,
        &payload.story_tag,
        payload.use_user_credits,
    )
    .await
    {
        Ok(preview) => {
            tracing::info!(
                total = preview.total_count,
                estimated_credits = preview.estimated_credits,
                tickets_used = tickets.len(),
                "Threat Hunting preview completed"
            );

            //  Calculate duration
            let duration_ms = start_time.elapsed().as_millis();

            //  Log successful response (metadata only, not full preview data)
            crate::routes::remote_log::log_response(
                "th_preview",
                &serde_json::json!({
                    "success": true,
                    "total_count": preview.total_count,
                    "estimated_credits": preview.estimated_credits,
                    "signal_lake_count": preview.signal_lake_count,
                    "credential_count": preview.credential_count,
                    "tickets_used": tickets.len()
                }),
                duration_ms,
                Some(&payload.tenant_id),
                true,
            );

            //  Log feature usage
            crate::routes::remote_log::log_feature_usage(
                "preview_generation",
                Some(&payload.tenant_id),
                true,
                Some(serde_json::json!({
                    "story_tag": &payload.story_tag,
                    "tickets_count": tickets.len(),
                    "total_results": preview.total_count,
                    "estimated_credits": preview.estimated_credits,
                    "duration_ms": duration_ms
                })),
            );

            Ok(Json(ThreatHuntingPreviewResponse {
                success: true,
                preview: Some(preview),
                message: format!("Preview ready. Found {} tickets with tag.", tickets.len()),
            }))
        }
        Err(e) => {
            tracing::error!("Threat Hunting preview failed: {}", e);

            //  Log error
            crate::routes::remote_log::log_error(
                "th_preview",
                "TH-ERR",
                &e.to_string(),
                Some(&payload.tenant_id),
                serde_json::json!({
                    "story_tag": &payload.story_tag,
                    "tickets_count": tickets.len()
                }),
            );

            Ok(Json(ThreatHuntingPreviewResponse {
                success: false,
                preview: None,
                message: format!("Preview failed: {}", e),
            }))
        }
    }
}

// Helpers moved to ReportService

// ========================
// SSE STREAMING PREVIEW
// ========================

/// Event types for SSE streaming
#[derive(Debug, Clone, Serialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum ThreatHuntingStreamEvent {
    Started {
        total_domains: usize,
        total_tickets: usize,
    },
    DomainProcessing {
        domain: String,
        index: usize,
        source: String,
    },
    DomainComplete {
        domain: String,
        source: String,
        count: u64,
    },
    Finished {
        total_count: u64,
        signal_lake_count: u64,
        chatter_count: u64,
        credential_count: u64,
        estimated_credits: f64,
    },
    Error {
        message: String,
    },
}

// ========================
// SSE STREAMING REPORT GENERATION
// ========================

/// Event types for SSE report generation streaming
#[derive(Debug, Clone, Serialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum ReportStreamEvent {
    /// Report generation started
    Started { stages: Vec<String> },
    /// Progress update for current stage
    StageProgress {
        stage: String,
        message: String,
        progress_pct: u8,
    },
    /// Stage completed
    StageComplete { stage: String },
    /// Report generation finished with HTML
    Finished {
        html: String,
        company_name: Option<String>,
    },
    /// Error occurred
    Error { code: String, message: String },
}

/// Request params for streaming report generation (GET for EventSource)
#[derive(Debug, Deserialize)]
pub struct GenerateReportStreamParams {
    pub tenant_id: String,
    pub from_date: String,
    pub to_date: String,
    #[serde(default = "default_language")]
    pub language: String,
    pub story_tag: Option<String>,
    #[serde(default)]
    pub include_threat_intel: bool,
    pub template_id: Option<String>,
    #[serde(default)]
    pub use_plugins: bool,
    pub plugin_theme: Option<String>,
    pub disabled_slides: Option<String>, // Comma-separated list
}

/// SSE endpoint for streaming Threat Hunting preview progress
/// Uses GET with query params for EventSource compatibility
pub async fn threat_hunting_preview_stream(
    jar: CookieJar,
    axum::extract::Query(params): axum::extract::Query<ThreatHuntingPreviewRequest>,
) -> Result<Sse<impl Stream<Item = Result<Event, Infallible>>>, ApiError> {
    let token = jar
        .get(AUTH_COOKIE_NAME)
        .map(|c| c.value().to_string())
        .ok_or_else(|| ApiError::Unauthorized("No session found".into()))?;

    tracing::info!(
        tenant = %params.tenant_id,
        story_tag = %params.story_tag,
        "Starting SSE Threat Hunting preview stream"
    );

    // Clone values for the async stream
    let tenant_id = params.tenant_id.clone();
    let story_tag = params.story_tag.clone();

    let stream = async_stream::stream! {
        // Fetch tickets first
        let tickets = match fetch_tagged_tickets_for_preview(&token, &tenant_id, &story_tag).await {
            Ok(t) => t,
            Err(e) => {
                let event = ThreatHuntingStreamEvent::Error {
                    message: format!("Failed to fetch tickets: {}", e),
                };
                if let Ok(json) = serde_json::to_string(&event) {
                    yield Ok(Event::default().data(json));
                }
                return;
            }
        };

        if tickets.is_empty() {
            let event = ThreatHuntingStreamEvent::Error {
                message: format!("No tickets found with tag '{}' in tenant {}", story_tag, tenant_id),
            };
            if let Ok(json) = serde_json::to_string(&event) {
                yield Ok(Event::default().data(json));
            }
            return;
        }

        // Extract unique domains (max 5)
        let unique_domains: Vec<String> = {
            let mut domains: std::collections::HashSet<String> = std::collections::HashSet::new();
            for ticket in &tickets {
                if !ticket.target.is_empty() {
                    domains.insert(ticket.target.clone());
                }
            }
            domains.into_iter().take(5).collect()
        };

        // Send started event
        let started = ThreatHuntingStreamEvent::Started {
            total_domains: unique_domains.len(),
            total_tickets: tickets.len(),
        };
        if let Ok(json) = serde_json::to_string(&started) {
            yield Ok(Event::default().data(json));
        }

        // Process each domain
        let client = match axur_core::api::create_client() {
            Ok(c) => c,
            Err(e) => {
                let event = ThreatHuntingStreamEvent::Error {
                    message: format!("Failed to create HTTP client: {}", e),
                };
                if let Ok(json) = serde_json::to_string(&event) {
                    yield Ok(Event::default().data(json));
                }
                return;
            }
        };

        let auth = format!("Bearer {}", token);
        let mut total_signal_lake: u64 = 0;
        let mut total_chatter: u64 = 0;
        let mut total_credentials: u64 = 0;

        // Determine customer for credits (None = User/Admin, Some = Tenant)
        let use_user_credits = params.use_user_credits;
        let customer_opt = if use_user_credits { None } else { Some(tenant_id.as_str()) };

        for (idx, domain) in unique_domains.iter().enumerate() {
             // Emit processing event
            let processing = ThreatHuntingStreamEvent::DomainProcessing {
                domain: domain.clone(),
                index: idx + 1,
                source: "multi-source".to_string(),
            };
            if let Ok(json) = serde_json::to_string(&processing) {
                yield Ok(Event::default().data(json));
            }

            // 1. Infra Search (Signal Lake)
            let query_infra = format!("domain=\"{}\"", domain);
            if let Ok(count) = axur_core::api::report::start_and_poll_th_search(
                &client, &auth, customer_opt, &query_infra, "signal-lake"
            ).await {
                total_signal_lake += count;
                if count > 0 {
                    let evt = ThreatHuntingStreamEvent::DomainComplete {
                        domain: domain.clone(),
                        source: "signal-lake".to_string(),
                        count,
                    };
                    if let Ok(json) = serde_json::to_string(&evt) { yield Ok(Event::default().data(json)); }
                }
            }

            // 2. Chatter Search
            let query_chatter = format!("content=\"{}\"", domain);
            for source in ["chat-message", "forum-message"] {
                if let Ok(count) = axur_core::api::report::start_and_poll_th_search(
                    &client, &auth, customer_opt, &query_chatter, source
                ).await {
                    total_chatter += count;
                    if count > 0 {
                         let evt = ThreatHuntingStreamEvent::DomainComplete {
                            domain: domain.clone(),
                            source: source.to_string(),
                            count,
                        };
                        if let Ok(json) = serde_json::to_string(&evt) { yield Ok(Event::default().data(json)); }
                    }
                }
            }

            // 3. Credential search is done separately after domain loop
            // (TH doesn't support tag: for credentials, must use Exposure API)

            // Rate limit wait
            tokio::time::sleep(std::time::Duration::from_secs(1)).await;
        }

        // 4. Fetch credentials via Exposure API using the story_tag
        // This is done once, not per-domain, since credentials are tagged with story_tag
        if !story_tag.is_empty() {
            let exposure_url = format!(
                "https://api.axur.com/gateway/1.0/api/exposure-api/credentials?tags=contains:{}&pageSize=100",
                story_tag
            );

            if let Ok(resp) = client.get(&exposure_url)
                .header("Authorization", &auth)
                .send()
                .await
            {
                if resp.status().is_success() {
                    if let Ok(body) = resp.text().await {
                        if let Ok(json) = serde_json::from_str::<serde_json::Value>(&body) {
                            // Get total count from pageable.total
                            if let Some(pageable) = json.get("pageable") {
                                if let Some(total) = pageable.get("total").and_then(|t| t.as_u64()) {
                                    total_credentials = total;

                                    // Emit event for credentials
                                    let evt = ThreatHuntingStreamEvent::DomainComplete {
                                        domain: format!("tag:{}", story_tag),
                                        source: "credential".to_string(),
                                        count: total,
                                    };
                                    if let Ok(json_str) = serde_json::to_string(&evt) {
                                        yield Ok(Event::default().data(json_str));
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }

        // Send finished event
        let total_count = total_signal_lake + total_chatter + total_credentials;
        let estimated_credits = (total_count as f64) * 0.01; // Rough estimate

        let finished = ThreatHuntingStreamEvent::Finished {
            total_count,
            signal_lake_count: total_signal_lake,
            chatter_count: total_chatter,
            credential_count: total_credentials,
            estimated_credits,
        };
        if let Ok(json) = serde_json::to_string(&finished) {
            yield Ok(Event::default().data(json));
        }
    };

    Ok(Sse::new(stream).keep_alive(KeepAlive::default()))
}

/// SSE endpoint for streaming report generation with progress events
/// Uses GET with query params for EventSource compatibility
pub async fn generate_report_stream(
    State(_state): State<AppState>,
    jar: CookieJar,
    axum::extract::Query(params): axum::extract::Query<GenerateReportStreamParams>,
) -> Result<Sse<impl Stream<Item = Result<Event, Infallible>>>, ApiError> {
    let token = jar
        .get(AUTH_COOKIE_NAME)
        .map(|c| c.value().to_string())
        .ok_or_else(|| ApiError::Unauthorized("No session found".into()))?;

    tracing::info!(
        tenant = %params.tenant_id,
        from = %params.from_date,
        to = %params.to_date,
        "Starting SSE Report generation stream"
    );

    // Clone all values for the async stream
    let tenant_id = params.tenant_id.clone();
    let from_date = params.from_date.clone();
    let to_date = params.to_date.clone();
    let language_str = params.language.clone();
    let story_tag = params.story_tag.clone();
    let include_threat_intel = params.include_threat_intel;
    let template_id = params.template_id.clone();
    let use_plugins = params.use_plugins;
    let _plugin_theme = params.plugin_theme.clone();
    let _disabled_slides: Option<Vec<String>> = params
        .disabled_slides
        .as_ref()
        .map(|s| s.split(',').map(|x| x.trim().to_string()).collect());
    // let pool = state.pool.clone(); // Removed: No longer using SQL pool

    let stream = async_stream::stream! {
        // Define stages
        let stages = vec![
            "validating".to_string(),
            "fetching_data".to_string(),
            "processing".to_string(),
            "generating_html".to_string(),
        ];

        // Emit started event
        let started = ReportStreamEvent::Started { stages: stages.clone() };
        if let Ok(json) = serde_json::to_string(&started) {
            yield Ok(Event::default().data(json));
        }

        // Stage 1: Validating
        let progress = ReportStreamEvent::StageProgress {
            stage: "validating".into(),
            message: "Validating request parameters...".into(),
            progress_pct: 10,
        };
        if let Ok(json) = serde_json::to_string(&progress) {
            yield Ok(Event::default().data(json));
        }

        if tenant_id.is_empty() || from_date.is_empty() || to_date.is_empty() {
            let err = ReportStreamEvent::Error {
                code: "RPT-001".into(),
                message: "Invalid request parameters".into(),
            };
            if let Ok(json) = serde_json::to_string(&err) {
                yield Ok(Event::default().data(json));
            }
            return;
        }

        let complete = ReportStreamEvent::StageComplete { stage: "validating".into() };
        if let Ok(json) = serde_json::to_string(&complete) {
            yield Ok(Event::default().data(json));
        }

        // Stage 2: Fetching data
        let progress = ReportStreamEvent::StageProgress {
            stage: "fetching_data".into(),
            message: "Fetching incidents and metrics from Axur API...".into(),
            progress_pct: 25,
        };
        if let Ok(json) = serde_json::to_string(&progress) {
            yield Ok(Event::default().data(json));
        }

        let report_data = match fetch_full_report(
            &token,
            &tenant_id,
            &from_date,
            &to_date,
            story_tag.clone(),
            include_threat_intel,
        )
        .await
        {
            Ok(data) => data,
            Err(e) => {
                let error_code = classify_error(&e.to_string());
                let err = ReportStreamEvent::Error {
                    code: error_code.code(),
                    message: e.to_string(),
                };
                if let Ok(json) = serde_json::to_string(&err) {
                    yield Ok(Event::default().data(json));
                }
                return;
            }
        };

        let complete = ReportStreamEvent::StageComplete { stage: "fetching_data".into() };
        if let Ok(json) = serde_json::to_string(&complete) {
            yield Ok(Event::default().data(json));
        }

        // Stage 3: Processing
        let progress = ReportStreamEvent::StageProgress {
            stage: "processing".into(),
            message: "Processing report data...".into(),
            progress_pct: 60,
        };
        if let Ok(json) = serde_json::to_string(&progress) {
            yield Ok(Event::default().data(json));
        }

        // Get dictionary for selected language
        let language = match language_str.to_lowercase().as_str() {
            "en" => Language::En,
            "pt" | "pt-br" => Language::PtBr,
            _ => Language::Es,
        };
        let dict = get_dictionary(language);

        // Handle custom template if provided
        let mut custom_template_slides: Option<Vec<String>> = None;
        if let Some(ref tid) = template_id {
            // Try mock templates first
            if let Some(tmpl) = crate::routes::templates::get_mock_template(tid) {
                let slides: Vec<String> = tmpl
                    .slides
                    .iter()
                    .filter_map(|s| s.canvas_json.clone())
                    .collect();
                if !slides.is_empty() {
                    custom_template_slides = Some(slides);
                }
            }
            // Try DB templates (Firestore)
            if custom_template_slides.is_none() {
                if let Some(firestore) = crate::firebase::get_firestore() {
                    // Try to finding user_id? We don't have user_id easily here in this context unless we lookup the template globally or search all users?
                    // The original SQL looked up by template ID without user ID?
                    // Wait, original SQL was: `SELECT content FROM user_templates WHERE id = $1`
                    // In Firestore, our schema is `user_templates/{user_id}/items/{template_id}`.
                    // We CANNOT efficienty get a document by ID if we don't know the parent collection path (the user_id).
                    // This is a schema mismatch.

                    // HOWEVER, `user_templates` table in Postgres likely had `id` as primary key global.
                    // In Firestore, we sharded by user.
                    // If we want to support "public" or "shared" templates by ID without knowing user, we need a global index or a "lookup" collection.

                    // For now, let's assume `template_id` might be a "system" template or we have to search.
                    // BUT, `marketplace.rs` has `marketplace_templates`.

                    // Workaround: Since we don't have the user_id of the template owner here (we only have `params`),
                    // we might fail to find private user templates here unless we change the API to pass owner_id.
                    // But `list_docs` on group collection `items`? No, `items` is subcollection.
                    // Firestore Group Query: `firestore.collectionGroup('items').where('id', '==', tid)`
                    // My `firebase.rs` client handles simple paths. It doesn't support collectionGroup queries easily yet.

                    // Quick fix: For now, we only support MOCK templates or we logging a warning that DB template loading is temporarily limited by ID only.
                    // Or, if the User is logged in (we have `token`), we *could* try to use the *current* user's ID as the owner?
                    // In `generate_report_stream`, we decode the session cookie to `token`. We can validate it to get `user_id`.

                    // Let's get the user_id from the cookie
                    let user_id_opt = jar
                        .get(crate::middleware::AUTH_USER_COOKIE_NAME)
                        .map(|c| c.value().to_string())
                        .map(|email| crate::github_storage::GitHubStorage::hash_user_id(&email));

                    if let Some(uid) = user_id_opt {
                         // Try fetching from THIS user's templates
                         let path = format!("user_templates/{}/items", uid);
                         if let Ok(Some(doc)) = firestore.get_doc::<serde_json::Value>(&path, tid).await {
                              if let Some(content) = doc.get("content").and_then(|c| c.as_array()) {
                                  let slides: Vec<String> = content
                                      .iter()
                                      .filter_map(|s| s.get("canvas_json").and_then(|c| c.as_str()).map(|s| s.to_string()))
                                      .collect();
                                   if !slides.is_empty() {
                                       custom_template_slides = Some(slides);
                                   }
                              }
                         }
                    } else {
                        // User not found or invalid session, can't look up private template
                    }
                }
            }
        }

        let complete = ReportStreamEvent::StageComplete { stage: "processing".into() };
        if let Ok(json) = serde_json::to_string(&complete) {
            yield Ok(Event::default().data(json));
        }

        // Stage 4: Generating HTML
        let progress = ReportStreamEvent::StageProgress {
            stage: "generating_html".into(),
            message: "Generating HTML report...".into(),
            progress_pct: 85,
        };
        if let Ok(json) = serde_json::to_string(&progress) {
            yield Ok(Event::default().data(json));
        }

        // Load offline assets (embedded for self-contained HTML)
        let offline_assets = OfflineAssets::load_embedded();

        // Generate HTML
        let html = if use_plugins {
            let lang_code = match language {
                Language::En => "en",
                Language::PtBr => "pt-br",
                Language::Es => "es",
            };
            let translations = match Translations::load(lang_code) {
                Ok(t) => t,
                Err(_) => Translations::load("en").unwrap(),
            };
            generate_report_with_plugins(
                &report_data,
                &translations,
                Some(&offline_assets),
                None, // No custom config
            )
        } else {
            generate_full_report_html(
                &report_data,
                custom_template_slides,
                Some(&offline_assets),
                &dict,
            )
        };

        let complete = ReportStreamEvent::StageComplete { stage: "generating_html".into() };
        if let Ok(json) = serde_json::to_string(&complete) {
            yield Ok(Event::default().data(json));
        }

        // Finished!
        let finished = ReportStreamEvent::Finished {
            html,
            company_name: Some(report_data.company_name.clone()),
        };
        if let Ok(json) = serde_json::to_string(&finished) {
            yield Ok(Event::default().data(json));
        }
    };

    Ok(Sse::new(stream).keep_alive(KeepAlive::default()))
}

```
      ]]>
        </FILE>
        <FILE path="routes\status.rs">
            <![CDATA[
```rs
//! Production status and health check module
//!
//! Provides comprehensive health checks for all services without consuming resources.

use axum::{http::StatusCode, response::IntoResponse, Json};
use serde::Serialize;
use std::env;

/// Simple health endpoint for cold start detection
/// GET /api/health - Returns immediately with minimal response
pub async fn health() -> impl IntoResponse {
    Json(serde_json::json!({
        "status": "ok",
        "timestamp": chrono::Utc::now().to_rfc3339()
    }))
}

/// Service check result
#[derive(Debug, Serialize)]
pub struct ServiceCheck {
    pub name: String,
    pub status: ServiceStatus,
    pub latency_ms: Option<u64>,
    pub message: Option<String>,
    pub version: Option<String>,
}

#[derive(Debug, Serialize)]
#[serde(rename_all = "lowercase")]
pub enum ServiceStatus {
    Ok,
    Degraded,
    Error,
    Unconfigured,
}

/// Full status response
#[derive(Debug, Serialize)]
pub struct StatusResponse {
    pub overall_status: ServiceStatus,
    pub timestamp: String,
    pub backend: BackendInfo,
    pub services: Vec<ServiceCheck>,
    pub environment: EnvironmentInfo,
}

#[derive(Debug, Serialize)]
pub struct BackendInfo {
    pub version: String,
    pub rust_version: String,
    pub build_profile: String,
    pub git_hash: String,
}

#[derive(Debug, Serialize)]
pub struct EnvironmentInfo {
    pub axur_api_configured: bool,
    pub github_logs_configured: bool,
    pub github_feedback_configured: bool,
}

/// Comprehensive status endpoint - checks all services
/// GET /api/status
pub async fn full_status() -> impl IntoResponse {
    let mut services = Vec::new();
    let mut has_errors = false;
    let mut has_degraded = false;

    // 1. Check Axur API connectivity
    let axur_check = check_axur_api().await;
    if matches!(axur_check.status, ServiceStatus::Error) {
        has_errors = true;
    }
    services.push(axur_check);

    // 2. Check GitHub Logs configuration
    let github_logs_check = check_github_logs();
    if matches!(github_logs_check.status, ServiceStatus::Unconfigured) {
        has_degraded = true;
    }
    services.push(github_logs_check);

    // 3. Check GitHub Feedback configuration
    let github_feedback_check = check_github_feedback();
    if matches!(github_feedback_check.status, ServiceStatus::Unconfigured) {
        has_degraded = true;
    }
    services.push(github_feedback_check);

    // 4. Check Firestore connectivity
    let db_check = check_firestore().await;
    if matches!(db_check.status, ServiceStatus::Error) {
        has_errors = true;
    }
    services.push(db_check);

    // Overall status
    let overall_status = if has_errors {
        ServiceStatus::Error
    } else if has_degraded {
        ServiceStatus::Degraded
    } else {
        ServiceStatus::Ok
    };

    let response = StatusResponse {
        overall_status,
        timestamp: chrono::Utc::now().to_rfc3339(),
        backend: BackendInfo {
            version: env!("CARGO_PKG_VERSION").to_string(),
            rust_version: "1.74".to_string(), // Approximate
            build_profile: if cfg!(debug_assertions) {
                "debug".to_string()
            } else {
                "release".to_string()
            },
            git_hash: env::var("GIT_HASH").unwrap_or_else(|_| "unknown".to_string()),
        },
        services,
        environment: EnvironmentInfo {
            axur_api_configured: env::var("AXUR_TOKEN").is_ok(),
            github_logs_configured: env::var("GH_LOGS_REPO").is_ok(),
            github_feedback_configured: env::var("GITHUB_TOKEN").is_ok(),
        },
    };

    let status_code = match response.overall_status {
        ServiceStatus::Ok => StatusCode::OK,
        ServiceStatus::Degraded => StatusCode::OK, // Still operational
        ServiceStatus::Error => StatusCode::SERVICE_UNAVAILABLE,
        ServiceStatus::Unconfigured => StatusCode::OK,
    };

    (status_code, Json(response))
}

/// Check Axur API connectivity (public endpoint)
async fn check_axur_api() -> ServiceCheck {
    let start = std::time::Instant::now();
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(5))
        .build();

    let client = match client {
        Ok(c) => c,
        Err(e) => {
            return ServiceCheck {
                name: "Axur API".into(),
                status: ServiceStatus::Error,
                latency_ms: None,
                message: Some(format!("Failed to create HTTP client: {}", e)),
                version: None,
            };
        }
    };

    // Try to reach Axur's public API endpoint
    let result = client
        .get("https://api.axur.com/gateway/1.0/api/customers/customers")
        .header("Accept", "application/json")
        .send()
        .await;

    let latency = start.elapsed().as_millis() as u64;

    match result {
        Ok(resp) => {
            let status_code = resp.status();
            // 401/403 are expected (no auth), but means API is reachable
            if status_code.as_u16() == 401
                || status_code.as_u16() == 403
                || status_code.is_success()
            {
                ServiceCheck {
                    name: "Axur API".into(),
                    status: ServiceStatus::Ok,
                    latency_ms: Some(latency),
                    message: Some("API reachable".into()),
                    version: None,
                }
            } else {
                ServiceCheck {
                    name: "Axur API".into(),
                    status: ServiceStatus::Degraded,
                    latency_ms: Some(latency),
                    message: Some(format!("Unexpected status: {}", status_code)),
                    version: None,
                }
            }
        }
        Err(e) => ServiceCheck {
            name: "Axur API".into(),
            status: ServiceStatus::Error,
            latency_ms: Some(latency),
            message: Some(format!("Connection failed: {}", e)),
            version: None,
        },
    }
}

/// Check GitHub Logs configuration
fn check_github_logs() -> ServiceCheck {
    let token_ok = env::var("GH_PAT").is_ok() || env::var("GITHUB_TOKEN").is_ok();
    let owner_ok = env::var("GH_OWNER").is_ok() || env::var("GITHUB_OWNER").is_ok();
    let repo_ok = env::var("GH_LOGS_REPO").is_ok() || env::var("GITHUB_LOGS_REPO").is_ok();

    if token_ok && owner_ok && repo_ok {
        ServiceCheck {
            name: "GitHub Logs".into(),
            status: ServiceStatus::Ok,
            latency_ms: None,
            message: Some("Configured".into()),
            version: None,
        }
    } else if token_ok && owner_ok {
        ServiceCheck {
            name: "GitHub Logs".into(),
            status: ServiceStatus::Ok,
            latency_ms: None,
            message: Some("Configured (using default repo)".into()),
            version: None,
        }
    } else {
        let missing: Vec<&str> = [
            if !token_ok {
                Some("GH_PAT/GITHUB_TOKEN")
            } else {
                None
            },
            if !owner_ok {
                Some("GH_OWNER/GITHUB_OWNER")
            } else {
                None
            },
        ]
        .into_iter()
        .flatten()
        .collect();

        ServiceCheck {
            name: "GitHub Logs".into(),
            status: ServiceStatus::Unconfigured,
            latency_ms: None,
            message: Some(format!("Missing: {}", missing.join(", "))),
            version: None,
        }
    }
}

/// Check GitHub Feedback configuration
fn check_github_feedback() -> ServiceCheck {
    let token_ok = env::var("GH_PAT").is_ok() || env::var("GITHUB_TOKEN").is_ok();
    let owner_ok = env::var("GH_OWNER").is_ok() || env::var("GITHUB_OWNER").is_ok();
    let repo_ok = env::var("GH_REPO").is_ok() || env::var("GITHUB_REPO").is_ok();

    if token_ok && owner_ok && repo_ok {
        ServiceCheck {
            name: "GitHub Feedback".into(),
            status: ServiceStatus::Ok,
            latency_ms: None,
            message: Some("Configured".into()),
            version: None,
        }
    } else {
        let missing: Vec<&str> = [
            if !token_ok {
                Some("GH_PAT/GITHUB_TOKEN")
            } else {
                None
            },
            if !owner_ok {
                Some("GH_OWNER/GITHUB_OWNER")
            } else {
                None
            },
            if !repo_ok {
                Some("GH_REPO/GITHUB_REPO")
            } else {
                None
            },
        ]
        .into_iter()
        .flatten()
        .collect();

        ServiceCheck {
            name: "GitHub Feedback".into(),
            status: ServiceStatus::Unconfigured,
            latency_ms: None,
            message: Some(format!("Missing: {}", missing.join(", "))),
            version: None,
        }
    }
}

/// Check Firestore connectivity
async fn check_firestore() -> ServiceCheck {
    let start = std::time::Instant::now();

    if let Some(firestore) = crate::firebase::get_firestore() {
        // Perform a lightweight list operation.
        // We can list `users` with limit 1.
        match firestore.list_docs::<serde_json::Value>("users").await {
            Ok(_) => {
                let duration = start.elapsed().as_millis() as u64;
                ServiceCheck {
                    name: "Firestore".to_string(),
                    status: ServiceStatus::Ok,
                    latency_ms: Some(duration),
                    message: Some("Connected".to_string()),
                    version: None,
                }
            }
            Err(e) => ServiceCheck {
                name: "Firestore".to_string(),
                status: ServiceStatus::Error,
                latency_ms: None,
                message: Some(format!("Connection success but query failed: {}", e)),
                version: None,
            },
        }
    } else {
        ServiceCheck {
            name: "Firestore".to_string(),
            status: ServiceStatus::Error,
            latency_ms: None,
            message: Some("Firestore client not initialized".to_string()),
            version: None,
        }
    }
}

```
      ]]>
        </FILE>
        <FILE path="routes\storage.rs">
            <![CDATA[
```rs
//! User Storage Routes
//!
//! API endpoints for user template storage using GitHub backend

use axum::{
    extract::Path,
    response::IntoResponse,
    routing::{delete, get, post},
    Json, Router,
};
use serde::Deserialize;

use crate::github_storage::get_github_storage;

/// Create storage routes
pub fn storage_routes() -> Router {
    Router::new()
        .route("/templates", get(list_templates))
        .route("/templates", post(save_template))
        .route("/templates/:name", get(load_template))
        .route("/templates/:name", delete(delete_template))
}

/// Request body for saving template
#[derive(Debug, Deserialize)]
pub struct SaveTemplateRequest {
    pub user_id: String,
    pub name: String,
    pub content: String,
}

/// List user's templates
async fn list_templates(Json(payload): Json<serde_json::Value>) -> impl IntoResponse {
    let user_id = payload
        .get("user_id")
        .and_then(|v| v.as_str())
        .unwrap_or("");

    if user_id.is_empty() {
        return Json(serde_json::json!({
            "error": "user_id required"
        }));
    }

    match get_github_storage() {
        Some(storage) => match storage.list_templates(user_id).await {
            Ok(templates) => Json(serde_json::json!({
                "templates": templates
            })),
            Err(e) => Json(serde_json::json!({
                "error": e
            })),
        },
        None => Json(serde_json::json!({
            "error": "Storage not configured",
            "templates": []
        })),
    }
}

/// Save a template
async fn save_template(Json(req): Json<SaveTemplateRequest>) -> impl IntoResponse {
    if req.user_id.is_empty() || req.name.is_empty() {
        return Json(serde_json::json!({
            "error": "user_id and name required"
        }));
    }

    match get_github_storage() {
        Some(storage) => {
            match storage
                .save_template(&req.user_id, &req.name, &req.content)
                .await
            {
                Ok(()) => Json(serde_json::json!({
                    "success": true,
                    "message": format!("Template '{}' saved", req.name)
                })),
                Err(e) => Json(serde_json::json!({
                    "error": e
                })),
            }
        }
        None => Json(serde_json::json!({
            "error": "Storage not configured"
        })),
    }
}

/// Load a template by name
async fn load_template(
    Path(name): Path<String>,
    Json(payload): Json<serde_json::Value>,
) -> impl IntoResponse {
    let user_id = payload
        .get("user_id")
        .and_then(|v| v.as_str())
        .unwrap_or("");

    if user_id.is_empty() {
        return Json(serde_json::json!({
            "error": "user_id required"
        }));
    }

    match get_github_storage() {
        Some(storage) => match storage.load_template(user_id, &name).await {
            Ok(content) => Json(serde_json::json!({
                "name": name,
                "content": content
            })),
            Err(e) => Json(serde_json::json!({
                "error": e
            })),
        },
        None => Json(serde_json::json!({
            "error": "Storage not configured"
        })),
    }
}

/// Delete a template
async fn delete_template(
    Path(name): Path<String>,
    Json(payload): Json<serde_json::Value>,
) -> impl IntoResponse {
    let user_id = payload
        .get("user_id")
        .and_then(|v| v.as_str())
        .unwrap_or("");

    if user_id.is_empty() {
        return Json(serde_json::json!({
            "error": "user_id required"
        }));
    }

    match get_github_storage() {
        Some(storage) => match storage.delete_template(user_id, &name).await {
            Ok(()) => Json(serde_json::json!({
                "success": true,
                "message": format!("Template '{}' deleted", name)
            })),
            Err(e) => Json(serde_json::json!({
                "error": e
            })),
        },
        None => Json(serde_json::json!({
            "error": "Storage not configured"
        })),
    }
}

```
      ]]>
        </FILE>
        <FILE path="routes\templates.rs">
            <![CDATA[
```rs
//! Template CRUD API routes (Simplified version)
//!
//! Uses dynamic queries to avoid compile-time database checks

use axum::{
    extract::{Path, Query, State},
    http::StatusCode,
    response::IntoResponse,
    Extension, Json,
};
use base64::{engine::general_purpose::STANDARD as BASE64, Engine as _};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

use crate::routes::AppState;
use axur_core::editor::PresentationTemplate;

// ==================== TYPES ====================

#[derive(Debug, Serialize, Deserialize)]
pub struct TemplateListItem {
    pub id: String,
    pub name: String,
    pub description: Option<String>,
    pub preview_image_url: Option<String>,
    pub created_at: String,
    pub updated_at: String,
}

#[derive(Debug, Deserialize)]
pub struct RawSlide {
    pub id: Option<String>,
    pub name: String,
    pub canvas_json: Option<serde_json::Value>,
}

#[derive(Debug, Deserialize)]
pub struct CreateTemplateRequest {
    pub name: String,
    pub description: Option<String>,
    pub slides: Vec<RawSlide>,
}

#[derive(Debug, Deserialize)]
pub struct UpdateTemplateRequest {
    pub name: Option<String>,
    pub description: Option<String>,
    pub template: Option<PresentationTemplate>,
}

/// Frontend-compatible template detail (uses serde_json::Value for slides)
#[derive(Debug, Clone, Serialize)]
pub struct TemplateDetail {
    pub id: String,
    pub name: String,
    pub description: Option<String>,
    pub slides: Vec<serde_json::Value>,
}

impl TemplateDetail {
    /// Convert from PresentationTemplate to frontend-compatible TemplateDetail
    pub fn from_template(id: &str, template: &PresentationTemplate) -> Self {
        let slides: Vec<serde_json::Value> = template
            .slides
            .iter()
            .enumerate()
            .map(|(_i, slide)| {
                serde_json::json!({
                    "id": slide.id.to_string(),
                    "name": slide.name.clone(),
                    "canvas_json": slide.canvas_json.clone().unwrap_or_default()
                })
            })
            .collect();

        Self {
            id: id.to_string(),
            name: template.name.clone(),
            description: template.description.clone(),
            slides,
        }
    }
}

#[derive(Debug, Serialize)]
pub struct TemplateResponse {
    pub success: bool,
    pub id: Option<String>,
    pub message: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub template: Option<TemplateDetail>,
}

#[derive(Debug, Deserialize)]
pub struct ListTemplatesQuery {
    pub limit: Option<i32>,
    pub offset: Option<i32>,
}

// ==================== GITHUB STORAGE ====================

#[derive(Clone)]
pub struct GitHubConfig {
    pub token: String,
    pub owner: String,
    pub repo: String,
}

impl GitHubConfig {
    pub fn from_env() -> Option<Self> {
        Some(Self {
            token: std::env::var("GITHUB_TOKEN").ok()?,
            owner: std::env::var("GITHUB_OWNER").unwrap_or_else(|_| "maisonnat".to_string()),
            repo: std::env::var("GITHUB_LOGS_REPO")
                .unwrap_or_else(|_| "axur-logs-private".to_string()),
        })
    }
}

async fn get_file_sha(config: &GitHubConfig, path: &str) -> Option<String> {
    let url = format!(
        "https://api.github.com/repos/{}/{}/contents/{}",
        config.owner, config.repo, path
    );

    let client = reqwest::Client::new();
    let res = client
        .get(&url)
        .header("Authorization", format!("Bearer {}", config.token))
        .header("User-Agent", "axur-bot")
        .send()
        .await
        .ok()?;

    if res.status().is_success() {
        let json: serde_json::Value = res.json().await.ok()?;
        json.get("sha")?.as_str().map(|s| s.to_string())
    } else {
        None
    }
}

async fn upload_template_to_github(
    config: &GitHubConfig,
    path: &str,
    template: &PresentationTemplate,
) -> Result<String, String> {
    let content = serde_json::to_string_pretty(template)
        .map_err(|e| format!("Serialization error: {}", e))?;

    let url = format!(
        "https://api.github.com/repos/{}/{}/contents/{}",
        config.owner, config.repo, path
    );

    let encoded = BASE64.encode(content.as_bytes());
    let sha = get_file_sha(config, path).await;

    let mut body = serde_json::json!({
        "message": format!("Update template: {}", template.name),
        "content": encoded,
        "committer": { "name": "Axur Bot", "email": "bot@axur.local" }
    });

    if let Some(s) = sha {
        body["sha"] = serde_json::json!(s);
    }

    let client = reqwest::Client::new();
    let res = client
        .put(&url)
        .header("Authorization", format!("Bearer {}", config.token))
        .header("User-Agent", "axur-bot")
        .header("Accept", "application/vnd.github.v3+json")
        .json(&body)
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if res.status().is_success() {
        let json: serde_json::Value = res.json().await.map_err(|e| e.to_string())?;
        Ok(json
            .get("content")
            .and_then(|c| c.get("html_url"))
            .and_then(|u| u.as_str())
            .unwrap_or("")
            .to_string())
    } else {
        Err(format!("GitHub upload failed: {}", res.status()))
    }
}

async fn upload_file_to_github(
    config: &GitHubConfig,
    path: &str,
    content: &[u8],
    commit_msg: &str,
) -> Result<String, String> {
    let encoded = BASE64.encode(content);
    let sha = get_file_sha(config, path).await;

    let mut body = serde_json::json!({
        "message": commit_msg,
        "content": encoded,
        "committer": { "name": "Axur Bot", "email": "bot@axur.local" }
    });

    if let Some(s) = sha {
        body["sha"] = serde_json::json!(s);
    }

    let url = format!(
        "https://api.github.com/repos/{}/{}/contents/{}",
        config.owner, config.repo, path
    );

    let client = reqwest::Client::new();
    let res = client
        .put(&url)
        .header("Authorization", format!("Bearer {}", config.token))
        .header("User-Agent", "axur-bot")
        .header("Accept", "application/vnd.github.v3+json")
        .json(&body)
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if res.status().is_success() {
        let json: serde_json::Value = res.json().await.map_err(|e| e.to_string())?;
        Ok(json
            .get("content")
            .and_then(|c| c.get("html_url"))
            .and_then(|u| u.as_str())
            .unwrap_or("")
            .to_string())
    } else {
        Err(format!("GitHub upload failed: {}", res.status()))
    }
}

/// Fetch raw file content (binary) from GitHub
pub async fn fetch_raw_file_from_github(
    config: &GitHubConfig,
    path: &str,
) -> Result<Vec<u8>, String> {
    let url = format!(
        "https://api.github.com/repos/{}/{}/contents/{}",
        config.owner, config.repo, path
    );

    let client = reqwest::Client::new();
    let res = client
        .get(&url)
        .header("Authorization", format!("Bearer {}", config.token))
        .header("User-Agent", "axur-bot")
        .header("Accept", "application/vnd.github.v3+json")
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if !res.status().is_success() {
        return Err(format!("GitHub fetch failed: {}", res.status()));
    }

    let json: serde_json::Value = res.json().await.map_err(|e| e.to_string())?;

    // Check if it's a file
    let type_ = json.get("type").and_then(|t| t.as_str()).unwrap_or("");
    if type_ != "file" {
        return Err("Not a file".to_string());
    }

    let content_b64 = json
        .get("content")
        .and_then(|c| c.as_str())
        .map(|s| s.replace('\n', ""))
        .ok_or_else(|| "No content found".to_string())?;

    BASE64
        .decode(content_b64)
        .map_err(|e| format!("Base64 decode failed: {}", e))
}

#[allow(dead_code)]
pub async fn fetch_template_from_github(
    config: &GitHubConfig,
    path: &str,
) -> Result<PresentationTemplate, String> {
    let url = format!(
        "https://api.github.com/repos/{}/{}/contents/{}",
        config.owner, config.repo, path
    );

    let client = reqwest::Client::new();
    let res = client
        .get(&url)
        .header("Authorization", format!("Bearer {}", config.token))
        .header("User-Agent", "axur-bot")
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if !res.status().is_success() {
        return Err(format!("Template not found: {}", res.status()));
    }

    let json: serde_json::Value = res.json().await.map_err(|e| e.to_string())?;
    let encoded = json
        .get("content")
        .and_then(|c| c.as_str())
        .ok_or("Missing content")?;

    let clean: String = encoded.chars().filter(|c| !c.is_whitespace()).collect();
    let decoded = BASE64.decode(&clean).map_err(|e| e.to_string())?;
    let content = String::from_utf8(decoded).map_err(|e| e.to_string())?;

    serde_json::from_str(&content).map_err(|e| e.to_string())
}

// ==================== ENDPOINTS ====================

/// GET /api/templates - List user's templates
pub async fn list_templates(
    State(_state): State<AppState>,
    Extension(user_id): Extension<String>,
    Query(_params): Query<ListTemplatesQuery>,
) -> impl IntoResponse {
    // Try Firestore first
    if let Some(firestore) = crate::firebase::get_firestore() {
        // Collection path: user_templates/{user_id} - documents are the templates
        let collection = format!("user_templates/{}/items", user_id);

        match firestore.list_docs::<TemplateListItem>(&collection).await {
            Ok(templates) => {
                tracing::debug!(
                    "Found {} templates for user {} from Firestore",
                    templates.len(),
                    user_id
                );
                return (
                    StatusCode::OK,
                    Json(serde_json::json!({
                        "success": true,
                        "templates": templates,
                        "total": templates.len(),
                        "source": "firestore"
                    })),
                );
            }
            Err(crate::firebase::FirestoreError::RateLimited) => {
                tracing::warn!("Firestore rate limited, returning empty list");
            }
            Err(e) => {
                tracing::warn!("Firestore error: {}, returning empty list", e);
            }
        }
    } else {
        tracing::debug!("Firestore not configured, returning empty list");
    }

    // Fallback: return empty list
    (
        StatusCode::OK,
        Json(serde_json::json!({
            "success": true,
            "templates": [],
            "total": 0,
            "source": "fallback"
        })),
    )
}

/// POST /api/templates - Create a new template (Multipart)
/// POST /api/templates - Create a new template (Multipart)
pub async fn create_template(
    State(_state): State<AppState>,
    Extension(user_id): Extension<String>,
    mut multipart: axum::extract::Multipart,
) -> impl IntoResponse {
    // 1. Parse Multipart Data
    let mut req: Option<CreateTemplateRequest> = None;
    let mut file_data: Option<Vec<u8>> = None;

    while let Ok(Some(field)) = multipart.next_field().await {
        let name = field.name().unwrap_or("").to_string();
        if name == "metadata" {
            let data = field.text().await.unwrap_or_default();
            if let Ok(parsed) = serde_json::from_str::<CreateTemplateRequest>(&data) {
                req = Some(parsed);
            }
        } else if name == "file" {
            if let Ok(bytes) = field.bytes().await {
                file_data = Some(bytes.to_vec());
            }
        }
    }

    let req = match req {
        Some(r) => r,
        None => {
            return (
                StatusCode::BAD_REQUEST,
                Json(TemplateResponse {
                    success: false,
                    id: None,
                    message: "Metadata field required".to_string(),
                    template: None,
                }),
            )
        }
    };

    if req.name.is_empty() {
        return (
            StatusCode::BAD_REQUEST,
            Json(TemplateResponse {
                success: false,
                id: None,
                message: "Name is required".to_string(),
                template: None,
            }),
        );
    }

    // 2. Setup GitHub & Firestore
    let config = match GitHubConfig::from_env() {
        Some(c) => c,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(TemplateResponse {
                    success: false,
                    id: None,
                    message: "GitHub not configured".to_string(),
                    template: None,
                }),
            );
        }
    };

    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(TemplateResponse {
                    success: false,
                    id: None,
                    message: "Storage not available".to_string(),
                    template: None,
                }),
            );
        }
    };

    let template_id = Uuid::new_v4();
    // GitHub Path: templates/{user_id}/{template_id}/metadata.json
    let metadata_path = format!("templates/{}/{}/metadata.json", user_id, template_id);
    let pptx_path = format!("templates/{}/{}/base.pptx", user_id, template_id);

    // 3. Create Template Object
    // Parse slides if available (indirectly via CreateTemplateRequest having slides)
    // We reuse the slide parsing from previous implementation or assume simplified object for metadata
    // The previous implementation for GitHub upload had logic to convert RawSlide to SlideDefinition.
    // If we want to support full editor templates, we need that logic.
    // For now, minimal object to satisfy types:
    let slides: Vec<axur_core::editor::SlideDefinition> = req
        .slides
        .iter()
        .enumerate()
        .map(|(i, s)| axur_core::editor::SlideDefinition {
            id: s
                .id
                .as_ref()
                .and_then(|i| Uuid::parse_str(i).ok())
                .unwrap_or_else(Uuid::new_v4),
            name: s.name.clone(),
            canvas_json: s.canvas_json.as_ref().map(|v| v.to_string()),
            order: i as i32,
            ..Default::default()
        })
        .collect();

    let template_obj = PresentationTemplate {
        id: template_id,
        name: req.name.clone(),
        description: req.description.clone(),
        slides,
        theme: axur_core::editor::Theme::default(),
        version: "1.0.0".to_string(),
    };

    // 4. Upload Metadata to GitHub
    if let Err(e) = upload_template_to_github(&config, &metadata_path, &template_obj).await {
        return (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(TemplateResponse {
                success: false,
                id: None,
                message: format!("Metadata upload failed: {}", e),
                template: None,
            }),
        );
    }

    // 5. Upload Base PPTX if provided
    if let Some(bytes) = file_data {
        if let Err(e) = upload_file_to_github(
            &config,
            &pptx_path,
            &bytes,
            &format!("Add base PPTX for {}", req.name),
        )
        .await
        {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(TemplateResponse {
                    success: false,
                    id: None,
                    message: format!("PPTX upload failed: {}", e),
                    template: None,
                }),
            );
        }
    }

    // 6. Save metadata to Firestore
    // Path: user_templates/{user_id}/items/{template_id}
    let created_at = chrono::Utc::now().to_rfc3339();
    let template_doc = serde_json::json!({
        "id": template_id.to_string(),
        "name": req.name,
        "description": req.description,
        "github_path": metadata_path,
        "created_at": created_at,
        "updated_at": created_at
    });

    match firestore
        .set_doc(
            &format!("user_templates/{}/items", user_id),
            &template_id.to_string(),
            &template_doc,
        )
        .await
    {
        Ok(_) => (
            StatusCode::CREATED,
            Json(TemplateResponse {
                success: true,
                id: Some(template_id.to_string()),
                message: "Template created".to_string(),
                template: None,
            }),
        ),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(TemplateResponse {
                success: false,
                id: None,
                message: format!("Failed to save metadata: {}", e),
                template: None,
            }),
        ),
    }
}

/// Helper to get mock templates
pub fn get_mock_template(id: &str) -> Option<PresentationTemplate> {
    // ===== AXUR OFFICIAL DESIGN SYSTEM =====
    // Background: #09090b (zinc-950), #18181b (zinc-900)
    // Cards: #27272a (zinc-800) with rx/ry: 12
    // Accent: #f97316 (orange-500)
    // Text: #ffffff (primary), #a1a1aa (zinc-400 secondary), #52525b (zinc-600 muted)
    // Success: #22c55e (green-500)
    // Warning: #f59e0b (amber-500)
    // Danger: #ef4444 (red-500)

    // Template 1: Axur Official - Cover Slide Style
    let json_official = r##"{
      "version": "5.3.0",
      "objects": [
        { "type": "rect", "left": 0, "top": 0, "width": 1280, "height": 720, "fill": "#09090b", "selectable": false },
        { "type": "rect", "left": 0, "top": 0, "width": 1280, "height": 8, "fill": "#f97316", "selectable": false },
        { "type": "rect", "left": 60, "top": 80, "width": 90, "height": 32, "fill": "#f97316", "rx": 2, "ry": 2 },
        { "type": "text", "left": 75, "top": 85, "fill": "#ffffff", "text": "TLP:AMBER", "fontSize": 14, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 60, "top": 150, "fill": "#ffffff", "text": "INFORME", "fontSize": 64, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "text", "left": 60, "top": 220, "fill": "#ffffff", "text": "EJECUTIVO", "fontSize": 64, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "text", "left": 60, "top": 320, "fill": "#f97316", "text": "Compaa", "fontSize": 16, "fontFamily": "Inter", "fontWeight": "600" },
        { "type": "text", "left": 60, "top": 345, "fill": "#ffffff", "text": "{{company_name}}", "fontSize": 32, "fontFamily": "Inter" },
        { "type": "text", "left": 60, "top": 410, "fill": "#f97316", "text": "Perodo", "fontSize": 16, "fontFamily": "Inter", "fontWeight": "600" },
        { "type": "text", "left": 60, "top": 435, "fill": "#ffffff", "text": "{{date_range}}", "fontSize": 24, "fontFamily": "Inter" },
        { "type": "text", "left": 60, "top": 660, "fill": "#f97316", "text": "/// AXUR", "fontSize": 24, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 900, "top": 665, "fill": "#52525b", "text": "Digital experiences made safe.", "fontSize": 12, "fontFamily": "Inter" }
      ]
    }"##;

    // Template 2: Executive Summary - KPI Dashboard
    let json_executive = r##"{
      "version": "5.3.0",
      "objects": [
        { "type": "rect", "left": 0, "top": 0, "width": 1280, "height": 720, "fill": "#18181b", "selectable": false },
        { "type": "text", "left": 60, "top": 40, "fill": "#f97316", "text": "Resumen Ejecutivo", "fontSize": 36, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "rect", "left": 60, "top": 110, "width": 360, "height": 180, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 90, "top": 140, "fill": "#a1a1aa", "text": "SEALES DETECTADAS", "fontSize": 12, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 90, "top": 180, "fill": "#ffffff", "text": "{{signals}}", "fontSize": 56, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "rect", "left": 460, "top": 110, "width": 360, "height": 180, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 490, "top": 140, "fill": "#a1a1aa", "text": "INCIDENTES CONFIRMADOS", "fontSize": 12, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 490, "top": 180, "fill": "#f97316", "text": "{{incidents}}", "fontSize": 56, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "rect", "left": 860, "top": 110, "width": 360, "height": 180, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 890, "top": 140, "fill": "#a1a1aa", "text": "AMENAZAS ACTIVAS", "fontSize": 12, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 890, "top": 180, "fill": "#ef4444", "text": "{{threats}}", "fontSize": 56, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "rect", "left": 60, "top": 320, "width": 360, "height": 180, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 90, "top": 350, "fill": "#a1a1aa", "text": "CREDENCIALES EXPUESTAS", "fontSize": 12, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 90, "top": 390, "fill": "#f59e0b", "text": "{{credentials}}", "fontSize": 56, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "rect", "left": 460, "top": 320, "width": 360, "height": 180, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 490, "top": 350, "fill": "#a1a1aa", "text": "TAKEDOWNS RESUELTOS", "fontSize": 12, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 490, "top": 390, "fill": "#22c55e", "text": "{{takedowns}}", "fontSize": 56, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "rect", "left": 860, "top": 320, "width": 360, "height": 180, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 890, "top": 350, "fill": "#a1a1aa", "text": "FUGAS DE CDIGO", "fontSize": 12, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 890, "top": 390, "fill": "#a855f7", "text": "{{code_leaks}}", "fontSize": 56, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "text", "left": 60, "top": 660, "fill": "#f97316", "text": "/// AXUR", "fontSize": 20, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 1180, "top": 665, "fill": "#52525b", "text": "2", "fontSize": 12, "fontFamily": "Inter" }
      ]
    }"##;

    // Template 3: Risk Assessment - Focus on Risk Score
    let json_risk = r##"{
      "version": "5.3.0",
      "objects": [
        { "type": "rect", "left": 0, "top": 0, "width": 1280, "height": 720, "fill": "#18181b", "selectable": false },
        { "type": "text", "left": 60, "top": 40, "fill": "#f97316", "text": "Evaluacin de Riesgo", "fontSize": 36, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "rect", "left": 60, "top": 110, "width": 500, "height": 450, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 230, "top": 140, "fill": "#a1a1aa", "text": "RISK SCORE", "fontSize": 14, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 180, "top": 220, "fill": "#f59e0b", "text": "{{risk_score}}", "fontSize": 140, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "text", "left": 210, "top": 400, "fill": "#ffffff", "text": "{{risk_label}}", "fontSize": 32, "fontFamily": "Inter", "fontWeight": "600" },
        { "type": "text", "left": 150, "top": 480, "fill": "#a1a1aa", "text": "Vectores: Phishing, Brand Abuse", "fontSize": 14, "fontFamily": "Inter" },
        { "type": "rect", "left": 600, "top": 110, "width": 620, "height": 210, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 640, "top": 140, "fill": "#a1a1aa", "text": "PRINCIPALES AMENAZAS", "fontSize": 12, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 640, "top": 180, "fill": "#ef4444", "text": " Credential Leak (Critical)", "fontSize": 18, "fontFamily": "Inter" },
        { "type": "text", "left": 640, "top": 220, "fill": "#f59e0b", "text": " Phishing Campaign #129", "fontSize": 18, "fontFamily": "Inter" },
        { "type": "text", "left": 640, "top": 260, "fill": "#a1a1aa", "text": " Suspicious Domain Registration", "fontSize": 18, "fontFamily": "Inter" },
        { "type": "rect", "left": 600, "top": 350, "width": 620, "height": 210, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 640, "top": 380, "fill": "#a1a1aa", "text": "RECOMENDACIONES", "fontSize": 12, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 640, "top": 420, "fill": "#ffffff", "text": "1. Reset admin passwords", "fontSize": 16, "fontFamily": "Inter" },
        { "type": "text", "left": 640, "top": 460, "fill": "#ffffff", "text": "2. Enable 2FA on VPN", "fontSize": 16, "fontFamily": "Inter" },
        { "type": "text", "left": 640, "top": 500, "fill": "#ffffff", "text": "3. Review access logs", "fontSize": 16, "fontFamily": "Inter" },
        { "type": "text", "left": 60, "top": 660, "fill": "#f97316", "text": "/// AXUR", "fontSize": 20, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 1180, "top": 665, "fill": "#52525b", "text": "3", "fontSize": 12, "fontFamily": "Inter" }
      ]
    }"##;

    // Template 4: Takedowns Performance
    let json_takedowns = r##"{
      "version": "5.3.0",
      "objects": [
        { "type": "rect", "left": 0, "top": 0, "width": 1280, "height": 720, "fill": "#18181b", "selectable": false },
        { "type": "text", "left": 60, "top": 40, "fill": "#f97316", "text": "Takedowns", "fontSize": 36, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "rect", "left": 60, "top": 110, "width": 360, "height": 130, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 90, "top": 140, "fill": "#22c55e", "text": "{{resolved}}", "fontSize": 48, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "text", "left": 200, "top": 155, "fill": "#a1a1aa", "text": "Resueltos", "fontSize": 20, "fontFamily": "Inter" },
        { "type": "rect", "left": 60, "top": 260, "width": 360, "height": 130, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 90, "top": 290, "fill": "#f59e0b", "text": "{{pending}}", "fontSize": 48, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "text", "left": 200, "top": 305, "fill": "#a1a1aa", "text": "Pendientes", "fontSize": 20, "fontFamily": "Inter" },
        { "type": "rect", "left": 60, "top": 410, "width": 360, "height": 130, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 90, "top": 440, "fill": "#ef4444", "text": "{{aborted}}", "fontSize": 48, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "text", "left": 200, "top": 455, "fill": "#a1a1aa", "text": "Cancelados", "fontSize": 20, "fontFamily": "Inter" },
        { "type": "rect", "left": 480, "top": 110, "width": 740, "height": 430, "fill": "#27272a", "rx": 12, "ry": 12 },
        { "type": "text", "left": 750, "top": 200, "fill": "#f97316", "text": "{{success_rate}}%", "fontSize": 120, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "text", "left": 720, "top": 380, "fill": "#a1a1aa", "text": "Tasa de xito", "fontSize": 28, "fontFamily": "Inter" },
        { "type": "text", "left": 60, "top": 660, "fill": "#f97316", "text": "/// AXUR", "fontSize": 20, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 1180, "top": 665, "fill": "#52525b", "text": "4", "fontSize": 12, "fontFamily": "Inter" }
      ]
    }"##;

    // Template 5: Closing / Thank You Slide
    let json_closing = r##"{
      "version": "5.3.0",
      "objects": [
        { "type": "rect", "left": 0, "top": 0, "width": 1280, "height": 720, "fill": "#09090b", "selectable": false },
        { "type": "text", "left": 540, "top": 200, "fill": "#f97316", "text": "/// AXUR", "fontSize": 48, "fontFamily": "Inter", "fontWeight": "bold" },
        { "type": "text", "left": 520, "top": 300, "fill": "#ffffff", "text": "Gracias", "fontSize": 72, "fontFamily": "Inter", "fontWeight": "900" },
        { "type": "text", "left": 450, "top": 400, "fill": "#a1a1aa", "text": "{{company_name}}", "fontSize": 32, "fontFamily": "Inter" },
        { "type": "text", "left": 380, "top": 480, "fill": "#52525b", "text": "Informe generado automticamente por Axur CLI", "fontSize": 18, "fontFamily": "Inter" },
        { "type": "text", "left": 530, "top": 530, "fill": "#3f3f46", "text": "{{date_range}}", "fontSize": 16, "fontFamily": "Inter" },
        { "type": "text", "left": 340, "top": 660, "fill": "#3f3f46", "text": "Axur. Digital experiences made safe. All rights reserved.", "fontSize": 12, "fontFamily": "Inter" }
      ]
    }"##;

    match id {
        "1" | "axur_official" => Some(PresentationTemplate {
            name: "Axur Official".to_string(),
            slides: vec![axur_core::editor::SlideDefinition {
                canvas_json: Some(json_official.to_string()),
                ..Default::default()
            }],
            ..Default::default()
        }),
        "2" | "executive" => Some(PresentationTemplate {
            name: "Executive Summary".to_string(),
            slides: vec![axur_core::editor::SlideDefinition {
                canvas_json: Some(json_executive.to_string()),
                ..Default::default()
            }],
            ..Default::default()
        }),
        "3" | "risk" => Some(PresentationTemplate {
            name: "Risk Focus".to_string(),
            slides: vec![axur_core::editor::SlideDefinition {
                canvas_json: Some(json_risk.to_string()),
                ..Default::default()
            }],
            ..Default::default()
        }),
        "4" | "technical" => Some(PresentationTemplate {
            name: "Technical Deep Dive".to_string(),
            slides: vec![axur_core::editor::SlideDefinition {
                canvas_json: Some(json_takedowns.to_string()),
                ..Default::default()
            }],
            ..Default::default()
        }),
        "5" | "compliance" => Some(PresentationTemplate {
            name: "Compliance Report".to_string(),
            slides: vec![axur_core::editor::SlideDefinition {
                canvas_json: Some(json_closing.to_string()),
                ..Default::default()
            }],
            ..Default::default()
        }),
        _ => None,
    }
}

/// GET /api/templates/:id
pub async fn get_template(Path(template_id): Path<String>) -> impl IntoResponse {
    // Check for mock templates first (no auth/db needed for these)
    if let Some(mock) = get_mock_template(&template_id) {
        return (
            StatusCode::OK,
            Json(TemplateResponse {
                success: true,
                id: Some(template_id.clone()),
                message: "Template loaded (Mock)".to_string(),
                template: Some(TemplateDetail::from_template(&template_id, &mock)),
            }),
        );
    }

    // For non-mock templates, return not found on public route
    // User templates should be accessed via authenticated route
    (
        StatusCode::NOT_FOUND,
        Json(TemplateResponse {
            success: false,
            id: None,
            message: format!("Template '{}' not found", template_id),
            template: None,
        }),
    )
}

/// PUT /api/templates/:id
pub async fn update_template(
    State(_state): State<AppState>,
    Extension(user_id): Extension<String>,
    Path(template_id): Path<String>,
    Json(req): Json<UpdateTemplateRequest>,
) -> impl IntoResponse {
    let config = match GitHubConfig::from_env() {
        Some(c) => c,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(TemplateResponse {
                    success: false,
                    id: None,
                    message: "GitHub not configured".to_string(),
                    template: None,
                }),
            );
        }
    };

    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(TemplateResponse {
                    success: false,
                    id: None,
                    message: "Storage not available".to_string(),
                    template: None,
                }),
            );
        }
    };

    // Get current template metadata from Firestore
    // Path: user_templates/{user_id}/items/{template_id}
    let current_meta: serde_json::Value = match firestore
        .get_doc(&format!("user_templates/{}/items", user_id), &template_id)
        .await
    {
        Ok(Some(doc)) => doc,
        Ok(None) => {
            return (
                StatusCode::NOT_FOUND,
                Json(TemplateResponse {
                    success: false,
                    id: None,
                    message: "Not found".to_string(),
                    template: None,
                }),
            );
        }
        Err(e) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(TemplateResponse {
                    success: false,
                    id: None,
                    message: e.to_string(),
                    template: None,
                }),
            );
        }
    };

    let github_path = current_meta
        .get("github_path")
        .and_then(|v| v.as_str())
        .unwrap_or_default()
        .to_string();

    // Update GitHub if content changed
    if let Some(ref template) = req.template {
        if !github_path.is_empty() {
            if let Err(e) = upload_template_to_github(&config, &github_path, template).await {
                return (
                    StatusCode::INTERNAL_SERVER_ERROR,
                    Json(TemplateResponse {
                        success: false,
                        id: None,
                        message: e,
                        template: None,
                    }),
                );
            }
        }
    }

    // Update metadata
    let current_name = current_meta
        .get("name")
        .and_then(|v| v.as_str())
        .unwrap_or("");
    let current_desc = current_meta.get("description").and_then(|v| v.as_str());

    let new_name = req
        .name
        .as_ref()
        .map(|s| s.as_str())
        .unwrap_or(current_name);
    let new_desc = req
        .description
        .as_ref()
        .map(|s| s.as_str())
        .or(current_desc);

    // Merge updates
    let mut update = current_meta.clone();
    if let Some(obj) = update.as_object_mut() {
        obj.insert("name".to_string(), serde_json::json!(new_name));
        obj.insert("description".to_string(), serde_json::json!(new_desc));
        obj.insert(
            "updated_at".to_string(),
            serde_json::json!(chrono::Utc::now().to_rfc3339()),
        );
    }

    // Save back to Firestore
    match firestore
        .update_doc(
            &format!("user_templates/{}/items", user_id),
            &template_id,
            &update,
        )
        .await
    {
        Ok(_) => (
            StatusCode::OK,
            Json(TemplateResponse {
                success: true,
                id: Some(template_id),
                message: "Updated".to_string(),
                template: None,
            }),
        ),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(TemplateResponse {
                success: false,
                id: None,
                message: e.to_string(),
                template: None,
            }),
        ),
    }
}

/// DELETE /api/templates/:id
pub async fn delete_template(
    State(_state): State<AppState>,
    Extension(user_id): Extension<String>,
    Path(template_id): Path<String>,
) -> impl IntoResponse {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(TemplateResponse {
                    success: false,
                    id: None,
                    message: "Storage not available".to_string(),
                    template: None,
                }),
            );
        }
    };

    // Delete from Firestore
    // Path: user_templates/{user_id}/items/{template_id}
    match firestore
        .delete_doc(&format!("user_templates/{}/items", user_id), &template_id)
        .await
    {
        Ok(_) => {
            // TODO: Delete from GitHub as well.
            // For now, metadata is gone so it won't show up.
            (
                StatusCode::OK,
                Json(TemplateResponse {
                    success: true,
                    id: Some(template_id),
                    message: "Deleted".to_string(),
                    template: None,
                }),
            )
        }
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR, // Or not found?
            Json(TemplateResponse {
                success: false,
                id: None,
                message: e.to_string(),
                template: None,
            }),
        ),
    }
}

// ==================== HELPERS ====================
// ensure_user_exists removed as it was only for SQL users table management

/// GET /api/templates/:id/pptx - Get the base PPTX file of a template
pub async fn get_template_pptx(
    State(_state): State<AppState>,
    Extension(user_id): Extension<String>,
    Path(template_id): Path<String>,
) -> impl IntoResponse {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({ "success": false, "error": "Storage not available" })),
            );
        }
    };

    let config = match GitHubConfig::from_env() {
        Some(c) => c,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({ "success": false, "error": "GitHub not configured" })),
            );
        }
    };

    // Get template info
    // Path: user_templates/{user_id}/items/{template_id}
    let meta: serde_json::Value = match firestore
        .get_doc(&format!("user_templates/{}/items", user_id), &template_id)
        .await
    {
        Ok(Some(doc)) => doc,
        Ok(None) => {
            return (
                StatusCode::NOT_FOUND,
                Json(serde_json::json!({ "success": false, "error": "Template not found" })),
            );
        }
        Err(e) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({ "success": false, "error": e.to_string() })),
            );
        }
    };

    let github_path = meta
        .get("github_path")
        .and_then(|v| v.as_str())
        .unwrap_or_default()
        .to_string();

    if github_path.is_empty() {
        return (
            StatusCode::NOT_FOUND,
            Json(serde_json::json!({ "success": false, "error": "No GitHub path for template" })),
        );
    }

    // Construct PPTX path from metadata path
    // metadata is at: templates/{user_id}/{template_id}/metadata.json
    // PPTX is at: templates/{user_id}/{template_id}/base.pptx
    let pptx_path = github_path.replace("metadata.json", "base.pptx");

    tracing::info!("Fetching PPTX from: {}", pptx_path);

    // Fetch PPTX from GitHub
    match fetch_raw_file_from_github(&config, &pptx_path).await {
        Ok(bytes) => {
            let base64_pptx = BASE64.encode(&bytes);
            (
                StatusCode::OK,
                Json(serde_json::json!({
                    "success": true,
                    "pptx_base64": base64_pptx,
                    "size_bytes": bytes.len()
                })),
            )
        }
        Err(e) => (
            StatusCode::NOT_FOUND,
            Json(serde_json::json!({
                "success": false,
                "error": format!("PPTX file not found: {}", e)
            })),
        ),
    }
}

// ==================== AUTO-SAVE ENDPOINTS (Firestore-only, no GitHub) ====================

/// Request for quick save (auto-save feature)
#[derive(Debug, Deserialize)]
pub struct QuickSaveRequest {
    /// Template name
    pub name: String,
    /// Optional description
    pub description: Option<String>,
    /// Slides content as JSON (array of slide objects with canvas_json)
    pub slides: serde_json::Value,
}

/// Response for quick-save operations
#[derive(Debug, Serialize)]
pub struct QuickSaveResponse {
    pub success: bool,
    pub id: String,
    pub message: String,
    pub saved_at: String,
}

/// POST /api/templates/quick-save - Create or update template in Firestore (draft)
/// This is the fast path for auto-save functionality
pub async fn quick_save_template(
    State(_state): State<AppState>,
    Extension(user_id): Extension<String>,
    Json(req): Json<QuickSaveRequest>,
) -> impl IntoResponse {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(QuickSaveResponse {
                    success: false,
                    id: String::new(),
                    message: "Storage not available".to_string(),
                    saved_at: String::new(),
                }),
            )
        }
    };

    // For quick save, we might need an ID. If specific ID not provided in request (not here yet),
    // we assume it's a new one or based on name?
    // Wait, the original code checked if name exists to update or insert.
    // Firestore scanning for name is expensive.
    // Ideally quick-save should take an ID if it's an update.
    // The request struct doesn't have ID.
    // So we search by name?
    // Firestore `list_docs` can be filtered? No, REST API basic list.
    // We can list all docs and find by name (inefficient) or assume client provides ID.
    // Original implementation: `SELECT id FROM user_templates WHERE user_id = $1 AND name = $2`

    // Compromise: We check if there's a param 'id' or we search.
    // Since we don't have search index easily without extra cost/setup maybe,
    // we will implement a suboptimal "List and Find" for now since user templates count is small per user.
    // Or we rely on client sending ID next time.
    // But the signature is `QuickSaveRequest` without ID.

    let path = format!("user_templates/{}/items", user_id);
    let mut template_id = Uuid::new_v4().to_string();
    let mut is_update = false;

    if let Ok(docs) = firestore.list_docs::<serde_json::Value>(&path).await {
        // Find by name
        for doc in docs {
            if let Some(name) = doc.get("name").and_then(|n| n.as_str()) {
                if name == req.name {
                    if let Some(id) = doc.get("id").and_then(|i| i.as_str()) {
                        template_id = id.to_string();
                        is_update = true;
                        break;
                    }
                }
            }
        }
    }

    let saved_at = chrono::Utc::now().to_rfc3339();

    // We store content directly in Firestore.
    // NOTE: Max 1MB. Large templates might fail.
    // If it fails, we should return error.
    let template_doc = serde_json::json!({
        "id": template_id,
        "name": req.name,
        "description": req.description,
        "content": {
            "slides": req.slides,
            "version": 1,
            "saved_at": saved_at.clone()
        },
        // We set github_path empty or "local" to indicate it's not on GitHub yet?
        // Or we reserve github_path for when it is synced.
        "updated_at": saved_at.clone(),
        // Only set created_at if new
    });

    // We need to merge with existing if update to preserve created_at and github_path
    let final_doc = if is_update {
        // We would ideally merge. `set_doc` overwrites?
        // Firestore REST update (patch) merges if mask present or separate method.
        // `update_doc` in our client uses PATCH.
        template_doc // We use this as partial update payload? `content` field + `updated_at`.
                     // But we want to set `content` field.
                     // Let's use `set_doc` which overwrites, effectively replacing the draft.
                     // BUT if github_path existed, we lose it?
                     // Let's first try to `update_doc` (PATCH).
    } else {
        template_doc
    };

    let result = if is_update {
        firestore.update_doc(&path, &template_id, &final_doc).await
    } else {
        // Add created_at
        let mut full_doc = final_doc;
        if let Some(obj) = full_doc.as_object_mut() {
            obj.insert(
                "created_at".to_string(),
                serde_json::json!(saved_at.clone()),
            );
            if !is_update {
                obj.insert("github_path".to_string(), serde_json::json!("")); // Explicit empty
            }
        }
        firestore.set_doc(&path, &template_id, &full_doc).await
    };

    match result {
        Ok(_) => {
            tracing::info!(
                "[AutoSave] {} template '{}' for user {}",
                if is_update { "Updated" } else { "Created" },
                req.name,
                user_id
            );
            (
                StatusCode::OK,
                Json(QuickSaveResponse {
                    success: true,
                    id: template_id,
                    message: if is_update {
                        "Template updated"
                    } else {
                        "Template created"
                    }
                    .to_string(),
                    saved_at,
                }),
            )
        }
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(QuickSaveResponse {
                success: false,
                id: String::new(),
                message: e.to_string(),
                saved_at: String::new(),
            }),
        ),
    }
}

/// GET /api/templates/quick-load/:id - Load template content from Firestore
pub async fn quick_load_template(
    State(_state): State<AppState>,
    Extension(user_id): Extension<String>,
    Path(template_id): Path<String>,
) -> impl IntoResponse {
    let firestore = match crate::firebase::get_firestore() {
        Some(fs) => fs,
        None => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                Json(serde_json::json!({ "success": false, "error": "Storage not available" })),
            )
        }
    };

    match firestore
        .get_doc::<serde_json::Value>(&format!("user_templates/{}/items", user_id), &template_id)
        .await
    {
        Ok(Some(doc)) => {
            let content = doc.get("content").cloned();
            (
                StatusCode::OK,
                Json(serde_json::json!({
                    "success": true,
                    "template": {
                         // We reconstruct structure expected by frontend if needed or just return content
                         // Original returned: id, name, description, content, updated_at
                         "id": doc.get("id"),
                         "name": doc.get("name"),
                         "description": doc.get("description"),
                         "content": content,
                         "updated_at": doc.get("updated_at")
                    }
                })),
            )
        }
        Ok(None) => (
            StatusCode::NOT_FOUND,
            Json(serde_json::json!({ "success": false, "error": "Not found" })),
        ),
        Err(e) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            Json(serde_json::json!({ "success": false, "error": e.to_string() })),
        ),
    }
}

```
      ]]>
        </FILE>
        <FILE path="services\mod.rs">
            <![CDATA[
```rs
pub mod report_service;

```
      ]]>
        </FILE>
        <FILE path="services\report_service.rs">
            <![CDATA[
```rs
use crate::error::ApiError;
use crate::routes::templates::{self, GitHubConfig};
use axur_core::api::report::fetch_full_report;
use axur_core::error_codes::{self, ErrorCode};
use axur_core::i18n::{get_dictionary, Language, Translations};
use axur_core::plugins::{PluginConfig, ThemeMode};
use axur_core::report::html::{generate_full_report_html, generate_report_with_plugins};
use axur_core::report::OfflineAssets;
use serde::{Deserialize, Serialize};
use std::time::Instant;
use uuid::Uuid;

// ========================
// TYPES (Moved from routes/report.rs)
// ========================

#[derive(Debug, Serialize)]
pub struct TenantResponse {
    pub key: String,
    pub name: String,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct GenerateReportRequest {
    pub tenant_id: String,
    pub from_date: String,
    pub to_date: String,
    #[serde(default = "default_language")]
    pub language: String,
    pub story_tag: Option<String>,
    #[serde(default)]
    pub include_threat_intel: bool,
    pub template_id: Option<String>,
    #[serde(default)]
    pub use_plugins: bool,
    #[serde(default)]
    pub theme: Option<String>,
    #[serde(default)]
    pub disabled_plugins: Option<Vec<String>>,
}

fn default_language() -> String {
    "es".to_string()
}

#[derive(Debug, Serialize)]
pub struct GenerateReportResponse {
    pub success: bool,
    pub html: Option<String>,
    pub company_name: Option<String>,
    pub message: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub error_code: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub error_message: Option<String>,
}

pub struct ReportService;

impl ReportService {
    /// Generate HTML report safely (No Panic)
    pub async fn generate_report(
        payload: &GenerateReportRequest,
        token: &str,
        user_id: &str,
    ) -> Result<GenerateReportResponse, ApiError> {
        let start_time = Instant::now();

        // 1. Fetch Data
        let report_data = match fetch_full_report(
            token,
            &payload.tenant_id,
            &payload.from_date,
            &payload.to_date,
            payload.story_tag.clone(),
            payload.include_threat_intel,
        )
        .await
        {
            Ok(data) => data,
            Err(e) => {
                let error_code = classify_error(&e.to_string());
                tracing::error!(
                    error_code = %error_code.code(),
                    context = %e.to_string(),
                    "Report generation failed"
                );

                //  Log error (Assuming log_error is handled by caller or we inject logger)
                // Ideally logging relates to HTTP layer, but Service can log domain errors.

                return Ok(GenerateReportResponse {
                    success: false,
                    html: None,
                    company_name: None,
                    message: e.to_string(),
                    error_code: Some(error_code.code()),
                    error_message: Some(get_user_friendly_message(&error_code)),
                });
            }
        };

        // 2. Load Language Safely
        let language = match payload.language.to_lowercase().as_str() {
            "en" => Language::En,
            "pt" | "pt-br" => Language::PtBr,
            _ => Language::Es,
        };

        let lang_code = match language {
            Language::En => "en",
            Language::PtBr => "pt-br",
            Language::Es => "es",
        };

        // SAFETY FIX: Handle Translations::load gracefully
        let translations = Translations::load(lang_code)
            .or_else(|_| Translations::load("en"))
            .map_err(|e| ApiError::Internal(format!("Failed to load translations: {}", e)))?;

        let dict = get_dictionary(language);

        // 3. Template Logic (Simplified Migration)
        let mut custom_template_slides: Option<Vec<String>> = None;
        if let Some(tid) = &payload.template_id {
            // Mock Templates
            if let Some(tmpl) = crate::routes::templates::get_mock_template(tid) {
                let slides: Vec<String> = tmpl
                    .slides
                    .iter()
                    .filter_map(|s| s.canvas_json.clone())
                    .collect();
                if !slides.is_empty() {
                    // SAFETY FIX: removed unwrap().len() logging to keep concise or use safe access
                    tracing::info!(
                        "Using mock template '{}' with {} slides",
                        tmpl.name,
                        slides.len()
                    );
                    custom_template_slides = Some(slides);
                }
            }
            // Firestore Templates (if not mock)
            if custom_template_slides.is_none() {
                if let Ok(uuid) = Uuid::parse_str(tid) {
                    if let Some(firestore) = crate::firebase::get_firestore() {
                        let doc_path = format!("user_templates/{}/items", user_id);
                        let doc_id = uuid.to_string();
                        if let Ok(Some(doc)) = firestore
                            .get_doc::<serde_json::Value>(&doc_path, &doc_id)
                            .await
                        {
                            if let Some(path) = doc.get("github_path").and_then(|s| s.as_str()) {
                                if let Some(config) = GitHubConfig::from_env() {
                                    match templates::fetch_template_from_github(&config, path).await
                                    {
                                        Ok(tmpl) => {
                                            let slides: Vec<String> = tmpl
                                                .slides
                                                .iter()
                                                .filter_map(|s| s.canvas_json.clone())
                                                .collect();
                                            if !slides.is_empty() {
                                                custom_template_slides = Some(slides);
                                                tracing::info!(
                                                    "Using custom private template: {}",
                                                    tmpl.name
                                                );
                                            }
                                        }
                                        Err(e) => tracing::error!("Failed from GitHub: {}", e),
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }

        // 4. Generate HTML
        let offline_assets = OfflineAssets::load_embedded();

        let html = if payload.use_plugins && custom_template_slides.is_none() {
            let theme_mode = match payload.theme.as_deref() {
                Some("light") => ThemeMode::Light,
                Some("auto") => ThemeMode::Auto,
                _ => ThemeMode::Dark, // Default
            };
            let config = PluginConfig::default()
                .with_theme(theme_mode)
                .disable_plugins(payload.disabled_plugins.clone().unwrap_or_default());

            generate_report_with_plugins(
                &report_data,
                &translations,
                Some(&offline_assets),
                Some(config),
            )
        } else {
            generate_full_report_html(
                &report_data,
                custom_template_slides,
                Some(&offline_assets),
                &dict,
            )
        };

        Ok(GenerateReportResponse {
            success: true,
            html: Some(html),
            company_name: Some(report_data.company_name),
            message: "Report generated successfully".into(),
            error_code: None,
            error_message: None,
        })
    }
}

// ========================
// HELPERS (Moved from routes/report.rs)
// ========================

pub fn classify_error(error: &str) -> ErrorCode {
    let lower = error.to_lowercase();
    if lower.contains("timeout") {
        if lower.contains("dark") || lower.contains("threat") {
            error_codes::threat_intel::dark_web_timeout()
        } else {
            error_codes::network::connection_timeout()
        }
    } else if lower.contains("cors") {
        error_codes::network::cors_blocked()
    } else if lower.contains("token") || lower.contains("expired") {
        error_codes::api::token_expired()
    } else if lower.contains("tenant") || lower.contains("not found") {
        error_codes::api::tenant_not_found()
    } else if lower.contains("rate") || lower.contains("limit") {
        error_codes::api::rate_limited()
    } else if lower.contains("dns") {
        error_codes::network::dns_failed()
    } else if lower.contains("ssl") || lower.contains("tls") || lower.contains("certificate") {
        error_codes::network::ssl_error()
    } else {
        error_codes::system::internal_error().with_context(error.to_string())
    }
}

pub fn get_user_friendly_message(code: &ErrorCode) -> String {
    match code.code().as_str() {
        "AUTH-001" => "Credenciales invlidas. Verifica tu email y contrasea.".into(),
        "AUTH-002" => "Cdigo 2FA incorrecto. Intenta de nuevo.".into(),
        "AUTH-003" => "Tu sesin ha expirado. Por favor, inicia sesin nuevamente.".into(),
        "AUTH-004" => "No hay sesin activa. Por favor, inicia sesin.".into(),
        "API-001" => "El token de Axur ha expirado. Reconecta tu cuenta.".into(),
        "API-002" => "El tenant seleccionado no fue encontrado.".into(),
        "API-003" => "Demasiadas solicitudes. Espera unos minutos e intenta de nuevo.".into(),
        "RPT-001" => "No hay datos en el perodo seleccionado.".into(),
        "RPT-004" => "Rango de fechas invlido o tenant no especificado.".into(),
        "TI-001" => {
            "La bsqueda en Dark Web excedi el tiempo de espera. Intenta nuevamente.".into()
        }
        "TI-002" => "El servicio de Threat Intelligence no est disponible temporalmente.".into(),
        "NET-001" => "Error de CORS. Contacta al administrador.".into(),
        "NET-002" => "Timeout de conexin. Verifica tu conexin a internet.".into(),
        "SYS-001" => "Error interno del servidor. Si persiste, contacta soporte.".into(),
        _ => "Ha ocurrido un error inesperado.".into(),
    }
}

```
      ]]>
        </FILE>
        <FILE path="utils\coords.rs">
            <![CDATA[
```rs
/// Convert screen pixels to English Metric Units (EMUs)
/// Assumption: 96 DPI, where 1 inch = 914400 EMUs / 96 = 9525 EMUs per pixel.
pub fn px_to_emu(px: f64) -> i64 {
    (px * 9525.0).round() as i64
}

/// Convert EMUs to screen pixels
pub fn emu_to_px(emu: i64) -> f64 {
    emu as f64 / 9525.0
}

```
      ]]>
        </FILE>
        <FILE path="utils\mod.rs">
            <![CDATA[
```rs
pub mod coords;

```
      ]]>
        </FILE>
    </FILES>
</AUDIT_PACKET>